{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f41f8a8-6f83-4c5c-ba32-4ee70b50a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import japanize_matplotlib\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytest\n",
    "import random\n",
    "import sys\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import HuberRegressor, LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as sp\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from unittest.mock import MagicMock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04566f44-9f0d-44e4-b2fa-eeed65de9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均絶対パーセント誤差 (MAPE)(Mean Absolute Percent Error (MAPE))を返す関数\n",
    "# 引数として長さの同じ二つのリストをとる\n",
    "# 引数l1: 実測値のリスト\n",
    "# 引数l2: 予測値のリスト\n",
    "# 単位：％\n",
    "\n",
    "def returnMapeScore(l1, l2):\n",
    "    return_num = 0\n",
    "    if(len(l1) != len(l2)):\n",
    "        print(\"引数のリストの長さが異なります\", end=\", \")\n",
    "        return -1\n",
    "    for i in range(len(l1)):\n",
    "        l1_num = l1[i]\n",
    "        l2_num = l2[i]\n",
    "\n",
    "        return_num += abs((l1_num - l2_num)/l1_num)\n",
    "\n",
    "    return_num /= len(l1)\n",
    "    return_num *= 100\n",
    "    return return_num\n",
    "\n",
    "\n",
    "# 使用例：returnMapeScore([1,2,3,4], [4,3,2,1])\n",
    "type(returnMapeScore([1, 2, 3, 4], [4, 3, 2, 1]))\n",
    "\n",
    "\n",
    "def test_returnMapeScore():\n",
    "    l1 = [1, 2, 3, 4]\n",
    "    l2 = [4, 3, 2, 1]\n",
    "    ansByFunc = returnMapeScore(l1, l2)\n",
    "    ansByHand = (abs(1-4)/1 + abs(2-3)/2 + abs(3-2)/3 + abs(4-1)/4)/4 * 100\n",
    "    # 多少の誤差を許容する\n",
    "    ansByFunc = int(ansByFunc * 100) / 100\n",
    "    ansByHand = int(ansByHand * 100) / 100\n",
    "\n",
    "    assert ansByFunc == ansByHand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c00b25-aeca-4a03-9a4b-cb8fe1ba25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベンチマークを指定して存在するファイル名のものを返す\n",
    "def returnExistingFileNames(benchmarkNames=[], classes=[], processes=[], csvDirPath=\"./csv_files\"):\n",
    "    candidateFileNames = {}\n",
    "    returnDict = {}\n",
    "    for benchmarkName in benchmarkNames:\n",
    "        for benchmarkClass in classes:\n",
    "            for process in processes:\n",
    "                candidateFileNames[f\"pprof_{benchmarkName}{benchmarkClass}{process}.csv\"] = {\n",
    "                    \"benchmarkName\": benchmarkName, \"benchmarkClass\": benchmarkClass, \"process\": process}\n",
    "    for candidateFileName in candidateFileNames.keys():\n",
    "        filePath = os.path.join(csvDirPath, candidateFileName)\n",
    "        if(os.path.exists(filePath) and os.stat(filePath).st_size != 0):\n",
    "            returnDict[candidateFileName] = candidateFileNames[candidateFileName]\n",
    "    return(returnDict)\n",
    "\n",
    "\n",
    "def test_returnExistingFileNames():\n",
    "    benchmarkNames = [\"test\"]\n",
    "    classes = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    processes = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "    csvDirPath = \"../csv_files/\"\n",
    "    returnedList = returnExistingFileNames(\n",
    "        benchmarkNames=benchmarkNames, classes=classes, processes=processes, csvDirPath=csvDirPath)\n",
    "#     print(returnedList)\n",
    "    assert returnedList[\"pprof_testA128.csv\"] == {\n",
    "        \"benchmarkName\": \"test\", \"benchmarkClass\": \"A\", \"process\": 128}\n",
    "    assert returnedList[\"pprof_testB256.csv\"] == {\n",
    "        \"benchmarkName\": \"test\", \"benchmarkClass\": \"B\", \"process\": 256}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d9031-7786-4834-8393-eba50f1e74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベンチマーク名・プロセス数・ベンチマーククラスをリストで渡して、実在するデータが集計されたDFを返す\n",
    "def returnCollectedExistingData(benchmarkNames=[], classes=[], processes=[], csvDirPath=\"./csv_files\"):\n",
    "    fileNames = returnExistingFileNames(\n",
    "        benchmarkNames=benchmarkNames, classes=classes, processes=processes, csvDirPath=csvDirPath)\n",
    "    csvDataList = []\n",
    "    for fileName in fileNames.keys():\n",
    "        rawDatum = pd.read_csv(f\"{csvDirPath}{fileName}\")\n",
    "        rawDatum[\"benchmarkName\"] = fileNames[fileName][\"benchmarkName\"]\n",
    "        rawDatum[\"benchmarkClass\"] = fileNames[fileName][\"benchmarkClass\"]\n",
    "        rawDatum[\"process\"] = fileNames[fileName][\"process\"]\n",
    "        csvDataList.append(rawDatum)\n",
    "    returnDF = pd.concat(csvDataList, axis=0)\n",
    "    returnDF = returnDF.rename(\n",
    "        columns={'Name': 'functionName', '#Call': 'functionCallNum'})\n",
    "    return(returnDF)\n",
    "\n",
    "\n",
    "def test_returnCollectedExistingData():\n",
    "    benchmarkNames = [\"test\"]\n",
    "    classes = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    processes = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "    csvDirPath = \"../csv_files/\"\n",
    "    returnedData = returnCollectedExistingData(\n",
    "        benchmarkNames=benchmarkNames, classes=classes, processes=processes, csvDirPath=csvDirPath)\n",
    "\n",
    "    case01 = {\"benchmarkName\": \"test\", \"benchmarkClass\": \"A\", \"process\": 128,\n",
    "              \"functionCalls\": {\"function00\": 99, \"function01\": 77, \"function02\": 555}}\n",
    "    case02 = {\"benchmarkName\": \"test\", \"benchmarkClass\": \"B\", \"process\": 256,\n",
    "              \"functionCalls\": {\"function00\": 5, \"function01\": 70, \"function02\": 900}}\n",
    "\n",
    "    for case in [case01, case02]:\n",
    "        benchmarkName = case[\"benchmarkName\"]\n",
    "        benchmarkClass = case[\"benchmarkClass\"]\n",
    "        process = case[\"process\"]\n",
    "        for functionName in case[\"functionCalls\"]:\n",
    "            functionCallNum = case[\"functionCalls\"][functionName]\n",
    "            targetData = returnedData[(returnedData['benchmarkName'] == benchmarkName) & (returnedData['benchmarkClass'] == benchmarkClass) & (\n",
    "                returnedData[\"process\"] == process) & (returnedData[\"functionName\"] == functionName)]\n",
    "            columns = targetData.columns.tolist()\n",
    "            functionCallNumIndex = columns.index(\"functionCallNum\")\n",
    "            assert targetData.iloc[0, functionCallNumIndex] == functionCallNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe5e199-2e43-4ed5-82dc-e3b9ebc4d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの共通部分となるクラス\n",
    "# すべての引数はただのリスト。クラスの初期化時に\"\"np.reshape()\"\"を実行する\n",
    "class ModelBase:\n",
    "    def __init__(self, trainX, trainY, targetX=[], targetY=[], benchmarkName=\"benchmarkName\", functionName=\"functionName\"):\n",
    "        self.benchmarkName = benchmarkName\n",
    "        self.functionName = functionName\n",
    "\n",
    "        self.trainX = np.reshape(trainX, (-1, 1))\n",
    "        self.trainY = np.reshape(trainY, (-1, 1))\n",
    "        self.targetX = np.reshape(targetX, (-1, 1))\n",
    "        self.targetY = np.reshape(targetY, (-1, 1))\n",
    "\n",
    "    def returnTargetX():\n",
    "        return(self.targetX)\n",
    "\n",
    "    def returnTargetY():\n",
    "        return(self.targetY)\n",
    "\n",
    "    def returnTrainX():\n",
    "        return(self.trainX)\n",
    "\n",
    "    def returnTrainY():\n",
    "        return(self.trainY)\n",
    "\n",
    "# # このクラスを継承したモデルは、いずれも次のように使用する\n",
    "# _modelLin = ModelLin(trainX=trainX, trainY=trainY, targetX=targetX, targetY=targetY)\n",
    "# _modelLin.calcLr()\n",
    "# plotY = _modelLin.predict(plotX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1aa3d8-8d06-426d-922b-a4b4fc114d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分岐モデル\n",
    "\n",
    "class ModelBranch(ModelBase):\n",
    "    def calcLr(self):\n",
    "        self.t = np.ndarray.argmax(self.trainY)\n",
    "        self.tNum = self.trainX[self.t]\n",
    "        if (self.t == 0 or self.t == len(self.trainY) - 1):\n",
    "            self.lr1 = LinearRegression()\n",
    "            self.lr1.fit(self.trainX, self.trainY)\n",
    "            self.lr2 = LinearRegression()\n",
    "            self.lr2.fit(self.trainX, self.trainY)\n",
    "        else:\n",
    "            self.trainX1 = self.trainX[:self.t]\n",
    "            self.trainX2 = self.trainX[self.t:]\n",
    "            self.trainY1 = self.trainY[:self.t]\n",
    "            self.trainY2 = self.trainY[self.t:]\n",
    "            self.lr1 = LinearRegression()\n",
    "            self.lr1.fit(self.trainX1, self.trainY1)\n",
    "            self.lr2 = LinearRegression()\n",
    "            self.lr2.fit(self.trainX2, self.trainY2)\n",
    "\n",
    "    def predict(self, num):\n",
    "        num = np.reshape(num, (-1, 1))\n",
    "        numT = np.ndarray.argmax(num)\n",
    "        numTMax = num[numT]\n",
    "        k = np.abs(np.asarray(num) - self.tNum).argmin()\n",
    "        if(len(num) == 1 and numTMax >= self.tNum):\n",
    "            predicted = self.lr2.predict(num)\n",
    "            return(predicted)\n",
    "        elif (numTMax < self.trainX[self.t] or k == 0):\n",
    "            predicted = self.lr1.predict(num)\n",
    "            return(predicted)\n",
    "        else:\n",
    "            num1 = num[:k]\n",
    "            num2 = num[k:]\n",
    "            predicted1 = self.lr1.predict(num1)\n",
    "            predicted2 = self.lr2.predict(num2)\n",
    "            predicted = np.concatenate([predicted1, predicted2])\n",
    "            return(predicted)\n",
    "\n",
    "    def ModelName(self):\n",
    "        return(\"ModelBranch\")\n",
    "\n",
    "# 線形飽和モデル\n",
    "# テスト用モデル式1：\n",
    "# y = 2x + 3 (x < 10)\n",
    "#     23     (x >= 10)\n",
    "# テスト用モデル式2：\n",
    "# y = 2x + 3\n",
    "\n",
    "\n",
    "def test_ModelBranch():\n",
    "    # X軸の値\n",
    "    plotXForBranch = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "    # Y軸の値\n",
    "    plotYForBranch = [5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 23, 23, 23, 23]\n",
    "#     plt.figure()\n",
    "#     plt.plot(plotXForBranch, plotYForBranch, label=\"y=2*+3(x<10), y=23(x>=10)\")\n",
    "    # モデルの構築\n",
    "    _modelBranch = ModelBranch(\n",
    "        trainX=plotXForBranch, trainY=plotYForBranch, targetX=[], targetY=[])\n",
    "    _modelBranch.calcLr()\n",
    "    predictedYForBranch = _modelBranch.predict(plotXForBranch)\n",
    "#     plt.plot(plotXForBranch, predictedYForBranch, label=\"線形飽和モデルによるモデル式\")\n",
    "#     plt.legend()\n",
    "    mapeScore = returnMapeScore(plotYForBranch, predictedYForBranch)\n",
    "    assert mapeScore < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd08c26-8a4e-4e76-a341-f41c27a6930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反比例モデル\n",
    "\n",
    "def ipFunc(x):\n",
    "    return 1/x\n",
    "\n",
    "\n",
    "class ModelIp(ModelBase):\n",
    "\n",
    "    def calcLr(self):\n",
    "        self.transformerIp = sp.FunctionTransformer(\n",
    "            func=ipFunc, inverse_func=ipFunc)\n",
    "        trainXIp = self.transformerIp.transform(self.trainX)\n",
    "        self.lr = LinearRegression()\n",
    "        self.lr.fit(trainXIp, self.trainY)\n",
    "\n",
    "    def predict(self, num):\n",
    "        num = np.reshape(num, (-1, 1))\n",
    "        numConverted = self.transformerIp.transform(num)\n",
    "        predicted = self.lr.predict(numConverted)\n",
    "        return(predicted)\n",
    "\n",
    "    def return_coef_(self):\n",
    "        return self.lr.coef_\n",
    "\n",
    "    def return_intercept_(self):\n",
    "        return self.lr.intercept_\n",
    "\n",
    "    def ModelName(self):\n",
    "        return(\"ModelIp\")\n",
    "\n",
    "# 反比例モデル\n",
    "# テスト用モデル式：\n",
    "# y = 2/x + 3\n",
    "\n",
    "\n",
    "def test_ModelIp():\n",
    "    # X軸の連続値\n",
    "    plotX = np.linspace(0.5, 270, 500)\n",
    "#     plt.figure()\n",
    "    plotY = 2/plotX + 3\n",
    "#     plt.plot(plotX, plotY, label=\"y = 2/x + 3\")\n",
    "    # モデルの構築\n",
    "    _modelIp = ModelIp(trainX=plotX, trainY=plotY, targetX=[], targetY=[])\n",
    "    _modelIp.calcLr()\n",
    "    predictedY = _modelIp.predict(plotX)\n",
    "#     plt.plot(plotX, predictedY, label=\"反比例モデルによるモデル式\")\n",
    "#     plt.legend()\n",
    "    mapeScore = returnMapeScore(plotY, predictedY)\n",
    "    assert mapeScore < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8cdeb-8715-4b46-934c-c31d73d0b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形モデル\n",
    "\n",
    "class ModelLin(ModelBase):\n",
    "\n",
    "    def calcLr(self):\n",
    "        self.lr = LinearRegression()\n",
    "        self.lr.fit(self.trainX, self.trainY)\n",
    "\n",
    "    def predict(self, num):\n",
    "        num = np.reshape(num, (-1, 1))\n",
    "        predicted = self.lr.predict(num)\n",
    "        return(predicted)\n",
    "\n",
    "    def return_coef_(self):\n",
    "        return self.lr.coef_\n",
    "\n",
    "    def return_intercept_(self):\n",
    "        return self.lr.intercept_\n",
    "\n",
    "    def ModelName(self):\n",
    "        return(\"ModelLin\")\n",
    "\n",
    "# 線形モデル\n",
    "# テスト用モデル式：\n",
    "# y = 2x + 3\n",
    "\n",
    "\n",
    "def test_ModelLin():\n",
    "    # X軸の連続値\n",
    "    plotX = np.linspace(0.5, 270, 500)\n",
    "#     plt.figure()\n",
    "    plotY = 2 * plotX + 3\n",
    "#     plt.plot(plotX, plotY, label=\"y = 2 * x + 3\")\n",
    "    # モデルの構築\n",
    "    _modelLin = ModelLin(trainX=plotX, trainY=plotY, targetX=[], targetY=[])\n",
    "    _modelLin.calcLr()\n",
    "    predictedY = _modelLin.predict(plotX)\n",
    "#     plt.plot(plotX, predictedY, label=\"線形モデルによるモデル式\")\n",
    "#     plt.legend()\n",
    "    mapeScore = returnMapeScore(plotY, predictedY)\n",
    "    assert mapeScore < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e7118-3f79-4ce6-8fb6-1886ac6807da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対数モデル\n",
    "\n",
    "\n",
    "def inverterLog10Func(x):\n",
    "    return 10**x\n",
    "\n",
    "\n",
    "class ModelLog10(ModelBase):\n",
    "\n",
    "    def calcLr(self):\n",
    "        self.transformerLog10 = sp.FunctionTransformer(\n",
    "            func=np.log10, inverse_func=inverterLog10Func)\n",
    "        trainXLog10 = self.transformerLog10.transform(self.trainX)\n",
    "        self.lr = LinearRegression()\n",
    "        self.lr.fit(trainXLog10, self.trainY)\n",
    "\n",
    "    def predict(self, num):\n",
    "        num = np.reshape(num, (-1, 1))\n",
    "        numConverted = self.transformerLog10.transform(num)\n",
    "        predicted = self.lr.predict(numConverted)\n",
    "        return(predicted)\n",
    "\n",
    "    def return_coef_(self):\n",
    "        return self.lr.coef_\n",
    "\n",
    "    def return_intercept_(self):\n",
    "        return self.lr.intercept_\n",
    "\n",
    "    def ModelName(self):\n",
    "        return(\"ModelLog\")\n",
    "\n",
    "# 対数モデル\n",
    "# テスト用モデル式：\n",
    "# y = 2 * log_{10}{x} + 3\n",
    "\n",
    "\n",
    "def test_ModelLog10():\n",
    "    # X軸の連続値\n",
    "    plotX = np.linspace(0.5, 270, 500)\n",
    "#     plt.figure()\n",
    "    plotY = 2 * np.log10(plotX) + 3\n",
    "#     plt.plot(plotX, plotY, label=\"y = 2 * log_{10}{x} + 3\")\n",
    "    # モデルの構築\n",
    "    _modelLog10 = ModelLog10(\n",
    "        trainX=plotX, trainY=plotY, targetX=[], targetY=[])\n",
    "    _modelLog10.calcLr()\n",
    "    predictedY = _modelLog10.predict(plotX)\n",
    "#     plt.plot(plotX, predictedY, label=\"対数モデルによるモデル式\")\n",
    "#     plt.legend()\n",
    "    mapeScore = returnMapeScore(plotY, predictedY)\n",
    "    assert mapeScore < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d861a72-f1ae-40be-992f-63d30c15b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引数として渡されたDFに\n",
    "# functionName, functionCallNum, benchmarkName, benchmarkClass, process\n",
    "# のカラムがあるかを確認する関数\n",
    "# あればTrue、なければFalseを返す\n",
    "def checkRawDFColumns(DF):\n",
    "    columns = DF.columns.tolist()\n",
    "    columnNames = [\"functionName\", \"functionCallNum\",\n",
    "                   \"benchmarkName\", \"benchmarkClass\", \"process\"]\n",
    "    for columnName in columnNames:\n",
    "        if((columnName in columns) == False):\n",
    "            print(columnName)\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def test_checkRawDFColumns():\n",
    "    # Trueケース\n",
    "    True01DF = pd.DataFrame(\n",
    "        [[\"functionName\", -1, \"benchmarkName\", \"Z\", -1]],\n",
    "        columns=[\"functionName\", \"functionCallNum\",\n",
    "                 \"benchmarkName\", \"benchmarkClass\", \"process\"]\n",
    "    )\n",
    "    True02DF = pd.DataFrame(\n",
    "        [[\"functionName\", -1, \"benchmarkName\", \"Z\", -1, \"addedData0\"]],\n",
    "        columns=[\"functionName\", \"functionCallNum\", \"benchmarkName\",\n",
    "                 \"benchmarkClass\", \"process\", \"addedData0\"]\n",
    "    )\n",
    "\n",
    "    # Falseケース\n",
    "    False01DF = pd.DataFrame(\n",
    "        [[\"functionName\", -1, \"benchmarkName\", \"Z\"]],\n",
    "        columns=[\"functionName\", \"functionCallNum\",\n",
    "                 \"benchmarkName\", \"benchmarkClass\"]\n",
    "    )\n",
    "    False02DF = pd.DataFrame(\n",
    "        [[-1, \"benchmarkName\", \"Z\", -1]],\n",
    "        columns=[\"functionCallNum\", \"benchmarkName\",\n",
    "                 \"benchmarkClass\", \"process\"]\n",
    "    )\n",
    "\n",
    "    assert True == checkRawDFColumns(True01DF)\n",
    "    assert True == checkRawDFColumns(True02DF)\n",
    "    assert False == checkRawDFColumns(False01DF)\n",
    "    assert False == checkRawDFColumns(False02DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131876a-796d-4c33-8071-3195317a4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験結果を集計するためのデータフレームのカラムの名称のリストを返す関数\n",
    "def returnNumOfColumns(dataType=False):\n",
    "    returnList = []\n",
    "    returnDict = {}\n",
    "    # ベンチマーク名\n",
    "    returnList.append(\"benchmarkName\")\n",
    "    returnDict[\"benchmarkName\"] = str\n",
    "    # 関数名\n",
    "    returnList.append(\"functionName\")\n",
    "    returnDict[\"functionName\"] = str\n",
    "    # 使用データ(説明変数のリスト)\n",
    "    returnList.append(\"usedDataX\")\n",
    "    returnDict[\"usedDataX\"] = object\n",
    "    # 使用データ(目的変数のリスト)\n",
    "    returnList.append(\"usedDataY\")\n",
    "    returnDict[\"usedDataY\"] = object\n",
    "    # 使用データ数\n",
    "    returnList.append(\"numOfData\")\n",
    "    returnDict[\"numOfData\"] = \"int16\"\n",
    "    # 固定したもの(\"Process\" or \"Class\")\n",
    "    returnList.append(\"ProcessOrClass\")\n",
    "    returnDict[\"ProcessOrClass\"] = str\n",
    "    # 固定したもの(プロセス数(数値)or問題サイズ(文字列))\n",
    "    returnList.append(\"fixed\")\n",
    "    returnDict[\"fixed\"] = object\n",
    "    # 予測対象プロセス数\n",
    "    returnList.append(\"targetProcess\")\n",
    "    returnDict[\"targetProcess\"] = \"int16\"\n",
    "    # 予測対象問題サイズ\n",
    "    returnList.append(\"targetProblemSize\")\n",
    "    returnDict[\"targetProblemSize\"] = str\n",
    "    # 予測対象関数コール回数\n",
    "    returnList.append(\"targetNumOfFunctionCall\")\n",
    "    returnDict[\"targetNumOfFunctionCall\"] = \"float32\"\n",
    "    # 線形モデルのオブジェクト\n",
    "    returnList.append(\"objectLinModel\")\n",
    "    returnDict[\"objectLinModel\"] = object\n",
    "    # 線形モデルのMAPE\n",
    "    returnList.append(\"MAPEOfLinModel\")\n",
    "    returnDict[\"MAPEOfLinModel\"] = \"float32\"\n",
    "    # 反比例モデルのオブジェクト\n",
    "    returnList.append(\"objectIpModel\")\n",
    "    returnDict[\"objectIpModel\"] = object\n",
    "    # 反比例モデルのMAPE\n",
    "    returnList.append(\"MAPEOfIpModel\")\n",
    "    returnDict[\"MAPEOfIpModel\"] = \"float32\"\n",
    "    # 対数モデルのオブジェクト\n",
    "    returnList.append(\"objectLogModel\")\n",
    "    returnDict[\"objectLogModel\"] = object\n",
    "    # 対数モデルのMAPE\n",
    "    returnList.append(\"MAPEOfLogModel\")\n",
    "    returnDict[\"MAPEOfLogModel\"] = \"float32\"\n",
    "    # 線形飽和モデルのオブジェクト\n",
    "    returnList.append(\"objectBranchModel\")\n",
    "    returnDict[\"objectBranchModel\"] = object\n",
    "    # 線形飽和モデルのMAPE\n",
    "    returnList.append(\"MAPEOfBranchModel\")\n",
    "    returnDict[\"MAPEOfBranchModel\"] = \"float32\"\n",
    "    # 説明変数に対するMAPEが最小のモデル名\n",
    "    returnList.append(\"objectBestModelName\")\n",
    "    returnDict[\"objectBestModelName\"] = object\n",
    "    # 説明変数に対するMAPEが最小のモデルを用いて予測対象の関数コール回数を予測した時の絶対相対誤差率[%]\n",
    "    returnList.append(\"MAPEOfBestModel\")\n",
    "    returnDict[\"MAPEOfBestModel\"] = \"float32\"\n",
    "    if(dataType == True):\n",
    "        return(returnDict)\n",
    "    else:\n",
    "        return(returnList)\n",
    "\n",
    "# 使用例\n",
    "# columnNames = return_numOfColumns()\n",
    "# df_sample = pd.DataFrame(columns=columnNames)\n",
    "# df_sample\n",
    "\n",
    "\n",
    "def test_returnNumOfColumns():\n",
    "    returnedList = returnNumOfColumns()\n",
    "    returnedDict = returnNumOfColumns(dataType=True)\n",
    "    # カラム名と辞書のキーが一致しているかを確認\n",
    "    for key in returnedDict.keys():\n",
    "        assert (key in returnedList)\n",
    "    # カラム名を返す場合にリスト長が想定通りかどうかを確認\n",
    "    assert len(returnedList) == 20\n",
    "    # カラム名を返す場合に辞書のキー数が想定通りかどうかを確認\n",
    "    assert len(returnedDict.keys()) == 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756936f-fcf3-4ed2-b14f-06b7739f9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnSpecificDataFromCSV(benchmarkName=\"cg\", functionName=\".TAU_application\", process=\"1\", benchmarkClass=\"A\", csvDirPath=\"./csv_files\"):\n",
    "    fileName = f\"pprof_{benchmarkName}{benchmarkClass}{process}.csv\"\n",
    "    filePath = f\"{csvDirPath}/{fileName}\"\n",
    "    rawCSVData = pd.read_csv(filePath)\n",
    "    rawCSVDataPerFunction = rawCSVData[(\n",
    "        rawCSVData[\"Name\"] == functionName)].set_index(\"Name\")\n",
    "    returnData = rawCSVDataPerFunction.at[functionName, \"#Call\"]\n",
    "    return(returnData)\n",
    "\n",
    "\n",
    "def test_returnSpecificDataFromCSV():\n",
    "    case01 = {\"benchmarkName\": \"test\", \"benchmarkClass\": \"A\",\n",
    "              \"process\": 128, \"functionName\": \"function00\", \"functionCallNum\": 99}\n",
    "    case02 = {\"benchmarkName\": \"test\", \"benchmarkClass\": \"B\",\n",
    "              \"process\": 256, \"functionName\": \"function02\", \"functionCallNum\": 900}\n",
    "    for case in [case01, case02]:\n",
    "        benchmarkName = case[\"benchmarkName\"]\n",
    "        benchmarkClass = case[\"benchmarkClass\"]\n",
    "        process = case[\"process\"]\n",
    "        functionName = case[\"functionName\"]\n",
    "        functionCallNum = case[\"functionCallNum\"]\n",
    "        assert functionCallNum == returnSpecificDataFromCSV(\n",
    "            benchmarkName=benchmarkName, functionName=functionName, process=process, benchmarkClass=benchmarkClass, csvDirPath=\"../csv_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa244456-4f08-4113-bd2f-9ce923f08338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertStrToInt_problemSizeInNPB(Alphabet: str):\n",
    "    if(Alphabet == \"A\"):\n",
    "        return (1)\n",
    "    elif(Alphabet == \"B\"):\n",
    "        return (4)\n",
    "    elif(Alphabet == \"C\"):\n",
    "        return (16)\n",
    "    elif(Alphabet == \"D\"):\n",
    "        return (256)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def test_convertStrToInt_problemSizeInNPB():\n",
    "    case00 = {\"input\":\"A\", \"output\":1}\n",
    "    case01 = {\"input\":\"Z\", \"output\":False}\n",
    "    \n",
    "    for case in [case00 , case01]:\n",
    "        output = convertStrToInt_problemSizeInNPB(case[\"input\"])\n",
    "        assert output == case[\"output\"] \n",
    "\n",
    "\n",
    "def convertIntToStr_problemSizeInNPB(number):\n",
    "    number = int(number)\n",
    "    if(number == 1):\n",
    "        return(\"A\")\n",
    "    elif(number == 4):\n",
    "        return(\"B\")\n",
    "    elif(number == 16):\n",
    "        return(\"C\")\n",
    "    elif(number == 256):\n",
    "        return(\"D\")\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def test_convertIntToStr_problemSizeInNPB():\n",
    "    case00 = {\"input\":1, \"output\":\"A\"}\n",
    "    case01 = {\"input\":-1, \"output\":False}\n",
    "    \n",
    "    for case in [case00, case01]:\n",
    "        output = convertIntToStr_problemSizeInNPB(case[\"input\"])\n",
    "        assert output == case[\"output\"]\n",
    "\n",
    "\n",
    "def convertBenchmarkClasses_problemSizeInNPB(inputList=[\"A\", \"B\", \"C\", \"D\"]):\n",
    "    ReturnList = []\n",
    "    for content in inputList:\n",
    "        ReturnList.append(convertStrToInt_problemSizeInNPB(content))\n",
    "    return(ReturnList)\n",
    "\n",
    "def test_convertBenchmarkClasses_problemSizeInNPB():\n",
    "    case00 = {\"input\":[\"A\", \"B\", \"C\", \"D\"], \"output\":[1,4,16,256]}\n",
    "    case01 = {\"input\":[\"D\", \"A\"], \"output\":[256, 1]}\n",
    "    case02 = {\"input\":[\"A\", \"X\", \"Y\", \"Z\"], \"output\":[1, False, False, False]}\n",
    "    \n",
    "    for case in [case00, case01, case02]:\n",
    "        returnedList = convertBenchmarkClasses_problemSizeInNPB(inputList=case[\"input\"])\n",
    "        assert returnedList == case[\"output\"]\n",
    "        \n",
    "\n",
    "# return_numOfColumns()でのカラム名としてのモデル名、モデルのメソッドModelName()が返すモデル名を相互的なキー・バリューとした辞書を返す関数\n",
    "def returnDictModelNames():\n",
    "    returnDict = {}\n",
    "    # カラム名をキー・モデルが返すモデル名をバリュー\n",
    "    returnDict[\"objectLinModel\"] = \"ModelLin\"\n",
    "    returnDict[\"objectIpModel\"] = \"ModelIp\"\n",
    "    returnDict[\"objectLogModel\"] = \"ModelLog\"\n",
    "    returnDict[\"objectBranchModel\"] = \"ModelBranch\"\n",
    "    # モデルが返すモデル名をキー・カラム名をバリュー\n",
    "    returnDict[\"ModelLin\"] = \"objectLinModel\"\n",
    "    returnDict[\"ModelIp\"] = \"objectIpModel\"\n",
    "    returnDict[\"ModelLog\"] = \"objectLogModel\"\n",
    "    returnDict[\"ModelBranch\"] = \"objectBranchModel\"\n",
    "\n",
    "    return(returnDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a2585-5c6a-4c8c-85e9-84c9017051d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果を集計するためのDFに挿入するSeriesを作成する関数\n",
    "def returnSeriesOfData(benchmarkName=\"benhmarkName\", functionName=\"functionName\", rawX=[1, 2, 3], rawY=[1, 2, 3], fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=-1, csvDirPath=\"./csv_files\"):\n",
    "\n",
    "    dataSeries = pd.Series(index=returnNumOfColumns(), dtype=object)\n",
    "    dataSeries[\"benchmarkName\"] = benchmarkName\n",
    "    dataSeries[\"functionName\"] = functionName\n",
    "    dataSeries[\"usedDataX\"] = rawX\n",
    "    dataSeries[\"usedDataY\"] = rawY\n",
    "    dataSeries[\"numOfData\"] = len(rawX)\n",
    "    dataSeries[\"ProcessOrClass\"] = fixProcessOrClass\n",
    "    dataSeries[\"fixed\"] = fixed\n",
    "    dataSeries[\"targetProcess\"] = targetProcess\n",
    "    dataSeries[\"targetBenchmarkClass\"] = targetBenchmarkClass\n",
    "\n",
    "    dataSeries[\"targetNumOfFunctionCall\"] = returnSpecificDataFromCSV(\n",
    "        benchmarkName=benchmarkName, functionName=functionName, process=targetProcess, benchmarkClass=targetBenchmarkClass, csvDirPath=csvDirPath)\n",
    "\n",
    "#     # MAPE の算出には returnMapeScore()を用いる\n",
    "#     # returnMapeScore()の返り値の単位は％\n",
    "\n",
    "#     # 線形モデル\n",
    "    modelLin = ModelLin(trainX=rawX, trainY=rawY)\n",
    "    modelLin.calcLr()\n",
    "    predictedY = modelLin.predict(rawX)\n",
    "    dataSeries[\"objectLinModel\"] = modelLin\n",
    "    dataSeries[\"MAPEOfLinModel\"] = returnMapeScore(predictedY, rawY)\n",
    "    # 反比例モデル\n",
    "    modelIp = ModelIp(trainX=rawX, trainY=rawY)\n",
    "    modelIp.calcLr()\n",
    "    predictedY = modelIp.predict(rawX)\n",
    "    dataSeries[\"objectIpModel\"] = modelIp\n",
    "    dataSeries[\"MAPEOfIpModel\"] = returnMapeScore(predictedY, rawY)\n",
    "    # 対数モデル\n",
    "    modelLog = ModelLog10(trainX=rawX, trainY=rawY)\n",
    "    modelLog.calcLr()\n",
    "    predictedY = modelLog.predict(rawX)\n",
    "    dataSeries[\"objectLogModel\"] = modelLog\n",
    "    dataSeries[\"MAPEOfLogModel\"] = returnMapeScore(predictedY, rawY)\n",
    "    # 分岐モデル\n",
    "    modelBranch = ModelBranch(trainX=rawX, trainY=rawY)\n",
    "    modelBranch.calcLr()\n",
    "    predictedY = modelBranch.predict(rawX)\n",
    "    dataSeries[\"objectBranchModel\"] = modelBranch\n",
    "    dataSeries[\"MAPEOfBranchModel\"] = returnMapeScore(predictedY, rawY)\n",
    "    # 最適なモデルのモデルのモデル名・MAPE値の算出\n",
    "    listToCalcBestModel = {}\n",
    "    listToCalcBestModel[dataSeries[\"objectLinModel\"].ModelName(\n",
    "    )] = dataSeries[\"MAPEOfLinModel\"]\n",
    "    listToCalcBestModel[dataSeries[\"objectIpModel\"].ModelName(\n",
    "    )] = dataSeries[\"MAPEOfIpModel\"]\n",
    "    listToCalcBestModel[dataSeries[\"objectLogModel\"].ModelName(\n",
    "    )] = dataSeries[\"MAPEOfLogModel\"]\n",
    "    listToCalcBestModel[dataSeries[\"objectBranchModel\"].ModelName(\n",
    "    )] = dataSeries[\"MAPEOfBranchModel\"]\n",
    "    minMAPE = min(listToCalcBestModel.values())\n",
    "    dataSeries[\"MAPEOfBestModel\"] = minMAPE\n",
    "    dataSeries[\"objectBestModelName\"] = [\n",
    "        k for k, v in listToCalcBestModel.items() if v == minMAPE][0]\n",
    "    # relativeErrorOfBestModelへのデータ格納処理\n",
    "    # これには、学習したモデルから対象となる関数コール回数を予測し、予測値と実測値の相対誤差を入れる\n",
    "    dictOfModelNames = returnDictModelNames()\n",
    "    bestModelName = dataSeries[\"objectBestModelName\"]\n",
    "    bestModelColumnName = dictOfModelNames[bestModelName]\n",
    "    bestModelObject = dataSeries[bestModelColumnName]\n",
    "    if(fixProcessOrClass == \"Class\"):\n",
    "        targetX = targetProcess\n",
    "    else:\n",
    "        targetX = convertStrToInt_problemSizeInNPB(targetProblemSize)\n",
    "#     predictedTargetData = bestModelObject.predict(targetX).tolist()[0]\n",
    "#     dataSeries[\"predictedTargetNumOfFunctionCall\"] = predictedTargetData\n",
    "#     dataSeries[\"relativeErrorOfBestModel\"] = returnRelativeErrorRate(\n",
    "#         real_data=dataSeries[\"targetNumOfFunctionCall\"], predict_data=predictedTargetData)\n",
    "\n",
    "    return(dataSeries)\n",
    "\n",
    "\n",
    "@pytest.fixture()\n",
    "def test_generateCSVFilesForReturnSeriesOfData():\n",
    "    filePath = \"/tmp/pprof_testD256.csv\"\n",
    "    functionName = \"testFunctionName\"\n",
    "    with open(filePath, 'w') as f:\n",
    "        f.write(\"Name,#Call\\n\")\n",
    "        # 本来は各モデルごとに最適な関数コール回数とするべきだが、できないので-1を返すようにした\n",
    "        f.write(f\"{functionName},-1\\n\")\n",
    "\n",
    "\n",
    "def test_returnSeriesOfData(test_generateCSVFilesForReturnSeriesOfData):\n",
    "    # 共通部分の設定\n",
    "    benchmarkName = \"test\"\n",
    "    functionName = \"testFunctionName\"\n",
    "    targetProcess = 256\n",
    "    targetBenchmarkClass = \"D\"\n",
    "    fixProcessOrClass = \"Class\"\n",
    "    fix = targetBenchmarkClass\n",
    "\n",
    "    csvDirPathForTest = \"/tmp\"\n",
    "\n",
    "    explanatoryVariableX = np.array([1, 2, 4, 8, 16, 32, 64, 128, 256])\n",
    "    responseVariableY = [-1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "\n",
    "    # 分岐モデルが最適となる場合\n",
    "    # 目的変数を分岐モデルが最適となるように設定する\n",
    "    responseVariableY = [48, 52, 60, 76, 108, 172, 300, 300, 300]\n",
    "    branchSeries = returnSeriesOfData(benchmarkName=benchmarkName, functionName=f\"{functionName}\", rawX=explanatoryVariableX, rawY=responseVariableY,\n",
    "                                      fixProcessOrClass=fixProcessOrClass, fixed=targetBenchmarkClass, targetProcess=targetProcess, targetBenchmarkClass=targetBenchmarkClass, targetFunctionCallNum=responseVariableY[-1], csvDirPath=csvDirPathForTest)\n",
    "    # 最適なモデルが分岐モデルであることを確認\n",
    "    assert branchSeries[\"objectBestModelName\"] == \"ModelBranch\"\n",
    "    # 説明変数に対するMAPEが最小のモデルを用いて予測対象の関数コール回数を予測した時の絶対相対誤差率が非常に小さいことを確認\n",
    "\n",
    "    # 反比例モデルが最適となる場合\n",
    "    # 目的変数を反比例モデルが最適となるように設定する\n",
    "    responseVariableY = 2/explanatoryVariableX + 3\n",
    "    ipSeries = returnSeriesOfData(benchmarkName=benchmarkName, functionName=f\"{functionName}\", rawX=explanatoryVariableX, rawY=responseVariableY,\n",
    "                                  fixProcessOrClass=fixProcessOrClass, fixed=targetBenchmarkClass, targetProcess=targetProcess, targetBenchmarkClass=targetBenchmarkClass, csvDirPath=csvDirPathForTest)\n",
    "    # 最適なモデルが反比例モデルであることを確認\n",
    "    assert ipSeries[\"objectBestModelName\"] == \"ModelIp\"\n",
    "    # 説明変数に対するMAPEが最小のモデルを用いて予測対象の関数コール回数を予測した時の絶対相対誤差率が非常に小さいことを確認\n",
    "\n",
    "    # 線形モデルが最適となる場合\n",
    "    # 目的変数を線形モデルが最適となるように設定する\n",
    "    responseVariableY = 2 * explanatoryVariableX + 3\n",
    "    linSeries = returnSeriesOfData(benchmarkName=benchmarkName, functionName=f\"{functionName}\", rawX=explanatoryVariableX, rawY=responseVariableY,\n",
    "                                   fixProcessOrClass=fixProcessOrClass, fixed=targetBenchmarkClass, targetProcess=targetProcess, targetBenchmarkClass=targetBenchmarkClass, csvDirPath=csvDirPathForTest)\n",
    "    # 最適なモデルが線形モデルであることを確認\n",
    "    assert linSeries[\"objectBestModelName\"] == \"ModelLin\"\n",
    "    # 説明変数に対するMAPEが最小のモデルを用いて予測対象の関数コール回数を予測した時の絶対相対誤差率が非常に小さいことを確認\n",
    "\n",
    "    # 対数モデルが最適となる場合\n",
    "    # 目的変数を対数モデルが最適となるように設定する\n",
    "    responseVariableY = 2 * np.log10(explanatoryVariableX) + 3\n",
    "    logSeries = returnSeriesOfData(benchmarkName=benchmarkName, functionName=f\"{functionName}\", rawX=explanatoryVariableX, rawY=responseVariableY,\n",
    "                                   fixProcessOrClass=fixProcessOrClass, fixed=targetBenchmarkClass, targetProcess=targetProcess, targetBenchmarkClass=targetBenchmarkClass, csvDirPath=csvDirPathForTest)\n",
    "    # 最適なモデルが対数モデルであることを確認\n",
    "    assert logSeries[\"objectBestModelName\"] == \"ModelLog\"\n",
    "    # 説明変数に対するMAPEが最小のモデルを用いて予測対象の関数コール回数を予測した時の絶対相対誤差率が非常に小さいことを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34fdf09-109d-48ed-8c34-6008951ee6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture()\n",
    "def test_generateAllBranchFunctionCSVData():\n",
    "    benchmarkName = \"branch\"\n",
    "    fileNamePrefix = f\"pprof_{benchmarkName}\"\n",
    "    classes = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    explanatoryVariableX = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "    responseVariableY = [48, 52, 60, 76, 108, 172, 300, 300, 300]\n",
    "    functionNames = []\n",
    "    for i in range(4):\n",
    "        functionNames.append(f\"{benchmarkName}_0{i}\")\n",
    "    for benchmarkClass in classes:\n",
    "        for process in explanatoryVariableX:\n",
    "            fileName = f\"{fileNamePrefix}{benchmarkClass}{process}.csv\"\n",
    "            filePath = f\"/tmp/{fileName}\"\n",
    "            with open(filePath, 'w') as f:\n",
    "                f.write(\"Name,#Call\\n\")\n",
    "                for functionName in functionNames:\n",
    "                    functionCallNum = responseVariableY[explanatoryVariableX.index(process)]\n",
    "                    f.write(f\"{functionName},{functionCallNum}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
