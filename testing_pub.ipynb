{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:hello\n",
      "DEBUG:lib.lab_lib:hello\n"
     ]
    }
   ],
   "source": [
    "jupyter_pwd = %pwd\n",
    "if jupyter_pwd == \"/\":\n",
    "    %cd /workspace\n",
    "\n",
    "# %pdb on\n",
    "\n",
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib/lib.ipynb\n",
    "\n",
    "# ipynb形式のライブラリノートを.py形式に変更したものをインポート\n",
    "import lib\n",
    "import lib.lab_lib\n",
    "from lib.lab_lib import *\n",
    "\n",
    "# 生データの入ったCSVファイルの保持されたディレクトリ名を格納している変数\n",
    "csvDirPath = \"./csv_files/\"\n",
    "\n",
    "# NPBのベンチマーク名のリスト\n",
    "benchmarkNames = [\"cg\", \"ep\", \"ft\", \"is\", \"lu\", \"mg\"]\n",
    "\n",
    "# NPBのプロセス数\n",
    "npb_process :list[int] = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "train_npb_process :list[int] = npb_process[:-1]\n",
    "test_npb_process :list[int] = npb_process[-1:]\n",
    "# NPBのCGの初期変数\n",
    "cg_na: list[int] = [14000, 30000, 75000, 100000, 1500000]\n",
    "cg_nonzer: list[int] = [11, 12, 13, 14, 15, 18, 21]\n",
    "cg_niter: list[int] = [15, 30, 75, 90, 100]\n",
    "cg_shift: list[int] = [20, 40, 60, 80, 110, 200]\n",
    "\n",
    "train_cg_na: list[int] = cg_na[:-1]\n",
    "train_cg_nonzer: list[int] = cg_nonzer[:-1]\n",
    "train_cg_niter: list[int] = cg_niter[:-1]\n",
    "train_cg_shift: list[int] = cg_shift[:-1]\n",
    "\n",
    "test_cg_na: list[int] = cg_na[-1:]\n",
    "test_cg_nonzer: list[int] = cg_nonzer[-1:]\n",
    "test_cg_niter: list[int] = cg_niter[-1:]\n",
    "test_cg_shift: list[int] = cg_shift[-1:]\n",
    "\n",
    "# NPBのEPの初期変数\n",
    "train_ep_process :list[int] = [4, 8, 16, 32, 64]\n",
    "train_ep_size :list[int] = [24, 25, 28, 30, 32]\n",
    "test_ep_process :list[int] = [128, 256, 512]\n",
    "test_ep_size :list[int] = [36, 40, 44]\n",
    "\n",
    "# NPBのFTの初期変数\n",
    "train_ft_process :list[int] = [2, 4, 8, 16, 32, 64]\n",
    "train_ft_grid_size :list[int] = [32, 64, 128, 256, 512]\n",
    "train_ft_nit :list[int] = [5, 10, 15, 20, 25]\n",
    "\n",
    "test_ft_process :list[int] = [128, 256, 512]\n",
    "test_ft_grid_size :list[int] = [1024, 2048, 4096]\n",
    "test_ft_nit :list[int] = [30, 40, 50]\n",
    "\n",
    "# NPBのISの初期変数\n",
    "train_is_process :list[int] = [2, 4, 8, 16]\n",
    "train_is_no_of_keys :list[int] = [18, 20, 22, 24]\n",
    "train_is_max_value :list[int] = [9, 11, 13, 15]\n",
    "\n",
    "test_is_process :list[int] = [32, 64, 128]\n",
    "test_is_no_of_keys :list[int] = [28, 29, 30]\n",
    "test_is_max_value :list[int] = [18, 19, 20]\n",
    "\n",
    "# NPBのMGの初期変数\n",
    "mg_size :list[int] = [32, 64, 128, 256, 512]\n",
    "mg_nit: list[int] = [4, 10, 20, 35, 50]\n",
    "\n",
    "train_mg_process :list[int] = [4, 8, 16, 32, 64]\n",
    "train_mg_size :list[int] = [4, 8, 16, 32, 64]\n",
    "train_mg_nit :list[int] = [5, 10, 15, 20, 25]\n",
    "\n",
    "test_mg_process :list[int] = [128, 256, 512]\n",
    "test_mg_size :list[int] = [128, 256, 512]\n",
    "test_mg_nit :list[int] = [30, 40, 50]\n",
    "\n",
    "# LULESH ベンチマークプログラムのプロセス数・問題サイズ・イテレーション数\n",
    "lulesh_processes: list[int] = [8, 27, 64, 125, 216, 343, 512]\n",
    "lulesh_iterations: list[int] = [8, 16, 32, 64, 128, 256]\n",
    "lulesh_sizes: list[int] = [16, 24, 32, 48, 64, 128]\n",
    "\n",
    "train_lulesh_processes: list[int] = [8, 27, 64, 125, 216, 343]\n",
    "train_lulesh_iterations: list[int] = [8, 16, 32, 64, 128]\n",
    "train_lulesh_sizes: list[int] = [16, 24, 32, 48]\n",
    "\n",
    "test_lulesh_processes: list[int] = [512, 729, 1000]\n",
    "test_lulesh_iterations: list[int] = [256, 512, 1024]\n",
    "test_lulesh_sizes: list[int] = [64, 96, 128]\n",
    "\n",
    "# Extra-Pのオプション\n",
    "modelerNames: list[str] = [\n",
    "    # \"refining\", \n",
    "    \"multi-parameter\",\n",
    "    \"default\", \n",
    "    # \"basic --options poly_exponents=-1,0,1,2,3 log_exponents=0,1 force_combination_exponents=1 allow_negative_exponents=1\"\n",
    "    ]\n",
    "\n",
    "modelerOption: str = \"\"\" --options \\#spm=Basic \\#spo=poly_exponents=-1,0,1,2,3,log_exponents=0,1,force_combination_exponents=1,allow_negative_exponents=True\"\"\"\n",
    "\n",
    "list_csvDir = [\n",
    "    \"./csv_files/lulesh_1st/\",\n",
    "    \"./csv_files/lulesh_2nd/\",\n",
    "    \"./csv_files/lulesh_3rd/\",\n",
    "]\n",
    "\n",
    "list_csvDir_mg = [\n",
    "    \"./csv_files/mg_1st/\",\n",
    "    \"./csv_files/mg_2nd/\",\n",
    "    \"./csv_files/mg_3rd/\",\n",
    "]\n",
    "\n",
    "list_csvDir_ft :list[str] = [\n",
    "    \"./csv_files/ft_1st/\",\n",
    "    \"./csv_files/ft_2nd/\",\n",
    "    \"./csv_files/ft_3rd/\",\n",
    "]\n",
    "\n",
    "list_csvDir_ep :list[str] = [\n",
    "    \"./csv_files/ep_1st/\",\n",
    "    \"./csv_files/ep_2nd/\",\n",
    "    \"./csv_files/ep_3rd/\",\n",
    "]\n",
    "\n",
    "list_csvDir_is :list[str] = [\n",
    "    \"./csv_files/is_1st/\",\n",
    "    \"./csv_files/is_2nd/\",\n",
    "    \"./csv_files/is_3rd/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF_FT :pd.DataFrame = ret_averaged_rawDF_ft(list_process=train_ft_process, list_grid_size=train_ft_grid_size, list_nit=train_ft_nit, list_csvDir=list_csvDir_ft, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "testDF_FT :pd.DataFrame = ret_averaged_rawDF_ft(list_process=test_ft_process, list_grid_size=test_ft_grid_size, list_nit=test_ft_nit, list_csvDir=list_csvDir_ft, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "trainDF_MG :pd.DataFrame = ret_averaged_rawDF_mg(list_process=train_mg_process, list_size=train_mg_size, list_nit=train_mg_nit, list_csvDir=list_csvDir_mg, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "testDF_MG :pd.DataFrame = ret_averaged_rawDF_mg(list_process=test_mg_process, list_size=test_mg_size, list_nit=test_mg_nit, list_csvDir=list_csvDir_mg, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "trainDF_EP :pd.DataFrame = ret_averaged_rawDF_ep(list_process=train_ep_process, list_size=train_ep_size, list_csvDir=list_csvDir_ep, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "testDF_EP :pd.DataFrame = ret_averaged_rawDF_ep(list_process=test_ep_process, list_size=test_ep_size, list_csvDir=list_csvDir_ep, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "trainDF_IS :pd.DataFrame = ret_averaged_rawDF_is(list_process=train_is_process, list_key_max_value=train_is_max_value, list_no_of_keys=train_is_no_of_keys, list_csvDir=list_csvDir_is, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "testDF_IS :pd.DataFrame = ret_averaged_rawDF_is(list_process=test_is_process, list_key_max_value=test_is_max_value, list_no_of_keys=test_is_no_of_keys, list_csvDir=list_csvDir_is, resVar=\"Exclusive\")\n",
    "\n",
    "trainDF_lulesh :pd.DataFrame = ret_averaged_rawDF_lulesh(\n",
    "    list_process=train_lulesh_processes,\n",
    "    list_iteration=train_lulesh_iterations,\n",
    "    list_size = train_lulesh_sizes,\n",
    "    list_csvDir=list_csvDir,\n",
    "    resVar=\"Exclusive\"\n",
    ")\n",
    "\n",
    "testDF_lulesh :pd.DataFrame = ret_averaged_rawDF_lulesh(\n",
    "    list_process=test_lulesh_processes,\n",
    "    list_iteration=test_lulesh_iterations,\n",
    "    list_size = test_lulesh_sizes,\n",
    "    list_csvDir=list_csvDir,\n",
    "    resVar=\"Exclusive\"\n",
    ")\n",
    "\n",
    "expVars_ep :list[str] = [\"process\", \"size\"]\n",
    "expVars_ft :list[str] = [\"process\", \"grid_size\", \"nit\"]\n",
    "expVars_is :list[str] = [\"process\", \"no_of_keys\", \"key_max_value\"]\n",
    "expVars_mg :list[str] = [\"process\", \"problem_size\", \"nit\"]\n",
    "expVars_lulesh :list[str] = [\"process\", \"iteration\", \"size\"]\n",
    "\n",
    "resVar_in :str = \"Inclusive\"\n",
    "resVar_ex :str = \"Exclusive\"\n",
    "\n",
    "trainDF_in_FT :pd.DataFrame = ret_averaged_rawDF_ft(list_process=train_ft_process, list_grid_size=train_ft_grid_size, list_nit=train_ft_nit, list_csvDir=list_csvDir_ft, resVar=resVar_in)\n",
    "\n",
    "\n",
    "testDF_in_FT :pd.DataFrame = ret_averaged_rawDF_ft(list_process=test_ft_process, list_grid_size=test_ft_grid_size, list_nit=test_ft_nit, list_csvDir=list_csvDir_ft, resVar=resVar_in)\n",
    "\n",
    "\n",
    "trainDF_in_MG :pd.DataFrame = ret_averaged_rawDF_mg(list_process=train_mg_process, list_size=train_mg_size, list_nit=train_mg_nit, list_csvDir=list_csvDir_mg, resVar=resVar_in)\n",
    "\n",
    "\n",
    "testDF_in_MG :pd.DataFrame = ret_averaged_rawDF_mg(list_process=test_mg_process, list_size=test_mg_size, list_nit=test_mg_nit, list_csvDir=list_csvDir_mg, resVar=resVar_in)\n",
    "\n",
    "\n",
    "trainDF_in_EP :pd.DataFrame = ret_averaged_rawDF_ep(list_process=train_ep_process, list_size=train_ep_size, list_csvDir=list_csvDir_ep, resVar=resVar_in)\n",
    "\n",
    "\n",
    "testDF_in_EP :pd.DataFrame = ret_averaged_rawDF_ep(list_process=test_ep_process, list_size=test_ep_size, list_csvDir=list_csvDir_ep, resVar=resVar_in)\n",
    "\n",
    "\n",
    "trainDF_in_IS :pd.DataFrame = ret_averaged_rawDF_is(list_process=train_is_process, list_key_max_value=train_is_max_value, list_no_of_keys=train_is_no_of_keys, list_csvDir=list_csvDir_is, resVar=resVar_in)\n",
    "\n",
    "\n",
    "testDF_in_IS :pd.DataFrame = ret_averaged_rawDF_is(list_process=test_is_process, list_key_max_value=test_is_max_value, list_no_of_keys=test_is_no_of_keys, list_csvDir=list_csvDir_is, resVar=resVar_in)\n",
    "\n",
    "trainDF_in_lulesh :pd.DataFrame = ret_averaged_rawDF_lulesh(\n",
    "    list_process=train_lulesh_processes,\n",
    "    list_iteration=train_lulesh_iterations,\n",
    "    list_size = train_lulesh_sizes,\n",
    "    list_csvDir=list_csvDir,\n",
    "    resVar=resVar_in\n",
    ")\n",
    "\n",
    "testDF_in_lulesh :pd.DataFrame = ret_averaged_rawDF_lulesh(\n",
    "    list_process=test_lulesh_processes,\n",
    "    list_iteration=test_lulesh_iterations,\n",
    "    list_size = test_lulesh_sizes,\n",
    "    list_csvDir=list_csvDir,\n",
    "    resVar=resVar_in\n",
    ")\n",
    "\n",
    "dt_now = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca34503a3abba8bce7247bb581903c30c403bc8d\n",
      "9e2ecf93298a8b5db7fc5a81505de13ff35cec6d\n"
     ]
    }
   ],
   "source": [
    "_trainDF_FT_MpiAlltoall :pd.DataFrame = trainDF_FT[trainDF_FT[\"Name\"] == \"MPI_Alltoall()\"]\n",
    "_testDF_FT_MpiAlltoall :pd.DataFrame = testDF_FT[testDF_FT[\"Name\"] == \"MPI_Alltoall()\"]\n",
    "\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(_trainDF_FT_MpiAlltoall).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(_testDF_FT_MpiAlltoall).values).hexdigest() )\n",
    "\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_rawDFs_FT.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    _trainDF_FT_MpiAlltoall.to_excel(writer, sheet_name=\"train\")\n",
    "    _testDF_FT_MpiAlltoall.to_excel(writer, sheet_name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 必要な結果\n",
    "\n",
    "* 関数コール回数予測\n",
    "    * モデル適合度(MAPE表)\n",
    "    * モデル予測精度(MAPEが縦軸のグラフ、重み付きMAPEが縦軸のグラフ)\n",
    "* 実行時間予測\n",
    "    * モデル適合度(MAPE表)\n",
    "    * モデル予測精度(MAPEが縦軸のグラフ、重み付きMAPEが縦軸のグラフ)\n",
    "\n",
    "# 必要なブツ\n",
    "\n",
    "* ✅モデル構築用データ\n",
    "* ✅予測対象用データ\n",
    "* ✅関数コール回数の予測モデル\n",
    "* ✅関数の総実行時間の予測モデル\n",
    "* ✅1コール当たりの関数の総実行時間の予測モデル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarkName :str = \"mg\"\n",
    "\n",
    "mg_contents = ContentsForExtraP(trainDF = trainDF_MG, testDF= testDF_MG, resVar = \"Exclusive\", expVars= expVars_mg ,resVarPerCall = \"ExclusivePerCall\", benchmarkName = benchmarkName)\n",
    "\n",
    "mg_dict = mg_contents.exec_all()\n",
    "\n",
    "mg_ex_適合度 :pd.DataFrame = mg_dict[\"適合度\"]\n",
    "mg_ex_重み付きMAPE :pd.DataFrame = mg_dict[\"重み付きMAPE\"]\n",
    "mg_ex_MAPE :pd.DataFrame = mg_dict[\"MAPE\"]\n",
    "mg_ex_予測精度 :pd.DataFrame = mg_dict[\"予測精度\"]\n",
    "mg_ex_MAPE_on_functionName :pd.DataFrame = mg_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_ex.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in mg_dict.keys():\n",
    "        mg_dict[_key].to_excel(writer, sheet_name=_key)\n",
    "\n",
    "mg_in_contents = ContentsForExtraP(trainDF = trainDF_in_MG, testDF = testDF_in_MG, resVar = resVar_in, expVars = expVars_mg, resVarPerCall=f\"{resVar_in}PerCall\", benchmarkName=benchmarkName)\n",
    "mg_in_dict :dict[str, pd.DataFrame] = mg_in_contents.exec_all()\n",
    "mg_in_適合度 :pd.DataFrame = mg_in_dict[\"適合度\"]\n",
    "mg_in_重み付きMAPE :pd.DataFrame = mg_in_dict[\"重み付きMAPE\"]\n",
    "mg_in_MAPE :pd.DataFrame = mg_in_dict[\"MAPE\"]\n",
    "mg_in_予測精度 :pd.DataFrame = mg_in_dict[\"予測精度\"]\n",
    "mg_in_MAPE_on_functionName :pd.DataFrame = mg_in_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_in.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in mg_in_dict.keys():\n",
    "        mg_in_dict[_key].to_excel(writer, sheet_name=_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmarkName :str = \"ep\"\n",
    "\n",
    "ep_contents = ContentsForExtraP(trainDF = trainDF_EP, testDF= testDF_EP, resVar = \"Exclusive\", expVars= expVars_ep ,resVarPerCall = \"ExclusivePerCall\", benchmarkName = benchmarkName)\n",
    "\n",
    "ep_dict = ep_contents.exec_all()\n",
    "\n",
    "ep_ex_適合度 :pd.DataFrame = ep_dict[\"適合度\"]\n",
    "ep_ex_重み付きMAPE :pd.DataFrame = ep_dict[\"重み付きMAPE\"]\n",
    "ep_ex_MAPE :pd.DataFrame = ep_dict[\"MAPE\"]\n",
    "ep_ex_予測精度 :pd.DataFrame = ep_dict[\"予測精度\"]\n",
    "ep_ex_MAPE_on_functionName :pd.DataFrame = ep_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_ex.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in ep_dict.keys():\n",
    "        ep_dict[_key].to_excel(writer, sheet_name=_key)\n",
    "\n",
    "ep_in_contents = ContentsForExtraP(trainDF = trainDF_in_EP, testDF = testDF_in_EP, resVar = resVar_in, expVars = expVars_ep, resVarPerCall=f\"{resVar_in}PerCall\", benchmarkName=benchmarkName)\n",
    "ep_in_dict :dict[str, pd.DataFrame] = ep_in_contents.exec_all()\n",
    "ep_in_適合度 :pd.DataFrame = ep_in_dict[\"適合度\"]\n",
    "ep_in_重み付きMAPE :pd.DataFrame = ep_in_dict[\"重み付きMAPE\"]\n",
    "ep_in_MAPE :pd.DataFrame = ep_in_dict[\"MAPE\"]\n",
    "ep_in_予測精度 :pd.DataFrame = ep_in_dict[\"予測精度\"]\n",
    "ep_in_MAPE_on_functionName :pd.DataFrame = ep_in_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_in.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in ep_in_dict.keys():\n",
    "        ep_in_dict[_key].to_excel(writer, sheet_name=_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/src/lib/lab_lib.py:11045: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVarPerCall] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVarPerCall] = }\")\n",
      "/root/src/lib/lab_lib.py:11045: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVarPerCall] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVarPerCall] = }\")\n",
      "/root/src/lib/lab_lib.py:11042: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVar] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVar] = }\")\n",
      "/root/src/lib/lab_lib.py:11045: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVarPerCall] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVarPerCall] = }\")\n",
      "/root/src/lib/lab_lib.py:11042: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVar] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVar] = }\")\n",
      "/root/src/lib/lab_lib.py:11045: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVarPerCall] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVarPerCall] = }\")\n",
      "/root/src/lib/lab_lib.py:11045: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVarPerCall] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVarPerCall] = }\")\n",
      "/root/src/lib/lab_lib.py:11042: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVar] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVar] = }\")\n",
      "/root/src/lib/lab_lib.py:11045: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVarPerCall] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVarPerCall] = }\")\n",
      "/root/src/lib/lab_lib.py:11045: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVarPerCall] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVarPerCall] = }\")\n",
      "/root/src/lib/lab_lib.py:11045: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVarPerCall] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVarPerCall] = }\")\n",
      "/root/src/lib/lab_lib.py:11042: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVar] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVar] = }\")\n",
      "/root/src/lib/lab_lib.py:11045: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVarPerCall] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVarPerCall] = }\")\n",
      "/root/src/lib/lab_lib.py:11042: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVar] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVar] = }\")\n",
      "/root/src/lib/lab_lib.py:11045: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVarPerCall] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVarPerCall] = }\")\n",
      "/root/src/lib/lab_lib.py:11045: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVarPerCall] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVarPerCall] = }\")\n",
      "/root/src/lib/lab_lib.py:11042: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVar] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVar] = }\")\n",
      "/root/src/lib/lab_lib.py:11045: UserWarning: sr['Name'] = 'SET_CLASS', sr[self.resVarPerCall] = 0.0\n",
      "  warnings.warn(f\"{sr['Name'] = }, {sr[self.resVarPerCall] = }\")\n"
     ]
    }
   ],
   "source": [
    "benchmarkName :str = \"ft\"\n",
    "\n",
    "ft_contents = ContentsForExtraP(trainDF = trainDF_FT, testDF= testDF_FT, resVar = \"Exclusive\", expVars= expVars_ft ,resVarPerCall = \"ExclusivePerCall\", benchmarkName = benchmarkName)\n",
    "\n",
    "ft_dict = ft_contents.exec_all()\n",
    "\n",
    "ft_ex_適合度 :pd.DataFrame = ft_dict[\"適合度\"]\n",
    "ft_ex_重み付きMAPE :pd.DataFrame = ft_dict[\"重み付きMAPE\"]\n",
    "ft_ex_MAPE :pd.DataFrame = ft_dict[\"MAPE\"]\n",
    "ft_ex_予測精度 :pd.DataFrame = ft_dict[\"予測精度\"]\n",
    "ft_ex_MAPE_on_functionName :pd.DataFrame = ft_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_ex.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "    # ft_適合度.to_excel(writer, sheet_name=\"適合度\"),\n",
    "    # ft_MAPE.to_excel(writer, sheet_name=\"MAPE\"),\n",
    "    # ft_重み付きMAPE.to_excel(writer, sheet_name=\"重み付きMAPE\"),\n",
    "    # ft_予測精度.to_excel(writer, sheet_name=\"予測精度\"),\n",
    "\n",
    "    for _key in ft_dict.keys():\n",
    "        ft_dict[_key].to_excel(writer, sheet_name=_key)\n",
    "\n",
    "ft_in_contents = ContentsForExtraP(trainDF = trainDF_in_FT, testDF = testDF_in_FT, resVar = resVar_in, expVars = expVars_ft, resVarPerCall=f\"{resVar_in}PerCall\", benchmarkName=benchmarkName)\n",
    "ft_in_dict :dict[str, pd.DataFrame] = ft_in_contents.exec_all()\n",
    "ft_in_適合度 :pd.DataFrame = ft_in_dict[\"適合度\"]\n",
    "ft_in_重み付きMAPE :pd.DataFrame = ft_in_dict[\"重み付きMAPE\"]\n",
    "ft_in_MAPE :pd.DataFrame = ft_in_dict[\"MAPE\"]\n",
    "ft_in_予測精度 :pd.DataFrame = ft_in_dict[\"予測精度\"]\n",
    "ft_in_MAPE_on_functionName :pd.DataFrame = ft_in_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_in.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in ft_in_dict.keys():\n",
    "        ft_in_dict[_key].to_excel(writer, sheet_name=_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarkName :str = \"is\"\n",
    "\n",
    "is_contents = ContentsForExtraP(trainDF = trainDF_IS, testDF= testDF_IS, resVar = \"Exclusive\", expVars= expVars_is, resVarPerCall = \"ExclusivePerCall\", benchmarkName = benchmarkName)\n",
    "\n",
    "is_dict = is_contents.exec_all()\n",
    "\n",
    "is_ex_適合度 :pd.DataFrame = is_dict[\"適合度\"]\n",
    "is_ex_重み付きMAPE :pd.DataFrame = is_dict[\"重み付きMAPE\"]\n",
    "is_ex_MAPE :pd.DataFrame = is_dict[\"MAPE\"]\n",
    "is_ex_予測精度 :pd.DataFrame = is_dict[\"予測精度\"]\n",
    "is_ex_MAPE_on_functionName :pd.DataFrame = is_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_ex.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "    # is_適合度.to_excel(writer, sheet_name=\"適合度\"),\n",
    "    # is_MAPE.to_excel(writer, sheet_name=\"MAPE\"),\n",
    "    # is_重み付きMAPE.to_excel(writer, sheet_name=\"重み付きMAPE\"),\n",
    "    # is_予測精度.to_excel(writer, sheet_name=\"予測精度\"),\n",
    "\n",
    "    for _key in is_dict.keys():\n",
    "        is_dict[_key].to_excel(writer, sheet_name=_key)\n",
    "\n",
    "is_in_contents = ContentsForExtraP(trainDF = trainDF_in_IS, testDF = testDF_in_IS, resVar = resVar_in, expVars = expVars_is, resVarPerCall=f\"{resVar_in}PerCall\", benchmarkName=benchmarkName)\n",
    "is_in_dict :dict[str, pd.DataFrame] = is_in_contents.exec_all()\n",
    "is_in_適合度 :pd.DataFrame = is_in_dict[\"適合度\"]\n",
    "is_in_重み付きMAPE :pd.DataFrame = is_in_dict[\"重み付きMAPE\"]\n",
    "is_in_MAPE :pd.DataFrame = is_in_dict[\"MAPE\"]\n",
    "is_in_予測精度 :pd.DataFrame = is_in_dict[\"予測精度\"]\n",
    "is_in_MAPE_on_functionName :pd.DataFrame = is_in_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_in.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in is_in_dict.keys():\n",
    "        is_in_dict[_key].to_excel(writer, sheet_name=_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarkName :str = \"lulesh\"\n",
    "\n",
    "lulesh_contents = ContentsForExtraP(trainDF = trainDF_lulesh, testDF= testDF_lulesh, resVar = \"Exclusive\", expVars= expVars_lulesh ,resVarPerCall = \"ExclusivePerCall\", benchmarkName = \"lulesh\")\n",
    "\n",
    "lulesh_dict = lulesh_contents.exec_all()\n",
    "\n",
    "lulesh_ex_適合度 :pd.DataFrame = lulesh_dict[\"適合度\"]\n",
    "lulesh_ex_重み付きMAPE :pd.DataFrame = lulesh_dict[\"重み付きMAPE\"]\n",
    "lulesh_ex_MAPE :pd.DataFrame = lulesh_dict[\"MAPE\"]\n",
    "lulesh_ex_予測精度 :pd.DataFrame = lulesh_dict[\"予測精度\"]\n",
    "lulesh_ex_MAPE_on_functionName :pd.DataFrame = lulesh_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_ex.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "    # lulesh_適合度.to_excel(writer, sheet_name=\"適合度\"),\n",
    "    # lulesh_MAPE.to_excel(writer, sheet_name=\"MAPE\"),\n",
    "    # lulesh_重み付きMAPE.to_excel(writer, sheet_name=\"重み付きMAPE\"),\n",
    "    # lulesh_予測精度.to_excel(writer, sheet_name=\"予測精度\"),\n",
    "\n",
    "    for _key in lulesh_dict.keys():\n",
    "        lulesh_dict[_key].to_excel(writer, sheet_name=_key)\n",
    "\n",
    "lulesh_in_contents = ContentsForExtraP(trainDF = trainDF_in_lulesh, testDF = testDF_in_lulesh, resVar = resVar_in, expVars = expVars_lulesh, resVarPerCall=f\"{resVar_in}PerCall\", benchmarkName=benchmarkName)\n",
    "lulesh_in_dict :dict[str, pd.DataFrame] = lulesh_in_contents.exec_all()\n",
    "lulesh_in_適合度 :pd.DataFrame = lulesh_in_dict[\"適合度\"]\n",
    "lulesh_in_重み付きMAPE :pd.DataFrame = lulesh_in_dict[\"重み付きMAPE\"]\n",
    "lulesh_in_MAPE :pd.DataFrame = lulesh_in_dict[\"MAPE\"]\n",
    "lulesh_in_予測精度 :pd.DataFrame = lulesh_in_dict[\"予測精度\"]\n",
    "lulesh_in_MAPE_on_functionName :pd.DataFrame = lulesh_in_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_in.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in lulesh_in_dict.keys():\n",
    "        lulesh_in_dict[_key].to_excel(writer, sheet_name=_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ベンチマーク名</th>\n",
       "      <th>コール回数</th>\n",
       "      <th>排他的な総実行時間（直接方式）</th>\n",
       "      <th>排他的な総実行時間（分離方式）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EP</td>\n",
       "      <td>324.788035</td>\n",
       "      <td>603.094144</td>\n",
       "      <td>578.133169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FT</td>\n",
       "      <td>1.327231</td>\n",
       "      <td>20107.307838</td>\n",
       "      <td>385.155521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IS</td>\n",
       "      <td>23.662516</td>\n",
       "      <td>429.172481</td>\n",
       "      <td>448.695246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MG</td>\n",
       "      <td>11.575241</td>\n",
       "      <td>110.614697</td>\n",
       "      <td>47.061738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LULESH</td>\n",
       "      <td>2.638311</td>\n",
       "      <td>152.021226</td>\n",
       "      <td>106.569120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ベンチマーク名       コール回数  排他的な総実行時間（直接方式）  排他的な総実行時間（分離方式）\n",
       "0      EP  324.788035       603.094144       578.133169\n",
       "1      FT    1.327231     20107.307838       385.155521\n",
       "2      IS   23.662516       429.172481       448.695246\n",
       "3      MG   11.575241       110.614697        47.061738\n",
       "4  LULESH    2.638311       152.021226       106.569120"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_ex_適合度_mean :pd.Series = ep_ex_MAPE_on_functionName.mean(numeric_only=True)\n",
    "ft_ex_適合度_mean :pd.Series = ft_ex_MAPE_on_functionName.mean(numeric_only=True)\n",
    "is_ex_適合度_mean :pd.Series = is_ex_MAPE_on_functionName.mean(numeric_only=True)\n",
    "mg_ex_適合度_mean :pd.Series = mg_ex_MAPE_on_functionName.mean(numeric_only=True)\n",
    "lulesh_ex_適合度_mean :pd.Series = lulesh_ex_MAPE_on_functionName.mean(numeric_only=True)\n",
    "\n",
    "_list :list[pd.Series] = [\n",
    "    pd.Series([\"EP\", ep_ex_適合度_mean[\"MAPE_#Call\"], ep_ex_適合度_mean[\"MAPE_Exclusive\"], ep_ex_適合度_mean[\"MAPE_ExclusivePerCall\"]],index=[\"benchmarkName\", \"MAPE_#Call\", \"MAPE_Exclusive\", \"MAPE_ExclusivePerCall\"]),\n",
    "    pd.Series([\"FT\", ft_ex_適合度_mean[\"MAPE_#Call\"], ft_ex_適合度_mean[\"MAPE_Exclusive\"], ft_ex_適合度_mean[\"MAPE_ExclusivePerCall\"]],index=[\"benchmarkName\", \"MAPE_#Call\", \"MAPE_Exclusive\", \"MAPE_ExclusivePerCall\"]),\n",
    "    pd.Series([\"IS\", is_ex_適合度_mean[\"MAPE_#Call\"], is_ex_適合度_mean[\"MAPE_Exclusive\"], is_ex_適合度_mean[\"MAPE_ExclusivePerCall\"]],index=[\"benchmarkName\", \"MAPE_#Call\", \"MAPE_Exclusive\", \"MAPE_ExclusivePerCall\"]),\n",
    "    pd.Series([\"MG\", mg_ex_適合度_mean[\"MAPE_#Call\"], mg_ex_適合度_mean[\"MAPE_Exclusive\"], mg_ex_適合度_mean[\"MAPE_ExclusivePerCall\"]],index=[\"benchmarkName\", \"MAPE_#Call\", \"MAPE_Exclusive\", \"MAPE_ExclusivePerCall\"]),\n",
    "    pd.Series([\"LULESH\", lulesh_ex_適合度_mean[\"MAPE_#Call\"], lulesh_ex_適合度_mean[\"MAPE_Exclusive\"], lulesh_ex_適合度_mean[\"MAPE_ExclusivePerCall\"]],index=[\"benchmarkName\", \"MAPE_#Call\", \"MAPE_Exclusive\", \"MAPE_ExclusivePerCall\"]),\n",
    "]\n",
    "適合度_ex_mape :pd.DataFrame = pd.DataFrame(data=_list)\n",
    "\n",
    "適合度_ex_mape_JP :pd.DataFrame = 適合度_ex_mape.rename(columns={\n",
    "    \"benchmarkName\": \"ベンチマーク名\", \n",
    "    \"MAPE_#Call\": \"コール回数\",\n",
    "    \"MAPE_Exclusive\": \"排他的な総実行時間（直接方式）\",\n",
    "    \"MAPE_ExclusivePerCall\": \"排他的な総実行時間（分離方式）\",\n",
    "})\n",
    "\n",
    "適合度_ex_mape_JP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{ベンチマークごとのモデル適合度}\n",
      "\\label{2022年12月30日_ベンチマークごとのモデル適合度}\n",
      "\\begin{tabular}{llSSS}\n",
      "\\toprule\n",
      " & ベンチマーク名 & コール回数 & 排他的な総実行時間（直接方式） & 排他的な総実行時間（分離方式） \\\\\n",
      "\\midrule\n",
      "0 & EP & 324.79 & 603.09 & 578.13 \\\\\n",
      "1 & FT & 1.33 & 20107.31 & 385.16 \\\\\n",
      "2 & IS & 23.66 & 429.17 & 448.70 \\\\\n",
      "3 & MG & 11.58 & 110.61 & 47.06 \\\\\n",
      "4 & LULESH & 2.64 & 152.02 & 106.57 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(適合度_ex_mape_JP.style.format({\n",
    "    \"コール回数\":'{:.2f}',\n",
    "    \"排他的な総実行時間（直接方式）\":'{:.2f}',\n",
    "    \"排他的な総実行時間（分離方式）\":'{:.2f}',\n",
    "}).to_latex(\n",
    "    column_format=\"llSSS\",\n",
    "    label=\"2022年12月30日_ベンチマークごとのモデル適合度\",\n",
    "    caption=\"ベンチマークごとのモデル適合度\",\n",
    "    hrules=True,\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "適合度(コール回数)の表を作成\n",
    "\n",
    "構成は下記の通り\n",
    "\n",
    "| ベンチマーク名 | 平均 | 最小 | 最大 |\n",
    "|---------|----|----|----|\n",
    "|         |    |    |    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_DF_fitness_benchmarkName_mean_min_max(dict_DF :dict[str, pd.DataFrame], resVar :str):\n",
    "    _list_series :list[pd.Series] = []\n",
    "    for _key_dict_DF in dict_DF.keys():\n",
    "        _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "        _series[\"ベンチマーク名\"] = _key_dict_DF\n",
    "        columns :list[str]= dict_DF[_key_dict_DF].columns\n",
    "        _series[\"平均値\"] = dict_DF[_key_dict_DF][f\"APE_{resVar}\"].mean()\n",
    "        _series[\"最低値\"] = dict_DF[_key_dict_DF][f\"APE_{resVar}\"].min()\n",
    "        _series[\"最大値\"] = dict_DF[_key_dict_DF][f\"APE_{resVar}\"].max()\n",
    "\n",
    "        _list_series.append(_series)\n",
    "\n",
    "    return pd.DataFrame(data=_list_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{ベンチマークごとの関数コール回数モデルの適合度}\n",
      "\\label{2023年1月2日_ベンチマークごとの関数コール回数モデルの適合度}\n",
      "\\begin{tabular}{llSSS}\n",
      "\\toprule\n",
      " & ベンチマーク名 & 平均値 & 最低値 & 最大値 \\\\\n",
      "\\midrule\n",
      "0 & EP & 324.79 & 0.00 & 13775.78 \\\\\n",
      "1 & FT & 1.58 & 0.00 & 283.65 \\\\\n",
      "2 & IS & 23.66 & 0.00 & 2024.92 \\\\\n",
      "3 & MG & 10.92 & 0.00 & 903.92 \\\\\n",
      "4 & LULESH & 2.64 & 0.00 & 94.32 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ベンチマーク名</th>\n",
       "      <th>平均値</th>\n",
       "      <th>最低値</th>\n",
       "      <th>最大値</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EP</td>\n",
       "      <td>324.788035</td>\n",
       "      <td>1.110223e-14</td>\n",
       "      <td>13775.777710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FT</td>\n",
       "      <td>1.583628</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>283.652344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IS</td>\n",
       "      <td>23.662516</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2024.924314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MG</td>\n",
       "      <td>10.921127</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>903.923425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LULESH</td>\n",
       "      <td>2.638311</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>94.317078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ベンチマーク名         平均値           最低値           最大値\n",
       "0      EP  324.788035  1.110223e-14  13775.777710\n",
       "1      FT    1.583628  0.000000e+00    283.652344\n",
       "2      IS   23.662516  0.000000e+00   2024.924314\n",
       "3      MG   10.921127  0.000000e+00    903.923425\n",
       "4  LULESH    2.638311  0.000000e+00     94.317078"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input_dict :dict[str, pd.DataFrame] = {\n",
    "    \"EP\": ep_ex_適合度,\n",
    "    \"FT\": ft_ex_適合度,\n",
    "    \"IS\": is_ex_適合度,\n",
    "    \"MG\": mg_ex_適合度,\n",
    "    \"LULESH\": lulesh_ex_適合度,\n",
    "}\n",
    "\n",
    "DF_fitness_benchmarkName_mean_min_max :pd.DataFrame = return_DF_fitness_benchmarkName_mean_min_max(dict_DF=_input_dict, resVar=\"#Call\")\n",
    "\n",
    "print(DF_fitness_benchmarkName_mean_min_max.style.format({\n",
    "    \"平均値\":'{:.2f}',\n",
    "    \"最低値\":'{:.2f}',\n",
    "    \"最大値\":'{:.2f}',\n",
    "}).to_latex(\n",
    "    column_format=\"llSSS\",\n",
    "    label=\"2023年1月2日_ベンチマークごとの関数コール回数モデルの適合度\",\n",
    "    caption=\"ベンチマークごとの関数コール回数モデルの適合度\",\n",
    "    hrules=True,\n",
    "))\n",
    "\n",
    "DF_fitness_benchmarkName_mean_min_max"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "適合度（総実行時間）の表を作成\n",
    "\n",
    "構成は下記の通り\n",
    "\n",
    "|         | Ex           | Ex           | In           | In           |\n",
    "|---------|--------------|--------------|--------------|--------------|\n",
    "| ベンチマーク名 |  直接方式        | 分離方式         | 直接方式         | 分離方式         |\n",
    "|         | 平均値（最小値ー最大値） | 平均値（最小値ー最大値） | 平均値（最小値ー最大値） | 平均値（最小値ー最大値） |\n",
    "\n",
    "下記の構成のDFを作成し結合する\n",
    "\n",
    "\n",
    "\n",
    "|         | Ex or In     | Ex or In      |\n",
    "|---------|--------------|--------------|\n",
    "| ベンチマーク名 |  直接方式        | 分離方式         |\n",
    "|         | 平均値（最小値ー最大値） | 平均値（最小値ー最大値） |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ベンチマーク名           平均値       最低値           最大値\n",
      "0      EP    539.178969  0.136773  1.559976e+04\n",
      "1      FT  20711.595307  0.020261  4.125477e+06\n",
      "2      IS    402.925914  0.010435  4.859022e+04\n",
      "3      MG    104.060638  0.001647  1.104249e+04\n",
      "4  LULESH    152.021226  0.000340  1.521629e+04\n",
      "  ベンチマーク名         平均値       最低値           最大値\n",
      "0      EP  516.849396  0.078627  14251.434951\n",
      "1      FT  409.516766  0.001116  51945.343698\n",
      "2      IS  421.299789  0.037005  66931.589903\n",
      "3      MG   46.452634  0.013055   1015.196642\n",
      "4  LULESH  106.569120  0.000083  13155.787492\n"
     ]
    }
   ],
   "source": [
    "_input_dict :dict[str, pd.DataFrame] = {\n",
    "    \"EP\": ep_ex_適合度,\n",
    "    \"FT\": ft_ex_適合度,\n",
    "    \"IS\": is_ex_適合度,\n",
    "    \"MG\": mg_ex_適合度,\n",
    "    \"LULESH\": lulesh_ex_適合度,\n",
    "}\n",
    "\n",
    "DF_fitness_ex_benchmarkName_mean_min_max :pd.DataFrame = return_DF_fitness_benchmarkName_mean_min_max(dict_DF=_input_dict, resVar=f\"{resVar_ex}\")\n",
    "DF_fitness_exPerCall_benchmarkName_mean_min_max :pd.DataFrame = return_DF_fitness_benchmarkName_mean_min_max(dict_DF=_input_dict, resVar=f\"{resVar_ex}PerCall\")\n",
    "\n",
    "print(DF_fitness_ex_benchmarkName_mean_min_max)\n",
    "print(DF_fitness_exPerCall_benchmarkName_mean_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ベンチマーク名         平均値           最低値           最大値\n",
      "0      EP  439.776632  3.138075e-01  15599.759869\n",
      "1      FT  415.204292  2.168404e-14  84141.522135\n",
      "2      IS  364.002379  2.196985e-02  49760.631851\n",
      "3      MG  120.582720  8.257483e-03  26427.560834\n",
      "4  LULESH  145.280166  8.502370e-04  15816.067457\n",
      "  ベンチマーク名         平均値       最低値           最大値\n",
      "0      EP  417.696151  0.078627  14251.434951\n",
      "1      FT  472.659761  0.001116  51527.308809\n",
      "2      IS  408.554906  0.077285  66931.589903\n",
      "3      MG  138.322194  0.011259  42872.938916\n",
      "4  LULESH  146.162156  0.000083  13155.787492\n"
     ]
    }
   ],
   "source": [
    "_input_dict :dict[str, pd.DataFrame] = {\n",
    "    \"EP\": ep_in_適合度,\n",
    "    \"FT\": ft_in_適合度,\n",
    "    \"IS\": is_in_適合度,\n",
    "    \"MG\": mg_in_適合度,\n",
    "    \"LULESH\": lulesh_in_適合度,\n",
    "}\n",
    "\n",
    "DF_fitness_in_benchmarkName_mean_min_max :pd.DataFrame = return_DF_fitness_benchmarkName_mean_min_max(dict_DF=_input_dict, resVar=f\"{resVar_in}\")\n",
    "DF_fitness_inPerCall_benchmarkName_mean_min_max :pd.DataFrame = return_DF_fitness_benchmarkName_mean_min_max(dict_DF=_input_dict, resVar=f\"{resVar_in}PerCall\")\n",
    "\n",
    "print(DF_fitness_in_benchmarkName_mean_min_max)\n",
    "print(DF_fitness_inPerCall_benchmarkName_mean_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_DF_about_fitness_mean_min_max(inputDF :pd.DataFrame, dict_colName :list[str], formatted_colName :str) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"format_DF_about_fitness_mean_min_max()\n",
    "    \n",
    "    引数のDFから指定のフォーマットに変換する関数\n",
    "\n",
    "    出力DFフォーマットは下記の通り\n",
    "\n",
    "    |<ベンチマーク名>|<平均(最小, 最大)>|\n",
    "\n",
    "    Args:\n",
    "        inputDF(pd.DataFrame):入力DF\n",
    "        dict_colName(dict[str, str]):辞書。inputDFにおけるどの列名の対応を記録している。{\"benchmarkName\":<ベンチマーク名>, \"mean\":<平均>, \"min\":<最小>, \"max\":<最大>}\n",
    "        formatted_colName(str):まとめたカラム名\n",
    "\n",
    "    　Returns:\n",
    "        pd.DataFrame: 出力DF\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    _col_mea :str = dict_colName[\"mean\"]\n",
    "    _col_min :str = dict_colName[\"min\"]\n",
    "    _col_max :str = dict_colName[\"max\"]\n",
    "    _col_benchmarkName :str = dict_colName[\"benchmarkName\"]\n",
    "\n",
    "    _list_series :list[pd.Series] = []\n",
    "    \n",
    "    for _it_index, _it_series in inputDF.iterrows():\n",
    "        _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "        \n",
    "\n",
    "        _series[\"benchmarkname\"] = _it_series[colName_benchmark]\n",
    "        _mea :str = str(int(_it_series[_col_mea] * 1000) /1000)\n",
    "        _min :str = str(int(_it_series[_col_min] * 1000) /1000)\n",
    "        _max :str = str(int(_it_series[_col_max] * 1000) /1000)\n",
    "        _series[formatted_colName] = f\"{_mea}({_min},{_max})\"\n",
    "        \n",
    "        _list_series.append(_series)\n",
    "    \n",
    "    return pd.DataFrame(data=_list_series)\n",
    "\n",
    "\n",
    "def integrateDF_about_fitness_mean_min_max(inputDict :dict[str, pd.DataFrame], list_columnName_as_exception :list[str]):\n",
    "    \"\"\"integrateDF_about_fitness_mean_min_max()\n",
    "    \n",
    "    入力された複数のDFをmulti columnでまとめて返す関数\n",
    "\n",
    "    Args:\n",
    "        inputDict(dict[str, pd.DataFrame]): 入力辞書。キーがまとめるカラム名（大くくり）\n",
    "        list_columnName_as_exception(list[str]): 説明変数\n",
    "    \"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "_inputDict :dict[str, pd.DataFrame] = {\n",
    "    \"exclusive\": DF_fitness_ex_benchmarkName_mean_min_max,\n",
    "    \"inclusive\": DF_fitness_in_benchmarkName_mean_min_max,\n",
    "}\n",
    "\n",
    "colName_benchmark :str = \"ベンチマーク名\"\n",
    "\n",
    "target_colName :list[str] = [\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_colName :dict[str, str] = {\n",
    "    \"benchmarkName\": \"ベンチマーク名\",\n",
    "    \"mean\": \"平均値\",\n",
    "    \"min\": \"最低値\",\n",
    "    \"max\": \"最大値\",\n",
    "}\n",
    "\n",
    "DF_Exclude_直接方式_適合度 :pd.DataFrame = format_DF_about_fitness_mean_min_max(inputDF = DF_fitness_ex_benchmarkName_mean_min_max, dict_colName = dict_colName, formatted_colName=\"exclusive\")\n",
    "DF_Exclude_分離方式_適合度 :pd.DataFrame = format_DF_about_fitness_mean_min_max(inputDF = DF_fitness_exPerCall_benchmarkName_mean_min_max, dict_colName = dict_colName, formatted_colName=\"exclusive\")\n",
    "DF_Include_直接方式_適合度 :pd.DataFrame = format_DF_about_fitness_mean_min_max(inputDF = DF_fitness_in_benchmarkName_mean_min_max, dict_colName = dict_colName, formatted_colName=\"inclusive\")\n",
    "DF_Include_分離方式_適合度 :pd.DataFrame = format_DF_about_fitness_mean_min_max(inputDF = DF_fitness_inPerCall_benchmarkName_mean_min_max, dict_colName = dict_colName, formatted_colName=\"inclusive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  benchmarkname                    exclusive\n",
      "0            EP     539.178(0.136,15599.759)\n",
      "1            FT  20711.595(0.02,4125476.677)\n",
      "2            IS      402.925(0.01,48590.216)\n",
      "3            MG      104.06(0.001,11042.485)\n",
      "4        LULESH       152.021(0.0,15216.289)\n",
      "  benchmarkname                 exclusive\n",
      "0            EP  516.849(0.078,14251.434)\n",
      "1            FT  409.516(0.001,51945.343)\n",
      "2            IS  421.299(0.037,66931.589)\n",
      "3            MG    46.452(0.013,1015.196)\n",
      "4        LULESH    106.569(0.0,13155.787)\n",
      "  benchmarkname                 inclusive\n",
      "0            EP  439.776(0.313,15599.759)\n",
      "1            FT    415.204(0.0,84141.522)\n",
      "2            IS  364.002(0.021,49760.631)\n",
      "3            MG   120.582(0.008,26427.56)\n",
      "4        LULESH     145.28(0.0,15816.067)\n",
      "  benchmarkname                 inclusive\n",
      "0            EP  417.696(0.078,14251.434)\n",
      "1            FT  472.659(0.001,51527.308)\n",
      "2            IS  408.554(0.077,66931.589)\n",
      "3            MG  138.322(0.011,42872.938)\n",
      "4        LULESH    146.162(0.0,13155.787)\n"
     ]
    }
   ],
   "source": [
    "print(DF_Exclude_直接方式_適合度)\n",
    "print(DF_Exclude_分離方式_適合度)\n",
    "print(DF_Include_直接方式_適合度)\n",
    "print(DF_Include_分離方式_適合度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Exclude_適合度 :pd.DataFrame = pd.merge(left = DF_Exclude_直接方式_適合度.rename(columns={\"benchmarkname\": \"ベンチマーク名\", \"exclusive\": \"直接方式\"}).set_index(\"ベンチマーク名\"), right = DF_Exclude_分離方式_適合度.rename(columns={\"benchmarkname\": \"ベンチマーク名\", \"exclusive\": \"分離方式\"}).set_index(\"ベンチマーク名\"), on = \"ベンチマーク名\")\n",
    "DF_Include_適合度 :pd.DataFrame = pd.merge(left = DF_Include_直接方式_適合度.rename(columns={\"benchmarkname\": \"ベンチマーク名\", \"inclusive\": \"直接方式\"}).set_index(\"ベンチマーク名\"), right = DF_Include_分離方式_適合度.rename(columns={\"benchmarkname\": \"ベンチマーク名\", \"inclusive\": \"分離方式\"}).set_index(\"ベンチマーク名\"), on = \"ベンチマーク名\")\n",
    "\n",
    "DF_適合度 :pd.DataFrame = pd.concat({\"exclusive\": DF_Exclude_適合度, \"inclusive\": DF_Include_適合度}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{ベンチマークごとのモデル適合度}\n",
      "\\label{2022年12月30日_ベンチマークごとのモデル適合度}\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      " & \\multicolumn{2}{r}{exclusive} & \\multicolumn{2}{r}{inclusive} \\\\\n",
      " & 直接方式 & 分離方式 & 直接方式 & 分離方式 \\\\\n",
      "ベンチマーク名 &  &  &  &  \\\\\n",
      "\\midrule\n",
      "EP & 539.178(0.136,15599.759) & 516.849(0.078,14251.434) & 439.776(0.313,15599.759) & 417.696(0.078,14251.434) \\\\\n",
      "FT & 20711.595(0.02,4125476.677) & 409.516(0.001,51945.343) & 415.204(0.0,84141.522) & 472.659(0.001,51527.308) \\\\\n",
      "IS & 402.925(0.01,48590.216) & 421.299(0.037,66931.589) & 364.002(0.021,49760.631) & 408.554(0.077,66931.589) \\\\\n",
      "MG & 104.06(0.001,11042.485) & 46.452(0.013,1015.196) & 120.582(0.008,26427.56) & 138.322(0.011,42872.938) \\\\\n",
      "LULESH & 152.021(0.0,15216.289) & 106.569(0.0,13155.787) & 145.28(0.0,15816.067) & 146.162(0.0,13155.787) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">exclusive</th>\n",
       "      <th colspan=\"2\" halign=\"left\">inclusive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>直接方式</th>\n",
       "      <th>分離方式</th>\n",
       "      <th>直接方式</th>\n",
       "      <th>分離方式</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ベンチマーク名</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>539.178(0.136,15599.759)</td>\n",
       "      <td>516.849(0.078,14251.434)</td>\n",
       "      <td>439.776(0.313,15599.759)</td>\n",
       "      <td>417.696(0.078,14251.434)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>20711.595(0.02,4125476.677)</td>\n",
       "      <td>409.516(0.001,51945.343)</td>\n",
       "      <td>415.204(0.0,84141.522)</td>\n",
       "      <td>472.659(0.001,51527.308)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>402.925(0.01,48590.216)</td>\n",
       "      <td>421.299(0.037,66931.589)</td>\n",
       "      <td>364.002(0.021,49760.631)</td>\n",
       "      <td>408.554(0.077,66931.589)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>104.06(0.001,11042.485)</td>\n",
       "      <td>46.452(0.013,1015.196)</td>\n",
       "      <td>120.582(0.008,26427.56)</td>\n",
       "      <td>138.322(0.011,42872.938)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LULESH</th>\n",
       "      <td>152.021(0.0,15216.289)</td>\n",
       "      <td>106.569(0.0,13155.787)</td>\n",
       "      <td>145.28(0.0,15816.067)</td>\n",
       "      <td>146.162(0.0,13155.787)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           exclusive                            \\\n",
       "                                直接方式                      分離方式   \n",
       "ベンチマーク名                                                          \n",
       "EP          539.178(0.136,15599.759)  516.849(0.078,14251.434)   \n",
       "FT       20711.595(0.02,4125476.677)  409.516(0.001,51945.343)   \n",
       "IS           402.925(0.01,48590.216)  421.299(0.037,66931.589)   \n",
       "MG           104.06(0.001,11042.485)    46.452(0.013,1015.196)   \n",
       "LULESH        152.021(0.0,15216.289)    106.569(0.0,13155.787)   \n",
       "\n",
       "                        inclusive                            \n",
       "                             直接方式                      分離方式  \n",
       "ベンチマーク名                                                      \n",
       "EP       439.776(0.313,15599.759)  417.696(0.078,14251.434)  \n",
       "FT         415.204(0.0,84141.522)  472.659(0.001,51527.308)  \n",
       "IS       364.002(0.021,49760.631)  408.554(0.077,66931.589)  \n",
       "MG        120.582(0.008,26427.56)  138.322(0.011,42872.938)  \n",
       "LULESH      145.28(0.0,15816.067)    146.162(0.0,13155.787)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(DF_適合度.style.to_latex(\n",
    "    label=\"2022年12月30日_ベンチマークごとのモデル適合度\",\n",
    "    caption=\"ベンチマークごとのモデル適合度\",\n",
    "    hrules=True,\n",
    "))\n",
    "\n",
    "DF_適合度"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コール回数の予測精度のグラフを作成する。\n",
    "\n",
    "プロセス以外の説明変数のどちらかを選んで、\n",
    "* small\n",
    "* medium\n",
    "* large\n",
    "1枚のグラフに5つのベンチマークを併記する。\n",
    "\n",
    "| ベンチマーク名 | プロセス数以外の説明変数名 |\n",
    "|---------|---------------|\n",
    "| EP      | 問題サイズ         |\n",
    "| FT      | グリッドサイズ       |\n",
    "| IS      | No Of Keys    |\n",
    "| MG      | 問題サイズ         |\n",
    "| LULESH  | メッシュサイズ       |\n",
    "\n",
    "| ベンチマーク名 | small                                   | medium                                  | large                                   |\n",
    "|---------|-----------------------------------------|-----------------------------------------|-----------------------------------------|\n",
    "| EP      | process=512, size=36                    | process=512, size=40                    | process=512, size=44                    |\n",
    "| FT      | process=64, grid_size=128, nit=25       | process=64, grid_size=256, nit=25       | process=64, grid_size=512, nit=25       |\n",
    "| IS      | process=64, no_of_keys=28, max_value=20 | process=64, no_of_keys=29, max_value=20 | process=64, no_of_keys=30, max_value=20 |\n",
    "| MG      | process=64, size=16, nit=25             | process=64, size=32, nit=25             | process=64, size=64, nit=25             |\n",
    "| LULESH  | process=1000, iteration=48, size=32     | process=1000, iteration=48, size=64     | process=1000, iteration=48, size=128    |\n",
    "\n",
    "✔予測精度の表から、MAPE, 重み付きMAPEを算出\n",
    "\n",
    "✔各ベンチマークプログラムでまとまったものから取得したい値を取得\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_MAPE_ex_perCall_EP :dict[str, float] = {\n",
    "    \"small\" : ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == 512)&(ep_ex_MAPE[\"size\"] == 36)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == 512)&(ep_ex_MAPE[\"size\"] == 40)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == 512)&(ep_ex_MAPE[\"size\"] == 44)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_ex_perCall_FT :dict[str, float] = {\n",
    "    \"small\" : ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == 512)&(ft_ex_MAPE[\"grid_size\"] == 1024)&(ft_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == 512)&(ft_ex_MAPE[\"grid_size\"] == 2048)&(ft_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == 512)&(ft_ex_MAPE[\"grid_size\"] == 4096)&(ft_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_ex_perCall_IS :dict[str, float] = {\n",
    "    \"small\" : is_ex_MAPE[(is_ex_MAPE[\"process\"] == 128) &(is_ex_MAPE[\"no_of_keys\"] == 28) &(is_ex_MAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": is_ex_MAPE[(is_ex_MAPE[\"process\"] == 128) &(is_ex_MAPE[\"no_of_keys\"] == 29) &(is_ex_MAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : is_ex_MAPE[(is_ex_MAPE[\"process\"] == 128) &(is_ex_MAPE[\"no_of_keys\"] == 30) &(is_ex_MAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_ex_perCall_MG :dict[str, float] = {\n",
    "    \"small\" : mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == 512) &(mg_ex_MAPE[\"problem_size\"] == 128) &(mg_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == 512) &(mg_ex_MAPE[\"problem_size\"] == 256) &(mg_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == 512) &(mg_ex_MAPE[\"problem_size\"] == 512) &(mg_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_ex_perCall_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == 1000) &(lulesh_ex_MAPE[\"size\"] == 64) &(lulesh_ex_MAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == 1000) &(lulesh_ex_MAPE[\"size\"] == 96) &(lulesh_ex_MAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == 1000) &(lulesh_ex_MAPE[\"size\"] == 128)&(lulesh_ex_MAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "}\n",
    "\n",
    "dict_MAPE_ex_perCall :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_MAPE_ex_perCall_EP,\n",
    "    \"FT\": dict_MAPE_ex_perCall_FT,\n",
    "    \"IS\": dict_MAPE_ex_perCall_IS,\n",
    "    \"MG\": dict_MAPE_ex_perCall_MG,\n",
    "    \"LULESH\": dict_MAPE_ex_perCall_LULESH\n",
    "}\n",
    "\n",
    "dict_weightedMAPE_ex_perCall_EP :dict[str, float] = {\n",
    "    \"small\" : ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == 512)&(ep_ex_重み付きMAPE[\"size\"] == 36)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == 512)&(ep_ex_重み付きMAPE[\"size\"] == 40)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == 512)&(ep_ex_重み付きMAPE[\"size\"] == 44)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall_FT :dict[str, float] = {\n",
    "    \"small\" : ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == 512)&(ft_ex_重み付きMAPE[\"grid_size\"] == 1024)&(ft_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == 512)&(ft_ex_重み付きMAPE[\"grid_size\"] == 2048)&(ft_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == 512)&(ft_ex_重み付きMAPE[\"grid_size\"] == 4096)&(ft_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall_IS :dict[str, float] = {\n",
    "    \"small\" : is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == 128) &(is_ex_重み付きMAPE[\"no_of_keys\"] == 28) &(is_ex_重み付きMAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == 128) &(is_ex_重み付きMAPE[\"no_of_keys\"] == 29) &(is_ex_重み付きMAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == 128) &(is_ex_重み付きMAPE[\"no_of_keys\"] == 30) &(is_ex_重み付きMAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall_MG :dict[str, float] = {\n",
    "    \"small\" : mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == 512) &(mg_ex_重み付きMAPE[\"problem_size\"] == 128) &(mg_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == 512) &(mg_ex_重み付きMAPE[\"problem_size\"] == 256) &(mg_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == 512) &(mg_ex_重み付きMAPE[\"problem_size\"] == 512) &(mg_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == 1000) &(lulesh_ex_重み付きMAPE[\"size\"] == 64) &(lulesh_ex_重み付きMAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == 1000) &(lulesh_ex_重み付きMAPE[\"size\"] == 96) &(lulesh_ex_重み付きMAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == 1000) &(lulesh_ex_重み付きMAPE[\"size\"] == 128)&(lulesh_ex_重み付きMAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_weightedMAPE_ex_perCall_EP,\n",
    "    \"FT\": dict_weightedMAPE_ex_perCall_FT,\n",
    "    \"IS\": dict_weightedMAPE_ex_perCall_IS,\n",
    "    \"MG\": dict_weightedMAPE_ex_perCall_MG,\n",
    "    \"LULESH\": dict_weightedMAPE_ex_perCall_LULESH\n",
    "}\n",
    "\n",
    "DF_to_plot_MAPE_ex_perCall_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "DF_to_plot_weightedMAPE_ex_perCall_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "\n",
    "for benchmarkName in DF_to_plot_MAPE_ex_perCall_chart.index.tolist():\n",
    "    for columnName in DF_to_plot_MAPE_ex_perCall_chart.columns.tolist():\n",
    "        DF_to_plot_MAPE_ex_perCall_chart.loc[benchmarkName, columnName] = dict_MAPE_ex_perCall[benchmarkName][columnName]\n",
    "        DF_to_plot_weightedMAPE_ex_perCall_chart.loc[benchmarkName, columnName] = dict_weightedMAPE_ex_perCall[benchmarkName][columnName]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>small</th>\n",
       "      <th>medium</th>\n",
       "      <th>large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>54.1698385892566</td>\n",
       "      <td>61.9122293863539</td>\n",
       "      <td>58.9541195154365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>401400.495981994</td>\n",
       "      <td>3247677.85038714</td>\n",
       "      <td>26364249.1816045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>135.418427702011</td>\n",
       "      <td>122.525428877749</td>\n",
       "      <td>129.238960573315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>531.023795092643</td>\n",
       "      <td>1799.08054037095</td>\n",
       "      <td>2761.85614345787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LULESH</th>\n",
       "      <td>100.938776641633</td>\n",
       "      <td>105.331270167168</td>\n",
       "      <td>76.1867733617256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   small            medium             large\n",
       "EP      54.1698385892566  61.9122293863539  58.9541195154365\n",
       "FT      401400.495981994  3247677.85038714  26364249.1816045\n",
       "IS      135.418427702011  122.525428877749  129.238960573315\n",
       "MG      531.023795092643  1799.08054037095  2761.85614345787\n",
       "LULESH  100.938776641633  105.331270167168  76.1867733617256"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_to_plot_MAPE_ex_perCall_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>small</th>\n",
       "      <th>medium</th>\n",
       "      <th>large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>0.0157797692528926</td>\n",
       "      <td>0.00101380084353213</td>\n",
       "      <td>5.59138008110530e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>8.48865959393587</td>\n",
       "      <td>51.3245551011494</td>\n",
       "      <td>339.890735934620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>0.000440354174156456</td>\n",
       "      <td>0.000219463228973484</td>\n",
       "      <td>0.000101785164578757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>0.387063059859349</td>\n",
       "      <td>0.631488000433693</td>\n",
       "      <td>0.644445146834842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LULESH</th>\n",
       "      <td>1.20003650342787e-5</td>\n",
       "      <td>3.72447150065013e-6</td>\n",
       "      <td>1.76988826212904e-6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       small                medium                 large\n",
       "EP        0.0157797692528926   0.00101380084353213   5.59138008110530e-5\n",
       "FT          8.48865959393587      51.3245551011494      339.890735934620\n",
       "IS      0.000440354174156456  0.000219463228973484  0.000101785164578757\n",
       "MG         0.387063059859349     0.631488000433693     0.644445146834842\n",
       "LULESH   1.20003650342787e-5   3.72447150065013e-6   1.76988826212904e-6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_to_plot_weightedMAPE_ex_perCall_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_MAPE_call_EP :dict[str, float] = {\n",
    "    \"small\" : ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == 512)&(ep_ex_MAPE[\"size\"] == 36)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"medium\": ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == 512)&(ep_ex_MAPE[\"size\"] == 40)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"large\" : ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == 512)&(ep_ex_MAPE[\"size\"] == 44)].reset_index().iloc[0,:][\"MAPE_#Call\"]\n",
    "}\n",
    "dict_MAPE_call_FT :dict[str, float] = {\n",
    "    \"small\" : ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == 512)&(ft_ex_MAPE[\"grid_size\"] == 1024)&(ft_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"medium\": ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == 512)&(ft_ex_MAPE[\"grid_size\"] == 2048)&(ft_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"large\" : ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == 512)&(ft_ex_MAPE[\"grid_size\"] == 4096)&(ft_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_#Call\"]\n",
    "}\n",
    "dict_MAPE_call_IS :dict[str, float] = {\n",
    "    \"small\" : is_ex_MAPE[(is_ex_MAPE[\"process\"] == 128) &(is_ex_MAPE[\"no_of_keys\"] == 28) &(is_ex_MAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"medium\": is_ex_MAPE[(is_ex_MAPE[\"process\"] == 128) &(is_ex_MAPE[\"no_of_keys\"] == 29) &(is_ex_MAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"large\" : is_ex_MAPE[(is_ex_MAPE[\"process\"] == 128) &(is_ex_MAPE[\"no_of_keys\"] == 30) &(is_ex_MAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"MAPE_#Call\"]\n",
    "}\n",
    "dict_MAPE_call_MG :dict[str, float] = {\n",
    "    \"small\" : mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == 512) &(mg_ex_MAPE[\"problem_size\"] == 128) &(mg_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"medium\": mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == 512) &(mg_ex_MAPE[\"problem_size\"] == 256) &(mg_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"large\" : mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == 512) &(mg_ex_MAPE[\"problem_size\"] == 512) &(mg_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_#Call\"]\n",
    "}\n",
    "dict_MAPE_call_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == 1000) &(lulesh_ex_MAPE[\"size\"] == 64) &(lulesh_ex_MAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"medium\": lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == 1000) &(lulesh_ex_MAPE[\"size\"] == 96) &(lulesh_ex_MAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"large\" : lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == 1000) &(lulesh_ex_MAPE[\"size\"] == 128)&(lulesh_ex_MAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "}\n",
    "\n",
    "dict_MAPE_call :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_MAPE_call_EP,\n",
    "    \"FT\": dict_MAPE_call_FT,\n",
    "    \"IS\": dict_MAPE_call_IS,\n",
    "    \"MG\": dict_MAPE_call_MG,\n",
    "    \"LULESH\": dict_MAPE_call_LULESH\n",
    "}\n",
    "\n",
    "dict_weightedMAPE_call_EP :dict[str, float] = {\n",
    "    \"small\" : ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == 512)&(ep_ex_重み付きMAPE[\"size\"] == 36)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"medium\": ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == 512)&(ep_ex_重み付きMAPE[\"size\"] == 40)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"large\" : ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == 512)&(ep_ex_重み付きMAPE[\"size\"] == 44)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"]\n",
    "}\n",
    "dict_weightedMAPE_call_FT :dict[str, float] = {\n",
    "    \"small\" : ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == 512)&(ft_ex_重み付きMAPE[\"grid_size\"] == 1024)&(ft_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"medium\": ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == 512)&(ft_ex_重み付きMAPE[\"grid_size\"] == 2048)&(ft_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"large\" : ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == 512)&(ft_ex_重み付きMAPE[\"grid_size\"] == 4096)&(ft_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"]\n",
    "}\n",
    "dict_weightedMAPE_call_IS :dict[str, float] = {\n",
    "    \"small\" : is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == 128) &(is_ex_重み付きMAPE[\"no_of_keys\"] == 28) &(is_ex_重み付きMAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"medium\": is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == 128) &(is_ex_重み付きMAPE[\"no_of_keys\"] == 29) &(is_ex_重み付きMAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"large\" : is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == 128) &(is_ex_重み付きMAPE[\"no_of_keys\"] == 30) &(is_ex_重み付きMAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"]\n",
    "}\n",
    "dict_weightedMAPE_call_MG :dict[str, float] = {\n",
    "    \"small\" : mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == 512) &(mg_ex_重み付きMAPE[\"problem_size\"] == 128) &(mg_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"medium\": mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == 512) &(mg_ex_重み付きMAPE[\"problem_size\"] == 256) &(mg_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"large\" : mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == 512) &(mg_ex_重み付きMAPE[\"problem_size\"] == 512) &(mg_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"]\n",
    "}\n",
    "dict_weightedMAPE_call_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == 1000) &(lulesh_ex_重み付きMAPE[\"size\"] == 64) &(lulesh_ex_重み付きMAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"medium\": lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == 1000) &(lulesh_ex_重み付きMAPE[\"size\"] == 96) &(lulesh_ex_重み付きMAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"large\" : lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == 1000) &(lulesh_ex_重み付きMAPE[\"size\"] == 128)&(lulesh_ex_重み付きMAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "}\n",
    "dict_weightedMAPE_call :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_weightedMAPE_call_EP,\n",
    "    \"FT\": dict_weightedMAPE_call_FT,\n",
    "    \"IS\": dict_weightedMAPE_call_IS,\n",
    "    \"MG\": dict_weightedMAPE_call_MG,\n",
    "    \"LULESH\": dict_weightedMAPE_call_LULESH\n",
    "}\n",
    "\n",
    "DF_to_plot_MAPE_call_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "DF_to_plot_weightedMAPE_call_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "\n",
    "for benchmarkName in DF_to_plot_MAPE_call_chart.index.tolist():\n",
    "    for columnName in DF_to_plot_MAPE_call_chart.columns.tolist():\n",
    "        DF_to_plot_MAPE_call_chart.loc[benchmarkName, columnName] = dict_MAPE_call[benchmarkName][columnName]\n",
    "        DF_to_plot_weightedMAPE_call_chart.loc[benchmarkName, columnName] = dict_weightedMAPE_call[benchmarkName][columnName]\n",
    "\n",
    "\n",
    "dict_MAPE_in_perCall_EP :dict[str, float] = {\n",
    "    \"small\" : ep_in_MAPE[(ep_in_MAPE[\"process\"] == test_ep_process[-1])&(ep_in_MAPE[\"size\"] == test_ep_size[0])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"medium\": ep_in_MAPE[(ep_in_MAPE[\"process\"] == test_ep_process[-1])&(ep_in_MAPE[\"size\"] == test_ep_size[1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"large\" : ep_in_MAPE[(ep_in_MAPE[\"process\"] == test_ep_process[-1])&(ep_in_MAPE[\"size\"] == test_ep_size[2])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_in_perCall_FT :dict[str, float] = {\n",
    "    \"small\" : ft_in_MAPE[(ft_in_MAPE[\"process\"] == test_ep_process[-1])&(ft_in_MAPE[\"grid_size\"] == test_ft_grid_size[0])&(ft_in_MAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"medium\": ft_in_MAPE[(ft_in_MAPE[\"process\"] == test_ep_process[-1])&(ft_in_MAPE[\"grid_size\"] == test_ft_grid_size[1])&(ft_in_MAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"large\" : ft_in_MAPE[(ft_in_MAPE[\"process\"] == test_ep_process[-1])&(ft_in_MAPE[\"grid_size\"] == test_ft_grid_size[2])&(ft_in_MAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_in_perCall_IS :dict[str, float] = {\n",
    "    \"small\" : is_in_MAPE[(is_in_MAPE[\"process\"] == test_is_process[-1]) &(is_in_MAPE[\"no_of_keys\"] == test_is_no_of_keys[0]) &(is_in_MAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"medium\": is_in_MAPE[(is_in_MAPE[\"process\"] == test_is_process[-1]) &(is_in_MAPE[\"no_of_keys\"] == test_is_no_of_keys[1]) &(is_in_MAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"large\" : is_in_MAPE[(is_in_MAPE[\"process\"] == test_is_process[-1]) &(is_in_MAPE[\"no_of_keys\"] == test_is_no_of_keys[2]) &(is_in_MAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_in_perCall_MG :dict[str, float] = {\n",
    "    \"small\" : mg_in_MAPE[(mg_in_MAPE[\"process\"] == test_mg_process[-1]) &(mg_in_MAPE[\"problem_size\"] == test_mg_size[0]) &(mg_in_MAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"medium\": mg_in_MAPE[(mg_in_MAPE[\"process\"] == test_mg_process[-1]) &(mg_in_MAPE[\"problem_size\"] == test_mg_size[1]) &(mg_in_MAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"large\" : mg_in_MAPE[(mg_in_MAPE[\"process\"] == test_mg_process[-1]) &(mg_in_MAPE[\"problem_size\"] == test_mg_size[2]) &(mg_in_MAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_in_perCall_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_in_MAPE[(lulesh_in_MAPE[\"process\"] == test_lulesh_processes[-1]) &(lulesh_in_MAPE[\"size\"] == test_lulesh_sizes[0]) &(lulesh_in_MAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"medium\": lulesh_in_MAPE[(lulesh_in_MAPE[\"process\"] == test_lulesh_processes[-1]) &(lulesh_in_MAPE[\"size\"] == test_lulesh_sizes[1]) &(lulesh_in_MAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"large\" : lulesh_in_MAPE[(lulesh_in_MAPE[\"process\"] == test_lulesh_processes[-1]) &(lulesh_in_MAPE[\"size\"] == test_lulesh_sizes[2]) &(lulesh_in_MAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "}\n",
    "\n",
    "dict_MAPE_in_perCall :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_MAPE_in_perCall_EP,\n",
    "    \"FT\": dict_MAPE_in_perCall_FT,\n",
    "    \"IS\": dict_MAPE_in_perCall_IS,\n",
    "    \"MG\": dict_MAPE_in_perCall_MG,\n",
    "    \"LULESH\": dict_MAPE_in_perCall_LULESH\n",
    "}\n",
    "\n",
    "dict_weightedMAPE_in_perCall_EP :dict[str, float] = {\n",
    "    \"small\" : ep_in_重み付きMAPE[(ep_in_重み付きMAPE[\"process\"] == test_ep_process[0])&(ep_in_重み付きMAPE[\"size\"] == test_ep_size[0])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"medium\": ep_in_重み付きMAPE[(ep_in_重み付きMAPE[\"process\"] == test_ep_process[1])&(ep_in_重み付きMAPE[\"size\"] == test_ep_size[1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"large\" : ep_in_重み付きMAPE[(ep_in_重み付きMAPE[\"process\"] == test_ep_process[2])&(ep_in_重み付きMAPE[\"size\"] == test_ep_size[2])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_in_perCall_FT :dict[str, float] = {\n",
    "    \"small\" : ft_in_重み付きMAPE[(ft_in_重み付きMAPE[\"process\"] == test_ft_process[0])&(ft_in_重み付きMAPE[\"grid_size\"] == test_ft_grid_size[0])&(ft_in_重み付きMAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"medium\": ft_in_重み付きMAPE[(ft_in_重み付きMAPE[\"process\"] == test_ft_process[1])&(ft_in_重み付きMAPE[\"grid_size\"] == test_ft_grid_size[1])&(ft_in_重み付きMAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"large\" : ft_in_重み付きMAPE[(ft_in_重み付きMAPE[\"process\"] == test_ft_process[2])&(ft_in_重み付きMAPE[\"grid_size\"] == test_ft_grid_size[2])&(ft_in_重み付きMAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_in_perCall_IS :dict[str, float] = {\n",
    "    \"small\" : is_in_重み付きMAPE[(is_in_重み付きMAPE[\"process\"] == test_is_process[0]) &(is_in_重み付きMAPE[\"no_of_keys\"] == test_is_no_of_keys[0]) &(is_in_重み付きMAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"medium\": is_in_重み付きMAPE[(is_in_重み付きMAPE[\"process\"] == test_is_process[1]) &(is_in_重み付きMAPE[\"no_of_keys\"] == test_is_no_of_keys[1]) &(is_in_重み付きMAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"large\" : is_in_重み付きMAPE[(is_in_重み付きMAPE[\"process\"] == test_is_process[2]) &(is_in_重み付きMAPE[\"no_of_keys\"] == test_is_no_of_keys[2]) &(is_in_重み付きMAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_in_perCall_MG :dict[str, float] = {\n",
    "    \"small\" : mg_in_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == test_mg_process[0]) &(mg_in_重み付きMAPE[\"problem_size\"] == test_mg_size[0]) &(mg_in_重み付きMAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"medium\": mg_in_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == test_mg_process[1]) &(mg_in_重み付きMAPE[\"problem_size\"] == test_mg_size[1]) &(mg_in_重み付きMAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"large\" : mg_in_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == test_mg_process[2]) &(mg_in_重み付きMAPE[\"problem_size\"] == test_mg_size[2]) &(mg_in_重み付きMAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_in_perCall_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_in_重み付きMAPE[(lulesh_in_重み付きMAPE[\"process\"] == test_lulesh_processes[0]) &(lulesh_in_重み付きMAPE[\"size\"] == test_lulesh_sizes[0]) &(lulesh_in_重み付きMAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"medium\": lulesh_in_重み付きMAPE[(lulesh_in_重み付きMAPE[\"process\"] == test_lulesh_processes[1]) &(lulesh_in_重み付きMAPE[\"size\"] == test_lulesh_sizes[1]) &(lulesh_in_重み付きMAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"large\" : lulesh_in_重み付きMAPE[(lulesh_in_重み付きMAPE[\"process\"] == test_lulesh_processes[2]) &(lulesh_in_重み付きMAPE[\"size\"] == test_lulesh_sizes[2]) &(lulesh_in_重み付きMAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "}\n",
    "dict_weightedMAPE_in_perCall :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_weightedMAPE_in_perCall_EP,\n",
    "    \"FT\": dict_weightedMAPE_in_perCall_FT,\n",
    "    \"IS\": dict_weightedMAPE_in_perCall_IS,\n",
    "    \"MG\": dict_weightedMAPE_in_perCall_MG,\n",
    "    \"LULESH\": dict_weightedMAPE_in_perCall_LULESH\n",
    "}\n",
    "\n",
    "DF_to_plot_MAPE_in_perCall_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "DF_to_plot_weightedMAPE_in_perCall_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "\n",
    "for benchmarkName in DF_to_plot_MAPE_in_perCall_chart.index.tolist():\n",
    "    for columnName in DF_to_plot_MAPE_in_perCall_chart.columns.tolist():\n",
    "        DF_to_plot_MAPE_in_perCall_chart.loc[benchmarkName, columnName] = dict_MAPE_in_perCall[benchmarkName][columnName]\n",
    "        DF_to_plot_weightedMAPE_in_perCall_chart.loc[benchmarkName, columnName] = dict_weightedMAPE_in_perCall[benchmarkName][columnName]\n",
    "\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_chart_expVar.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    DF_to_plot_MAPE_call_chart.to_excel(writer, sheet_name=\"コール回数（MAPE）\")\n",
    "    DF_to_plot_weightedMAPE_call_chart.to_excel(writer, sheet_name=\"コール回数（重み付きMAPE）\")\n",
    "    DF_to_plot_MAPE_ex_perCall_chart.to_excel(writer, sheet_name=\"Exclusive（MAPE）\")\n",
    "    DF_to_plot_weightedMAPE_ex_perCall_chart.to_excel(writer, sheet_name=\"Exclusive（重み付きMAPE）\")\n",
    "    DF_to_plot_MAPE_in_perCall_chart.to_excel(writer, sheet_name=\"Inclusive（MAPE）\")\n",
    "    DF_to_plot_weightedMAPE_in_perCall_chart.to_excel(writer, sheet_name=\"Inclusive（重み付きMAPE）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>small</th>\n",
       "      <th>medium</th>\n",
       "      <th>large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>11.5866874822171</td>\n",
       "      <td>11.7544285223272</td>\n",
       "      <td>11.7641279743785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>846.932282926923</td>\n",
       "      <td>968.881332679345</td>\n",
       "      <td>1442.48554671983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>3.62684240145364</td>\n",
       "      <td>3.66527566896216</td>\n",
       "      <td>3.68449254325203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>41.3425820608501</td>\n",
       "      <td>73.8002797098333</td>\n",
       "      <td>132.244721640046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LULESH</th>\n",
       "      <td>2.72511675825220</td>\n",
       "      <td>2.72512279704510</td>\n",
       "      <td>2.72512258369738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   small            medium             large\n",
       "EP      11.5866874822171  11.7544285223272  11.7641279743785\n",
       "FT      846.932282926923  968.881332679345  1442.48554671983\n",
       "IS      3.62684240145364  3.66527566896216  3.68449254325203\n",
       "MG      41.3425820608501  73.8002797098333  132.244721640046\n",
       "LULESH  2.72511675825220  2.72512279704510  2.72512258369738"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_to_plot_MAPE_call_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>small</th>\n",
       "      <th>medium</th>\n",
       "      <th>large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>0.00331432542361967</td>\n",
       "      <td>0.000174227895953408</td>\n",
       "      <td>9.30368219814812e-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>1.31079611475855</td>\n",
       "      <td>1.49953651801906</td>\n",
       "      <td>2.23253321233814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>1.16733959401426e-5</td>\n",
       "      <td>5.89860193043626e-6</td>\n",
       "      <td>2.96476145354272e-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>0.0489320775478057</td>\n",
       "      <td>0.0690694489106718</td>\n",
       "      <td>0.0871413035337209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LULESH</th>\n",
       "      <td>3.24376693771265e-7</td>\n",
       "      <td>9.61464346476903e-8</td>\n",
       "      <td>4.05653077628884e-8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      small                medium                large\n",
       "EP      0.00331432542361967  0.000174227895953408  9.30368219814812e-6\n",
       "FT         1.31079611475855      1.49953651801906     2.23253321233814\n",
       "IS      1.16733959401426e-5   5.89860193043626e-6  2.96476145354272e-6\n",
       "MG       0.0489320775478057    0.0690694489106718   0.0871413035337209\n",
       "LULESH  3.24376693771265e-7   9.61464346476903e-8  4.05653077628884e-8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_to_plot_weightedMAPE_call_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_to_calc_cost_EP :pd.DataFrame\n",
    "DF_to_calc_cost_FT :pd.DataFrame\n",
    "DF_to_calc_cost_IS :pd.DataFrame\n",
    "DF_to_calc_cost_MG :pd.DataFrame\n",
    "DF_to_calc_cost_LULESH :pd.DataFrame\n",
    "\n",
    "# EP\n",
    "_list_series_EP :list[pd.Series] = []\n",
    "for elem_process in train_ep_process:\n",
    "    for elem_size in train_ep_size:\n",
    "        _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "        _series[\"process\"] = elem_process\n",
    "        _series[\"size\"] = elem_size\n",
    "        _series[\"time\"] = -1\n",
    "        _list_series_EP.append(_series)\n",
    "for elem_process in test_ep_process:\n",
    "    for elem_size in test_ep_size:\n",
    "        _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "        _series[\"process\"] = elem_process\n",
    "        _series[\"size\"] = elem_size\n",
    "        _series[\"time\"] = -1\n",
    "        _list_series_EP.append(_series)\n",
    "\n",
    "# FT\n",
    "_list_series_FT :list[pd.Series] = []\n",
    "for elem_process in train_ft_process:\n",
    "    for elem_grid_size in train_ft_grid_size:\n",
    "        for elem_nit in train_ft_nit:\n",
    "            _series = pd.Series(dtype=\"object\")\n",
    "            _series[\"process\"] = elem_process\n",
    "            _series[\"grid_size\"] = elem_grid_size\n",
    "            _series[\"nit\"] = elem_nit\n",
    "            _series[\"time\"] = -1\n",
    "            _list_series_FT.append(_series)\n",
    "for elem_process in test_ft_process:\n",
    "    for elem_grid_size in test_ft_grid_size:\n",
    "        for elem_nit in test_ft_nit:\n",
    "            _series = pd.Series(dtype=\"object\")\n",
    "            _series[\"process\"] = elem_process\n",
    "            _series[\"grid_size\"] = elem_grid_size\n",
    "            _series[\"nit\"] = elem_nit\n",
    "            _series[\"time\"] = -1\n",
    "            _list_series_FT.append(_series)\n",
    "\n",
    "# IS\n",
    "_list_series_IS :list[pd.Series] = []\n",
    "for elem_process in train_is_process:\n",
    "    for elem_no_of_keys in train_is_no_of_keys:\n",
    "        for elem_max_value in train_is_max_value:\n",
    "            _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "            _series[\"process\"] = elem_process\n",
    "            _series[\"no_of_keys\"] = elem_no_of_keys\n",
    "            _series[\"max_value\"] = elem_max_value\n",
    "            _series[\"time\"] = -1\n",
    "            _list_series_IS.append(_series)\n",
    "for elem_process in test_is_process:\n",
    "    for elem_no_of_keys in test_is_no_of_keys:\n",
    "        for elem_max_value in test_is_max_value:\n",
    "            _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "            _series[\"process\"] = elem_process\n",
    "            _series[\"no_of_keys\"] = elem_no_of_keys\n",
    "            _series[\"max_value\"] = elem_max_value\n",
    "            _series[\"time\"] = -1\n",
    "            _list_series_IS.append(_series)\n",
    "\n",
    "# MG\n",
    "_list_series_MG :list[pd.Series] = []\n",
    "for elem_process in train_mg_process:\n",
    "    for elem_size in train_mg_size:\n",
    "        for elem_nit in train_mg_nit:\n",
    "            _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "            _series[\"process\"] = elem_process\n",
    "            _series[\"size\"] = elem_size\n",
    "            _series[\"nit\"] = elem_nit\n",
    "            _series[\"time\"] = -1\n",
    "            _list_series_MG.append(_series)\n",
    "for elem_process in test_mg_process:\n",
    "    for elem_size in test_mg_size:\n",
    "        for elem_nit in test_mg_nit:\n",
    "            _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "            _series[\"process\"] = elem_process\n",
    "            _series[\"size\"] = elem_size\n",
    "            _series[\"nit\"] = elem_nit\n",
    "            _series[\"time\"] = -1\n",
    "            _list_series_MG.append(_series)\n",
    "\n",
    "# LULESH\n",
    "_list_series_LULESH :list[pd.Series] = []\n",
    "for elem_process in train_lulesh_processes:\n",
    "    for elem_iteration in train_lulesh_iterations:\n",
    "        for elem_size in train_lulesh_sizes:\n",
    "            _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "            _series[\"process\"] = elem_process\n",
    "            _series[\"iteration\"] = elem_iteration\n",
    "            _series[\"size\"] = elem_size\n",
    "            _series[\"time\"] = -1\n",
    "            _list_series_LULESH.append(_series)\n",
    "for elem_process in test_lulesh_processes:\n",
    "    for elem_iteration in test_lulesh_iterations:\n",
    "        for elem_size in test_lulesh_sizes:\n",
    "            _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "            _series[\"process\"] = elem_process\n",
    "            _series[\"iteration\"] = elem_iteration\n",
    "            _series[\"size\"] = elem_size\n",
    "            _series[\"time\"] = -1\n",
    "            _list_series_LULESH.append(_series)\n",
    "\n",
    "DF_to_calc_cost_EP :pd.DataFrame = pd.DataFrame(data=_list_series_EP)\n",
    "DF_to_calc_cost_FT :pd.DataFrame = pd.DataFrame(data=_list_series_FT)\n",
    "DF_to_calc_cost_IS :pd.DataFrame = pd.DataFrame(data=_list_series_IS)\n",
    "DF_to_calc_cost_MG :pd.DataFrame = pd.DataFrame(data=_list_series_MG)\n",
    "DF_to_calc_cost_LULESH :pd.DataFrame = pd.DataFrame(data=_list_series_LULESH)\n",
    "\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_table_to_calc_cost.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "    DF_to_calc_cost_EP.to_excel(writer, sheet_name=\"EP\")\n",
    "    DF_to_calc_cost_FT.to_excel(writer, sheet_name=\"FT\")\n",
    "    DF_to_calc_cost_IS.to_excel(writer, sheet_name=\"IS\")\n",
    "    DF_to_calc_cost_MG.to_excel(writer, sheet_name=\"MG\")\n",
    "    DF_to_calc_cost_LULESH.to_excel(writer, sheet_name=\"LULESH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_list_series: list[pd.Series] = []\n",
    "pis: list[str]\n",
    "\n",
    "for elem_process in train_lulesh_processes + test_lulesh_processes:\n",
    "    fileDir: str = \"./txt_files/ElapFiles/\"\n",
    "    fileName: str = f\"p{elem_process}_Elap\"\n",
    "    with open(fileDir + fileName) as f:\n",
    "        l: list[str] = [s.strip() for s in f.readlines()]\n",
    "    if len(l) % 2 != 0:\n",
    "        warnings.warn(\"ファイルの行数が偶数ではありません\")\n",
    "    for i in range(len(l)):\n",
    "        if i % 2 == 0:\n",
    "            pis = l[i].split(sep=\"/\")[-3:]\n",
    "        else:\n",
    "            time = l[i].split(sep=\" \")[-2]\n",
    "            _series: pd.Series = pd.Series(\n",
    "                {\n",
    "                    \"p\": int(pis[0].replace(\"p\", \"\")),\n",
    "                    \"i\": int(pis[1].replace(\"i\", \"\")),\n",
    "                    \"s\": int(pis[2].replace(\"s\", \"\")),\n",
    "                    \"time\": float(time),\n",
    "                }\n",
    "            )\n",
    "            _series[\"cost\"] = _series[\"p\"] * _series[\"time\"]\n",
    "            _list_series.append(_series)\n",
    "        # print(f\"pis={pis}, time={time}\")\n",
    "\n",
    "DF_pis_time: pd.DataFrame = pd.DataFrame(data=_list_series)\n",
    "\n",
    "DF_pis_time_sorted :pd.DataFrame = DF_pis_time.sort_values(by=[\"p\", \"i\", \"s\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{DF_pis_time_sorted.to_csv()}\")\n",
    "\n",
    "_list_p :list[int] = list(set(DF_pis_time_sorted[\"p\"].to_list()))\n",
    "_list_i :list[int] = list(set(DF_pis_time_sorted[\"i\"].to_list()))\n",
    "_list_s :list[int] = list(set(DF_pis_time_sorted[\"s\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# small, medium, large を異なるプロセス数で表す。\n",
    "\n",
    "small, medium, largeはそれぞれ予測対象環境のプロセス数3通りに小さい順にそれぞれ対応\n",
    "\n",
    "他の説明変数は予測対象環境の最大値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_MAPE_ex_perCall_EP :dict[str, float] = {\n",
    "    \"small\" : ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == test_ep_process[0])&(ep_ex_MAPE[\"size\"] == test_ep_size[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == test_ep_process[1])&(ep_ex_MAPE[\"size\"] == test_ep_size[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == test_ep_process[2])&(ep_ex_MAPE[\"size\"] == test_ep_size[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_ex_perCall_FT :dict[str, float] = {\n",
    "    \"small\" : ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == test_ep_process[0])&(ft_ex_MAPE[\"grid_size\"] == test_ft_grid_size[-1])&(ft_ex_MAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == test_ep_process[1])&(ft_ex_MAPE[\"grid_size\"] == test_ft_grid_size[-1])&(ft_ex_MAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == test_ep_process[2])&(ft_ex_MAPE[\"grid_size\"] == test_ft_grid_size[-1])&(ft_ex_MAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_ex_perCall_IS :dict[str, float] = {\n",
    "    \"small\" : is_ex_MAPE[(is_ex_MAPE[\"process\"] == test_is_process[0]) &(is_ex_MAPE[\"no_of_keys\"] == test_is_no_of_keys[-1]) &(is_ex_MAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": is_ex_MAPE[(is_ex_MAPE[\"process\"] == test_is_process[1]) &(is_ex_MAPE[\"no_of_keys\"] == test_is_no_of_keys[-1]) &(is_ex_MAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : is_ex_MAPE[(is_ex_MAPE[\"process\"] == test_is_process[2]) &(is_ex_MAPE[\"no_of_keys\"] == test_is_no_of_keys[-1]) &(is_ex_MAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_ex_perCall_MG :dict[str, float] = {\n",
    "    \"small\" : mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == test_mg_process[0]) &(mg_ex_MAPE[\"problem_size\"] == test_mg_size[-1]) &(mg_ex_MAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == test_mg_process[1]) &(mg_ex_MAPE[\"problem_size\"] == test_mg_size[-1]) &(mg_ex_MAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == test_mg_process[2]) &(mg_ex_MAPE[\"problem_size\"] == test_mg_size[-1]) &(mg_ex_MAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_ex_perCall_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == test_lulesh_processes[0]) &(lulesh_ex_MAPE[\"size\"] == test_lulesh_sizes[-1]) &(lulesh_ex_MAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == test_lulesh_processes[1]) &(lulesh_ex_MAPE[\"size\"] == test_lulesh_sizes[-1]) &(lulesh_ex_MAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == test_lulesh_processes[2]) &(lulesh_ex_MAPE[\"size\"] == test_lulesh_sizes[-1]) &(lulesh_ex_MAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "}\n",
    "\n",
    "dict_MAPE_ex_perCall :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_MAPE_ex_perCall_EP,\n",
    "    \"FT\": dict_MAPE_ex_perCall_FT,\n",
    "    \"IS\": dict_MAPE_ex_perCall_IS,\n",
    "    \"MG\": dict_MAPE_ex_perCall_MG,\n",
    "    \"LULESH\": dict_MAPE_ex_perCall_LULESH\n",
    "}\n",
    "\n",
    "dict_weightedMAPE_ex_perCall_EP :dict[str, float] = {\n",
    "    \"small\" : ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == test_ep_process[0])&(ep_ex_重み付きMAPE[\"size\"] == test_ep_size[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == test_ep_process[1])&(ep_ex_重み付きMAPE[\"size\"] == test_ep_size[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == test_ep_process[2])&(ep_ex_重み付きMAPE[\"size\"] == test_ep_size[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall_FT :dict[str, float] = {\n",
    "    \"small\" : ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == test_ft_process[0])&(ft_ex_重み付きMAPE[\"grid_size\"] == test_ft_grid_size[-1])&(ft_ex_重み付きMAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == test_ft_process[1])&(ft_ex_重み付きMAPE[\"grid_size\"] == test_ft_grid_size[-1])&(ft_ex_重み付きMAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == test_ft_process[2])&(ft_ex_重み付きMAPE[\"grid_size\"] == test_ft_grid_size[-1])&(ft_ex_重み付きMAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall_IS :dict[str, float] = {\n",
    "    \"small\" : is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == test_is_process[0]) &(is_ex_重み付きMAPE[\"no_of_keys\"] == test_is_no_of_keys[-1]) &(is_ex_重み付きMAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == test_is_process[1]) &(is_ex_重み付きMAPE[\"no_of_keys\"] == test_is_no_of_keys[-1]) &(is_ex_重み付きMAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == test_is_process[2]) &(is_ex_重み付きMAPE[\"no_of_keys\"] == test_is_no_of_keys[-1]) &(is_ex_重み付きMAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall_MG :dict[str, float] = {\n",
    "    \"small\" : mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == test_mg_process[0]) &(mg_ex_重み付きMAPE[\"problem_size\"] == test_mg_size[-1]) &(mg_ex_重み付きMAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == test_mg_process[1]) &(mg_ex_重み付きMAPE[\"problem_size\"] == test_mg_size[-1]) &(mg_ex_重み付きMAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == test_mg_process[2]) &(mg_ex_重み付きMAPE[\"problem_size\"] == test_mg_size[-1]) &(mg_ex_重み付きMAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == test_lulesh_processes[0]) &(lulesh_ex_重み付きMAPE[\"size\"] == test_lulesh_sizes[-1]) &(lulesh_ex_重み付きMAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == test_lulesh_processes[1]) &(lulesh_ex_重み付きMAPE[\"size\"] == test_lulesh_sizes[-1]) &(lulesh_ex_重み付きMAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == test_lulesh_processes[2]) &(lulesh_ex_重み付きMAPE[\"size\"] == test_lulesh_sizes[-1]) &(lulesh_ex_重み付きMAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_weightedMAPE_ex_perCall_EP,\n",
    "    \"FT\": dict_weightedMAPE_ex_perCall_FT,\n",
    "    \"IS\": dict_weightedMAPE_ex_perCall_IS,\n",
    "    \"MG\": dict_weightedMAPE_ex_perCall_MG,\n",
    "    \"LULESH\": dict_weightedMAPE_ex_perCall_LULESH\n",
    "}\n",
    "\n",
    "DF_to_plot_MAPE_ex_perCall_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "DF_to_plot_weightedMAPE_ex_perCall_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "\n",
    "for benchmarkName in DF_to_plot_MAPE_ex_perCall_chart.index.tolist():\n",
    "    for columnName in DF_to_plot_MAPE_ex_perCall_chart.columns.tolist():\n",
    "        DF_to_plot_MAPE_ex_perCall_chart.loc[benchmarkName, columnName] = dict_MAPE_ex_perCall[benchmarkName][columnName]\n",
    "        DF_to_plot_weightedMAPE_ex_perCall_chart.loc[benchmarkName, columnName] = dict_weightedMAPE_ex_perCall[benchmarkName][columnName]\n",
    "\n",
    "dict_MAPE_in_perCall_EP :dict[str, float] = {\n",
    "    \"small\" : ep_in_MAPE[(ep_in_MAPE[\"process\"] == test_ep_process[0])&(ep_in_MAPE[\"size\"] == test_ep_size[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"medium\": ep_in_MAPE[(ep_in_MAPE[\"process\"] == test_ep_process[1])&(ep_in_MAPE[\"size\"] == test_ep_size[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"large\" : ep_in_MAPE[(ep_in_MAPE[\"process\"] == test_ep_process[2])&(ep_in_MAPE[\"size\"] == test_ep_size[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_in_perCall_FT :dict[str, float] = {\n",
    "    \"small\" : ft_in_MAPE[(ft_in_MAPE[\"process\"] == test_ep_process[0])&(ft_in_MAPE[\"grid_size\"] == test_ft_grid_size[-1])&(ft_in_MAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"medium\": ft_in_MAPE[(ft_in_MAPE[\"process\"] == test_ep_process[1])&(ft_in_MAPE[\"grid_size\"] == test_ft_grid_size[-1])&(ft_in_MAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"large\" : ft_in_MAPE[(ft_in_MAPE[\"process\"] == test_ep_process[2])&(ft_in_MAPE[\"grid_size\"] == test_ft_grid_size[-1])&(ft_in_MAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_in_perCall_IS :dict[str, float] = {\n",
    "    \"small\" : is_in_MAPE[(is_in_MAPE[\"process\"] == test_is_process[0]) &(is_in_MAPE[\"no_of_keys\"] == test_is_no_of_keys[-1]) &(is_in_MAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"medium\": is_in_MAPE[(is_in_MAPE[\"process\"] == test_is_process[1]) &(is_in_MAPE[\"no_of_keys\"] == test_is_no_of_keys[-1]) &(is_in_MAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"large\" : is_in_MAPE[(is_in_MAPE[\"process\"] == test_is_process[2]) &(is_in_MAPE[\"no_of_keys\"] == test_is_no_of_keys[-1]) &(is_in_MAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_in_perCall_MG :dict[str, float] = {\n",
    "    \"small\" : mg_in_MAPE[(mg_in_MAPE[\"process\"] == test_mg_process[0]) &(mg_in_MAPE[\"problem_size\"] == test_mg_size[-1]) &(mg_in_MAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"medium\": mg_in_MAPE[(mg_in_MAPE[\"process\"] == test_mg_process[1]) &(mg_in_MAPE[\"problem_size\"] == test_mg_size[-1]) &(mg_in_MAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"large\" : mg_in_MAPE[(mg_in_MAPE[\"process\"] == test_mg_process[2]) &(mg_in_MAPE[\"problem_size\"] == test_mg_size[-1]) &(mg_in_MAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_in_perCall_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_in_MAPE[(lulesh_in_MAPE[\"process\"] == test_lulesh_processes[0]) &(lulesh_in_MAPE[\"size\"] == test_lulesh_sizes[-1]) &(lulesh_in_MAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"medium\": lulesh_in_MAPE[(lulesh_in_MAPE[\"process\"] == test_lulesh_processes[1]) &(lulesh_in_MAPE[\"size\"] == test_lulesh_sizes[-1]) &(lulesh_in_MAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "    \"large\" : lulesh_in_MAPE[(lulesh_in_MAPE[\"process\"] == test_lulesh_processes[2]) &(lulesh_in_MAPE[\"size\"] == test_lulesh_sizes[-1]) &(lulesh_in_MAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"MAPE_InclusivePerCall\"],\n",
    "}\n",
    "\n",
    "dict_MAPE_in_perCall :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_MAPE_in_perCall_EP,\n",
    "    \"FT\": dict_MAPE_in_perCall_FT,\n",
    "    \"IS\": dict_MAPE_in_perCall_IS,\n",
    "    \"MG\": dict_MAPE_in_perCall_MG,\n",
    "    \"LULESH\": dict_MAPE_in_perCall_LULESH\n",
    "}\n",
    "\n",
    "dict_weightedMAPE_in_perCall_EP :dict[str, float] = {\n",
    "    \"small\" : ep_in_重み付きMAPE[(ep_in_重み付きMAPE[\"process\"] == test_ep_process[0])&(ep_in_重み付きMAPE[\"size\"] == test_ep_size[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"medium\": ep_in_重み付きMAPE[(ep_in_重み付きMAPE[\"process\"] == test_ep_process[1])&(ep_in_重み付きMAPE[\"size\"] == test_ep_size[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"large\" : ep_in_重み付きMAPE[(ep_in_重み付きMAPE[\"process\"] == test_ep_process[2])&(ep_in_重み付きMAPE[\"size\"] == test_ep_size[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_in_perCall_FT :dict[str, float] = {\n",
    "    \"small\" : ft_in_重み付きMAPE[(ft_in_重み付きMAPE[\"process\"] == test_ft_process[0])&(ft_in_重み付きMAPE[\"grid_size\"] == test_ft_grid_size[-1])&(ft_in_重み付きMAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"medium\": ft_in_重み付きMAPE[(ft_in_重み付きMAPE[\"process\"] == test_ft_process[1])&(ft_in_重み付きMAPE[\"grid_size\"] == test_ft_grid_size[-1])&(ft_in_重み付きMAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"large\" : ft_in_重み付きMAPE[(ft_in_重み付きMAPE[\"process\"] == test_ft_process[2])&(ft_in_重み付きMAPE[\"grid_size\"] == test_ft_grid_size[-1])&(ft_in_重み付きMAPE[\"nit\"] == test_ft_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_in_perCall_IS :dict[str, float] = {\n",
    "    \"small\" : is_in_重み付きMAPE[(is_in_重み付きMAPE[\"process\"] == test_is_process[0]) &(is_in_重み付きMAPE[\"no_of_keys\"] == test_is_no_of_keys[-1]) &(is_in_重み付きMAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"medium\": is_in_重み付きMAPE[(is_in_重み付きMAPE[\"process\"] == test_is_process[1]) &(is_in_重み付きMAPE[\"no_of_keys\"] == test_is_no_of_keys[-1]) &(is_in_重み付きMAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"large\" : is_in_重み付きMAPE[(is_in_重み付きMAPE[\"process\"] == test_is_process[2]) &(is_in_重み付きMAPE[\"no_of_keys\"] == test_is_no_of_keys[-1]) &(is_in_重み付きMAPE[\"key_max_value\"] == test_is_max_value[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_in_perCall_MG :dict[str, float] = {\n",
    "    \"small\" : mg_in_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == test_mg_process[0]) &(mg_in_重み付きMAPE[\"problem_size\"] == test_mg_size[-1]) &(mg_in_重み付きMAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"medium\": mg_in_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == test_mg_process[1]) &(mg_in_重み付きMAPE[\"problem_size\"] == test_mg_size[-1]) &(mg_in_重み付きMAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"large\" : mg_in_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == test_mg_process[2]) &(mg_in_重み付きMAPE[\"problem_size\"] == test_mg_size[-1]) &(mg_in_重み付きMAPE[\"nit\"] == test_mg_nit[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_in_perCall_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_in_重み付きMAPE[(lulesh_in_重み付きMAPE[\"process\"] == test_lulesh_processes[0]) &(lulesh_in_重み付きMAPE[\"size\"] == test_lulesh_sizes[-1]) &(lulesh_in_重み付きMAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"medium\": lulesh_in_重み付きMAPE[(lulesh_in_重み付きMAPE[\"process\"] == test_lulesh_processes[1]) &(lulesh_in_重み付きMAPE[\"size\"] == test_lulesh_sizes[-1]) &(lulesh_in_重み付きMAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "    \"large\" : lulesh_in_重み付きMAPE[(lulesh_in_重み付きMAPE[\"process\"] == test_lulesh_processes[2]) &(lulesh_in_重み付きMAPE[\"size\"] == test_lulesh_sizes[-1]) &(lulesh_in_重み付きMAPE[\"iteration\"] == test_lulesh_iterations[-1])].reset_index().iloc[0,:][\"weightedMAPE_InclusivePerCall\"],\n",
    "}\n",
    "dict_weightedMAPE_in_perCall :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_weightedMAPE_in_perCall_EP,\n",
    "    \"FT\": dict_weightedMAPE_in_perCall_FT,\n",
    "    \"IS\": dict_weightedMAPE_in_perCall_IS,\n",
    "    \"MG\": dict_weightedMAPE_in_perCall_MG,\n",
    "    \"LULESH\": dict_weightedMAPE_in_perCall_LULESH\n",
    "}\n",
    "\n",
    "DF_to_plot_MAPE_in_perCall_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "DF_to_plot_weightedMAPE_in_perCall_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "\n",
    "for benchmarkName in DF_to_plot_MAPE_in_perCall_chart.index.tolist():\n",
    "    for columnName in DF_to_plot_MAPE_in_perCall_chart.columns.tolist():\n",
    "        DF_to_plot_MAPE_in_perCall_chart.loc[benchmarkName, columnName] = dict_MAPE_in_perCall[benchmarkName][columnName]\n",
    "        DF_to_plot_weightedMAPE_in_perCall_chart.loc[benchmarkName, columnName] = dict_weightedMAPE_in_perCall[benchmarkName][columnName]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_chart_process.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    DF_to_plot_MAPE_call_chart.to_excel(writer, sheet_name=\"コール回数（MAPE）\")\n",
    "    DF_to_plot_weightedMAPE_call_chart.to_excel(writer, sheet_name=\"コール回数（重み付きMAPE）\")\n",
    "    DF_to_plot_MAPE_ex_perCall_chart.to_excel(writer, sheet_name=\"Exclusive（MAPE）\")\n",
    "    DF_to_plot_weightedMAPE_ex_perCall_chart.to_excel(writer, sheet_name=\"Exclusive（重み付きMAPE）\")\n",
    "    DF_to_plot_MAPE_in_perCall_chart.to_excel(writer, sheet_name=\"Inclusive（MAPE）\")\n",
    "    DF_to_plot_weightedMAPE_in_perCall_chart.to_excel(writer, sheet_name=\"Inclusive（重み付きMAPE）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_chart_process_inclusive.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    DF_to_plot_MAPE_call_chart.to_excel(writer, sheet_name=\"コール回数（MAPE）\")\n",
    "    DF_to_plot_weightedMAPE_call_chart.to_excel(writer, sheet_name=\"コール回数（重み付きMAPE）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_worst_weightedMAPE_Call = {'EP': 0.00331432542361967, 'FT': 2.23253321233814, 'IS': 1.16733959401426e-5, 'MG': 0.119897177704057, 'LULESH': 1.29386264501382e-6}\n",
      "{'EP': 4.59032849608456e-31, 'FT': 3.15597766051700e+23, 'IS': 1.13013035064582e-111, 'MG': 3.72865923689435e-13, 'LULESH': 2.34063976778258e-144}\n",
      "float_weightedMAPE_ExclusivePerCall_geometric_mean = 1.36219536733643e-32040\n"
     ]
    }
   ],
   "source": [
    "ep_ex_重み付きMAPE\n",
    "ft_ex_重み付きMAPE\n",
    "is_ex_重み付きMAPE\n",
    "mg_ex_重み付きMAPE\n",
    "lulesh_ex_重み付きMAPE\n",
    "\n",
    "# callのweightedMAPEの最悪値の算出\n",
    "series_ep_worst_weightedMAPE_Call :pd.Series = ep_ex_重み付きMAPE.loc[ep_ex_重み付きMAPE[\"weightedMAPE_#Call\"].astype(float).idxmax()]\n",
    "series_ft_worst_weightedMAPE_Call :pd.Series = ft_ex_重み付きMAPE.loc[ft_ex_重み付きMAPE[\"weightedMAPE_#Call\"].astype(float).idxmax()]\n",
    "series_is_worst_weightedMAPE_Call :pd.Series = is_ex_重み付きMAPE.loc[is_ex_重み付きMAPE[\"weightedMAPE_#Call\"].astype(float).idxmax()]\n",
    "series_mg_worst_weightedMAPE_Call :pd.Series = mg_ex_重み付きMAPE.loc[mg_ex_重み付きMAPE[\"weightedMAPE_#Call\"].astype(float).idxmax()]\n",
    "series_lulesh_worst_weightedMAPE_Call :pd.Series = lulesh_ex_重み付きMAPE.loc[lulesh_ex_重み付きMAPE[\"weightedMAPE_#Call\"].astype(float).idxmax()]\n",
    "\n",
    "dict_worst_weightedMAPE_Call :dict[str, float] = {\n",
    "    \"EP\": series_ep_worst_weightedMAPE_Call[\"weightedMAPE_#Call\"],\n",
    "    \"FT\": series_ft_worst_weightedMAPE_Call[\"weightedMAPE_#Call\"],\n",
    "    \"IS\": series_is_worst_weightedMAPE_Call[\"weightedMAPE_#Call\"],\n",
    "    \"MG\": series_mg_worst_weightedMAPE_Call[\"weightedMAPE_#Call\"],\n",
    "    \"LULESH\": series_lulesh_worst_weightedMAPE_Call[\"weightedMAPE_#Call\"],\n",
    "}\n",
    "\n",
    "print(f\"{dict_worst_weightedMAPE_Call = }\")\n",
    "\n",
    "float_ep_weightedMAPE_ExclusivePerCall_prod :float = math.prod(ep_ex_重み付きMAPE[\"weightedMAPE_ExclusivePerCall\"])\n",
    "float_ft_weightedMAPE_ExclusivePerCall_prod :float = math.prod(ft_ex_重み付きMAPE[\"weightedMAPE_ExclusivePerCall\"])\n",
    "float_is_weightedMAPE_ExclusivePerCall_prod :float = math.prod(is_ex_重み付きMAPE[\"weightedMAPE_ExclusivePerCall\"])\n",
    "float_mg_weightedMAPE_ExclusivePerCall_prod :float = math.prod(mg_ex_重み付きMAPE[\"weightedMAPE_ExclusivePerCall\"])\n",
    "float_lulesh_weightedMAPE_ExclusivePerCall_prod :float = math.prod(lulesh_ex_重み付きMAPE[\"weightedMAPE_ExclusivePerCall\"])\n",
    "\n",
    "dict_weightedMAPE_ExclusivePerCall_prod :dict[str, float] = {\n",
    "    \"EP\" : float_ep_weightedMAPE_ExclusivePerCall_prod,\n",
    "    \"FT\" : float_ft_weightedMAPE_ExclusivePerCall_prod,\n",
    "    \"IS\" : float_is_weightedMAPE_ExclusivePerCall_prod,\n",
    "    \"MG\" : float_mg_weightedMAPE_ExclusivePerCall_prod,\n",
    "    \"LULESH\" : float_lulesh_weightedMAPE_ExclusivePerCall_prod,\n",
    "}\n",
    "\n",
    "float_weightedMAPE_ExclusivePerCall_prod :float = math.prod(dict_weightedMAPE_ExclusivePerCall_prod.values())\n",
    "\n",
    "print(f\"{dict_weightedMAPE_ExclusivePerCall_prod}\")\n",
    "\n",
    "float_weightedMAPE_ExclusivePerCall_geometric_mean :float = np.power(\n",
    "    float_weightedMAPE_ExclusivePerCall_prod,\n",
    "    sum([\n",
    "        len(ep_ex_重み付きMAPE),\n",
    "        len(ft_ex_重み付きMAPE),\n",
    "        len(is_ex_重み付きMAPE),\n",
    "        len(mg_ex_重み付きMAPE),\n",
    "        len(lulesh_ex_重み付きMAPE),\n",
    "    ])\n",
    ")\n",
    "\n",
    "print(f\"{float_weightedMAPE_ExclusivePerCall_geometric_mean = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23253321233814\n"
     ]
    }
   ],
   "source": [
    "float_worst_weightedMAPE_Call = -1\n",
    "for benchmarkName in dict_weightedMAPE_call.keys():\n",
    "    for scale in dict_weightedMAPE_call[benchmarkName]:\n",
    "        _elem_weightedMAPE_call :float = dict_weightedMAPE_call[benchmarkName][scale]\n",
    "        if _elem_weightedMAPE_call > float_worst_weightedMAPE_Call:\n",
    "            float_worst_weightedMAPE_Call = _elem_weightedMAPE_call\n",
    "print(f\"{float_worst_weightedMAPE_Call}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float_weightedMAPE_ExclusivePerCall_prod = 1.79322666736374e-51\n",
      "int_num_elems = 15\n",
      "6.37569936658214E-762\n"
     ]
    }
   ],
   "source": [
    "float_weightedMAPE_ExclusivePerCall_prod :float = 1\n",
    "int_num_elems :int = 0\n",
    "for benchmarkName in dict_weightedMAPE_call.keys():\n",
    "    for scale in dict_weightedMAPE_call[benchmarkName]:\n",
    "        _elem_weightedMAPE_call :float = dict_weightedMAPE_call[benchmarkName][scale]\n",
    "        float_weightedMAPE_ExclusivePerCall_prod = float_weightedMAPE_ExclusivePerCall_prod * _elem_weightedMAPE_call\n",
    "        int_num_elems += 1\n",
    "print(f\"{float_weightedMAPE_ExclusivePerCall_prod = }\")\n",
    "\n",
    "float_weightedMAPE_ExclusivePerCall_geometric_mean :float = np.power(float_weightedMAPE_ExclusivePerCall_prod, int_num_elems)\n",
    "print(f\"{int_num_elems = }\")\n",
    "print(f\"{float_weightedMAPE_ExclusivePerCall_geometric_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_whole_weightedMAPE :list[float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_small = DF_to_plot_weightedMAPE_ex_perCall_chart[\"small\"].tolist()\n",
    "list_medium = DF_to_plot_weightedMAPE_ex_perCall_chart[\"medium\"].tolist()\n",
    "list_large = DF_to_plot_weightedMAPE_ex_perCall_chart[\"large\"].tolist()\n",
    "list_whole_weightedMAPE = list_small + list_medium + list_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_small = DF_to_plot_MAPE_ex_perCall_chart[\"small\"].tolist()\n",
    "list_medium = DF_to_plot_MAPE_ex_perCall_chart[\"medium\"].tolist()\n",
    "list_large = DF_to_plot_MAPE_ex_perCall_chart[\"large\"].tolist()\n",
    "list_whole_weightedMAPE = list_whole_weightedMAPE + list_small + list_medium + list_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_whole_weightedMAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.41930127897056$"
      ],
      "text/plain": [
       "1.41930127897056"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def geo_mean(iterable):\n",
    "    a = np.array(iterable)\n",
    "    return a.prod()**(1.0/len(a))\n",
    "\n",
    "geo_mean(list_whole_weightedMAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process                          298.666667\n",
      "size                              40.000000\n",
      "weightedMAPE_Exclusive             0.027591\n",
      "weightedMAPE_ExclusivePerCall      0.003162\n",
      "weightedMAPE_#Call                 0.000680\n",
      "dtype: float64\n",
      "process                           298.666667\n",
      "grid_size                        2389.333333\n",
      "nit                                40.000000\n",
      "weightedMAPE_Exclusive           7168.501985\n",
      "weightedMAPE_ExclusivePerCall      49.119841\n",
      "weightedMAPE_#Call                  0.563642\n",
      "dtype: float64\n",
      "process                          74.666667\n",
      "no_of_keys                       29.000000\n",
      "key_max_value                    19.000000\n",
      "weightedMAPE_Exclusive            0.000134\n",
      "weightedMAPE_ExclusivePerCall     0.000124\n",
      "weightedMAPE_#Call                0.000004\n",
      "dtype: float64\n",
      "process                          298.666667\n",
      "problem_size                     298.666667\n",
      "nit                               40.000000\n",
      "weightedMAPE_Exclusive             0.337219\n",
      "weightedMAPE_ExclusivePerCall      0.390495\n",
      "weightedMAPE_#Call                 0.073626\n",
      "dtype: float64\n",
      "process                          7.470000e+02\n",
      "iteration                        5.973333e+02\n",
      "size                             9.600000e+01\n",
      "weightedMAPE_Exclusive           5.303529e-06\n",
      "weightedMAPE_ExclusivePerCall    6.286798e-06\n",
      "weightedMAPE_#Call               3.354338e-07\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# EP\n",
    "print(ep_ex_重み付きMAPE.mean())\n",
    "\n",
    "# FT\n",
    "print(ft_ex_重み付きMAPE.mean())\n",
    "\n",
    "# IS\n",
    "print(is_ex_重み付きMAPE.mean())\n",
    "\n",
    "# MG\n",
    "print(mg_ex_重み付きMAPE.mean())\n",
    "\n",
    "# LULESH\n",
    "print(lulesh_ex_重み付きMAPE.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "645e00e4d60457c31a103f31eb5d29e9424124f9b16aaf1029c5753bc573c11c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
