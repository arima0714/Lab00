{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:hello\n",
      "DEBUG:lib.lab_lib:hello\n"
     ]
    }
   ],
   "source": [
    "jupyter_pwd = %pwd\n",
    "if jupyter_pwd == \"/\":\n",
    "    %cd /workspace\n",
    "\n",
    "# %pdb on\n",
    "\n",
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib/lib.ipynb\n",
    "\n",
    "# ipynb形式のライブラリノートを.py形式に変更したものをインポート\n",
    "import lib\n",
    "import lib.lab_lib\n",
    "from lib.lab_lib import *\n",
    "\n",
    "# 生データの入ったCSVファイルの保持されたディレクトリ名を格納している変数\n",
    "csvDirPath = \"./csv_files/\"\n",
    "\n",
    "# NPBのベンチマーク名のリスト\n",
    "benchmarkNames = [\"cg\", \"ep\", \"ft\", \"is\", \"lu\", \"mg\"]\n",
    "\n",
    "# NPBのプロセス数\n",
    "npb_process :list[int] = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "train_npb_process :list[int] = npb_process[:-1]\n",
    "test_npb_process :list[int] = npb_process[-1:]\n",
    "# NPBのCGの初期変数\n",
    "cg_na: list[int] = [14000, 30000, 75000, 100000, 1500000]\n",
    "cg_nonzer: list[int] = [11, 12, 13, 14, 15, 18, 21]\n",
    "cg_niter: list[int] = [15, 30, 75, 90, 100]\n",
    "cg_shift: list[int] = [20, 40, 60, 80, 110, 200]\n",
    "\n",
    "train_cg_na: list[int] = cg_na[:-1]\n",
    "train_cg_nonzer: list[int] = cg_nonzer[:-1]\n",
    "train_cg_niter: list[int] = cg_niter[:-1]\n",
    "train_cg_shift: list[int] = cg_shift[:-1]\n",
    "\n",
    "test_cg_na: list[int] = cg_na[-1:]\n",
    "test_cg_nonzer: list[int] = cg_nonzer[-1:]\n",
    "test_cg_niter: list[int] = cg_niter[-1:]\n",
    "test_cg_shift: list[int] = cg_shift[-1:]\n",
    "\n",
    "# NPBのEPの初期変数\n",
    "train_ep_process :list[int] = [4, 8, 16, 32, 64]\n",
    "train_ep_size :list[str] = [\"S\", \"W\", \"A\", \"B\", \"C\"]\n",
    "test_ep_process :list[int] = [128, 256, 512]\n",
    "test_ep_size :list[str] = [\"D\", \"E\", \"F\"]\n",
    "\n",
    "# NPBのFTの初期変数\n",
    "train_ft_process :list[int] = [2, 4, 8, 16, 32, 64]\n",
    "train_ft_grid_size :list[int] = [32, 64, 128, 256, 512]\n",
    "train_ft_nit :list[int] = [5, 10, 15, 20, 25]\n",
    "\n",
    "test_ft_process :list[int] = [128, 256, 512]\n",
    "test_ft_grid_size :list[int] = [1024, 2048, 4096]\n",
    "test_ft_nit :list[int] = [30, 40, 50]\n",
    "\n",
    "# NPBのISの初期変数\n",
    "train_is_process :list[int] = [2, 4, 8, 16, 32, 64]\n",
    "train_is_no_of_keys :list[int] = [18, 20, 22, 24, 26, 28, 30, 32]\n",
    "train_is_max_value :list[int] = [5, 7, 9, 11, 13, 15, 17]\n",
    "\n",
    "# NPBのMGの初期変数\n",
    "mg_size :list[int] = [32, 64, 128, 256, 512]\n",
    "mg_nit: list[int] = [4, 10, 20, 35, 50]\n",
    "\n",
    "train_mg_process :list[int] = [4, 8, 16, 32, 64]\n",
    "train_mg_size :list[int] = [4, 8, 16, 32, 64]\n",
    "train_mg_nit :list[int] = [5, 10, 15, 20, 25]\n",
    "\n",
    "test_mg_process :list[int] = [128, 256, 512]\n",
    "test_mg_size :list[int] = [128, 256, 512]\n",
    "test_mg_nit :list[int] = [30, 40, 50]\n",
    "\n",
    "# LULESH ベンチマークプログラムのプロセス数・問題サイズ・イテレーション数\n",
    "lulesh_processes: list[int] = [8, 27, 64, 125, 216, 343, 512]\n",
    "lulesh_iterations: list[int] = [8, 16, 32, 64, 128, 256]\n",
    "lulesh_sizes: list[int] = [16, 24, 32, 48, 64, 128]\n",
    "\n",
    "train_lulesh_processes: list[int] = [8, 27, 64, 125, 216, 343]\n",
    "train_lulesh_iterations: list[int] = [8, 16, 32, 64, 128]\n",
    "train_lulesh_sizes: list[int] = [16, 24, 32, 48]\n",
    "\n",
    "test_lulesh_processes: list[int] = [512, 729, 1000]\n",
    "test_lulesh_iterations: list[int] = [256, 512, 1024]\n",
    "test_lulesh_sizes: list[int] = [64, 96, 128]\n",
    "\n",
    "# Extra-Pのオプション\n",
    "modelerNames: list[str] = [\n",
    "    # \"refining\", \n",
    "    \"multi-parameter\",\n",
    "    \"default\", \n",
    "    # \"basic --options poly_exponents=-1,0,1,2,3 log_exponents=0,1 force_combination_exponents=1 allow_negative_exponents=1\"\n",
    "    ]\n",
    "\n",
    "modelerOption: str = \"\"\" --options \\#spm=Basic \\#spo=poly_exponents=-1,0,1,2,3,log_exponents=0,1,force_combination_exponents=1,allow_negative_exponents=True\"\"\"\n",
    "\n",
    "list_csvDir = [\n",
    "    \"./csv_files/lulesh_1st/\",\n",
    "    \"./csv_files/lulesh_2nd/\",\n",
    "    \"./csv_files/lulesh_3rd/\",\n",
    "]\n",
    "\n",
    "list_csvDir_mg = [\n",
    "    \"./csv_files/mg_1st/\",\n",
    "    \"./csv_files/mg_2nd/\",\n",
    "    \"./csv_files/mg_3rd/\",\n",
    "]\n",
    "\n",
    "list_csvDir_ft :list[str] = [\n",
    "    \"./csv_files/ft_1st/\",\n",
    "    \"./csv_files/ft_2nd/\",\n",
    "    \"./csv_files/ft_3rd/\",\n",
    "]\n",
    "\n",
    "list_csvDir_ep :list[str] = [\n",
    "    \"./csv_files/ep_1st/\",\n",
    "    \"./csv_files/ep_2nd/\",\n",
    "    \"./csv_files/ep_3rd/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rawDF_ep(\n",
    "    list_process: list[int],\n",
    "    list_size: list[int],\n",
    "    csvDir: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"return_rawDF_ep()\n",
    "\n",
    "    ベンチマークプログラムEPの手動で変更した初期変数におけるプロファイルを取得する関数\n",
    "\n",
    "    Args:\n",
    "        list_process(list[int]):プロセス数のリスト\n",
    "        list_size(list[int]):初期変数sizeのリスト\n",
    "        csvDir(str):CSVファイルの保持されているディレクトリ\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    list_before_concat_DF: list[pd.DataFrame] = []\n",
    "\n",
    "    for elem_process in list_process:\n",
    "        for elem_size in list_size:\n",
    "            filePath: str = f\"{csvDir}ft_grid_size{elem_size}_process{elem_process}.csv\"\n",
    "            if os.path.isfile(filePath):\n",
    "                try:\n",
    "                    DF_read_raw: pd.DataFrame = pd.read_csv(filePath)\n",
    "                    DF_read_raw[\"process\"] = elem_process\n",
    "                    DF_read_raw[\"size\"] = elem_size\n",
    "                    list_before_concat_DF.append(DF_read_raw)\n",
    "                except:\n",
    "                    warnings.warn(f\"{filePath} is empty.\")\n",
    "            else:\n",
    "                warnings.warn(f\"{filePath} doesn't exist\")\n",
    "                continue\n",
    "    return pd.concat(objs=list_before_concat_DF, axis=0)\n",
    "\n",
    "\n",
    "def ret_averaged_rawDF_ep(\n",
    "    list_process: list[int],\n",
    "    list_size: list[int],\n",
    "    list_csvDir: list[str],\n",
    "    resVar: str,\n",
    "):\n",
    "    \"\"\"複数のCSVからDFを取得する関数（ベンチマークプログラムEP）\n",
    "\n",
    "    列Inclusiveおよび列Exclusiveが秒に変換され、InclusivePerCallもしくはExclusivePerCall列が生成される。\n",
    "\n",
    "    Args:\n",
    "        list_process(list[int]):プロセス数のリスト\n",
    "        list_grid_size(list[int]):グリッドサイズのリスト\n",
    "        list_nit(list[int]):イテレーション数のリスト\n",
    "        list_csvDir(list[str]):CSVを保持したディレクトリ名のリスト\n",
    "        resVar(str):説明変数の文字列\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    list_DFs_for_return: list[pd.DataFrame] = []\n",
    "    for elem_process in list_process:\n",
    "        for elem_size in list_size:\n",
    "            list_inputDFs_for_averaged: list[pd.DataFrame] = []\n",
    "            for elem_csvDir in list_csvDir:\n",
    "                try:\n",
    "                    _raw_DF: pd.DataFrame = return_rawDF_ep(\n",
    "                        list_process=[elem_process],\n",
    "                        list_size=[elem_size],\n",
    "                        csvDir=elem_csvDir,\n",
    "                    )\n",
    "\n",
    "                    if resVar in [\"Exclusive\", \"Inclusive\", \"#Call\", \"#Subrs\"]:\n",
    "                        # resVar 列の整形\n",
    "                        if resVar in [\"Exclusive\", \"Inclusive\"]:\n",
    "                            _tmp_converted = map(\n",
    "                                convertPprofTime, list(_raw_DF[resVar])\n",
    "                            )\n",
    "                            _raw_DF[resVar] = list(_tmp_converted)\n",
    "                        # {resVar}PerCall 列の生成\n",
    "                        _raw_DF = add_perCallColumn(\n",
    "                            inputDF=_raw_DF,\n",
    "                            divisorColName=\"#Call\",\n",
    "                            dividendColName=resVar,\n",
    "                            targetColumnName=f\"{resVar}PerCall\",\n",
    "                        )\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                list_inputDFs_for_averaged.append(_raw_DF)\n",
    "            list_DFs_for_return.append(\n",
    "                ret_averagedDF(inputDFs=list_inputDFs_for_averaged, resVar=resVar)\n",
    "            )\n",
    "    return pd.concat(objs=list_DFs_for_return, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   %Time  Exclusive Inclusive  #Call  #Subrs              Name  process  \\\n",
      "0  100.0   0.000004     6,054    1.0     1.0  .TAU_application        2   \n",
      "1  100.0   0.000088     6,054    1.0    65.0                FT        2   \n",
      "2   90.8   7.144667     5,497    1.0     0.0    MPI_Finalize()        2   \n",
      "3    9.1   0.000169       549    1.0    11.0             SETUP        2   \n",
      "4    9.1   0.511000       548    1.0     0.0        MPI_Init()        2   \n",
      "\n",
      "   grid_size  nit  ExclusivePerCall  \n",
      "0         32    5          0.000004  \n",
      "1         32    5          0.000078  \n",
      "2         32    5          5.497000  \n",
      "3         32    5          0.000172  \n",
      "4         32    5          0.548000  \n",
      "   %Time  Exclusive Inclusive    #Call     #Subrs              Name  process  \\\n",
      "0  100.0   0.000004     5,661      1.0      1.000  .TAU_application      128   \n",
      "1  100.0   0.000337     5,661      1.0    124.016                FT      128   \n",
      "2   70.4   0.000165     3,984     27.0    108.000               FFT      128   \n",
      "3   27.8   0.105000     1,576  10368.0  93312.000             CFFTZ      128   \n",
      "4   26.0   0.980359     1,471  93312.0      0.000             FFTZ2      128   \n",
      "\n",
      "   grid_size  nit  ExclusivePerCall  \n",
      "0       1024   30          0.000004  \n",
      "1       1024   30          0.000335  \n",
      "2       1024   30          0.000006  \n",
      "3       1024   30          0.000010  \n",
      "4       1024   30          0.000016  \n",
      "   %Time  Exclusive Inclusive  #Call  #Subrs              Name  process  \\\n",
      "0  100.0   0.000009     8,752    1.0    1.00  .TAU_application        4   \n",
      "1  100.0   0.000182     8,752    1.0   60.75            MG_MPI        4   \n",
      "2   95.9   8.117667     8,395    1.0    0.00    MPI_Finalize()        4   \n",
      "3    4.1   0.354667       354    1.0    0.00        MPI_Init()        4   \n",
      "4    0.0   0.000106     0.645   34.0  612.00             COMM3        4   \n",
      "\n",
      "   problem_size  nit  ExclusivePerCall  \n",
      "0             4    5          0.000011  \n",
      "1             4    5          0.000170  \n",
      "2             4    5          8.395000  \n",
      "3             4    5          0.354000  \n",
      "4             4    5          0.000002  \n",
      "   %Time  Exclusive Inclusive  #Call   #Subrs              Name  process  \\\n",
      "0  100.0   0.000019     1,373    1.0    1.000  .TAU_application      128   \n",
      "1  100.0   0.000246     1,373    1.0  110.023            MG_MPI      128   \n",
      "2   59.3   0.639000       814    1.0    0.000        MPI_Init()      128   \n",
      "3   37.5   0.517000       514    1.0    0.000    MPI_Finalize()      128   \n",
      "4    2.4   0.000362        33   31.0  961.000              MG3P      128   \n",
      "\n",
      "   problem_size  nit  ExclusivePerCall  \n",
      "0           128   30          0.000017  \n",
      "1           128   30          0.000248  \n",
      "2           128   30          0.814000  \n",
      "3           128   30          0.514000  \n",
      "4           128   30          0.000012  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17048/1906563771.py:34: UserWarning: ./csv_files/ep_1st/ft_grid_sizeS_process4.csv doesn't exist\n",
      "  warnings.warn(f\"{filePath} doesn't exist\")\n",
      "/tmp/ipykernel_17048/1906563771.py:34: UserWarning: ./csv_files/ep_2nd/ft_grid_sizeS_process4.csv doesn't exist\n",
      "  warnings.warn(f\"{filePath} doesn't exist\")\n",
      "/tmp/ipykernel_17048/1906563771.py:34: UserWarning: ./csv_files/ep_3rd/ft_grid_sizeS_process4.csv doesn't exist\n",
      "  warnings.warn(f\"{filePath} doesn't exist\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'warning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m _tmp_DF :pd\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m ret_averaged_rawDF_mg(list_process\u001b[39m=\u001b[39mtest_mg_process, list_size\u001b[39m=\u001b[39mtest_mg_size, list_nit\u001b[39m=\u001b[39mtest_mg_nit, list_csvDir\u001b[39m=\u001b[39mlist_csvDir_mg, resVar\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExclusive\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(_tmp_DF\u001b[39m.\u001b[39mhead())\n\u001b[0;32m---> 13\u001b[0m trainDF_EP :pd\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m ret_averaged_rawDF_ep(list_process\u001b[39m=\u001b[39;49mtrain_ep_process, list_size\u001b[39m=\u001b[39;49mtrain_ep_size, list_csvDir\u001b[39m=\u001b[39;49mlist_csvDir_ep, resVar\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mExclusive\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(trainDF_EP\u001b[39m.\u001b[39mhead())\n\u001b[1;32m     16\u001b[0m trainDF_EP :pd\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m ret_averaged_rawDF_ep(list_process\u001b[39m=\u001b[39mtest_ep_process, list_size\u001b[39m=\u001b[39mtest_ep_size, list_csvDir\u001b[39m=\u001b[39mlist_csvDir_ep, resVar\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExclusive\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [2], line 89\u001b[0m, in \u001b[0;36mret_averaged_rawDF_ep\u001b[0;34m(list_process, list_size, list_csvDir, resVar)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     87\u001b[0m             list_inputDFs_for_averaged\u001b[39m.\u001b[39mappend(_raw_DF)\n\u001b[1;32m     88\u001b[0m         list_DFs_for_return\u001b[39m.\u001b[39mappend(\n\u001b[0;32m---> 89\u001b[0m             ret_averagedDF(inputDFs\u001b[39m=\u001b[39;49mlist_inputDFs_for_averaged, resVar\u001b[39m=\u001b[39;49mresVar)\n\u001b[1;32m     90\u001b[0m         )\n\u001b[1;32m     91\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mconcat(objs\u001b[39m=\u001b[39mlist_DFs_for_return, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/workspace/lib/lab_lib.py:9884\u001b[0m, in \u001b[0;36mret_averagedDF\u001b[0;34m(inputDFs, resVar)\u001b[0m\n\u001b[1;32m   9873\u001b[0m \u001b[39m\"\"\"入力されたDFのリストをまとめる。まとめる対象はresVarで指定したカラム名\u001b[39;00m\n\u001b[1;32m   9874\u001b[0m \n\u001b[1;32m   9875\u001b[0m \u001b[39mArgs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9880\u001b[0m \u001b[39m    pd.DataFrame:概要通りの処理がなされたDF\u001b[39;00m\n\u001b[1;32m   9881\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   9883\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputDFs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 9884\u001b[0m     warning\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mlen(inputDFs) == 0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   9885\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   9887\u001b[0m set_index_size \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warning' is not defined"
     ]
    }
   ],
   "source": [
    "_tmp_DF :pd.DataFrame = ret_averaged_rawDF_ft(list_process=train_ft_process, list_grid_size=train_ft_grid_size, list_nit=train_ft_nit, list_csvDir=list_csvDir_ft, resVar=\"Exclusive\")\n",
    "print(_tmp_DF.head())\n",
    "\n",
    "_tmp_DF :pd.DataFrame = ret_averaged_rawDF_ft(list_process=test_ft_process, list_grid_size=test_ft_grid_size, list_nit=test_ft_nit, list_csvDir=list_csvDir_ft, resVar=\"Exclusive\")\n",
    "print(_tmp_DF.head())\n",
    "\n",
    "_tmp_DF :pd.DataFrame = ret_averaged_rawDF_mg(list_process=train_mg_process, list_size=train_mg_size, list_nit=train_mg_nit, list_csvDir=list_csvDir_mg, resVar=\"Exclusive\")\n",
    "print(_tmp_DF.head())\n",
    "\n",
    "_tmp_DF :pd.DataFrame = ret_averaged_rawDF_mg(list_process=test_mg_process, list_size=test_mg_size, list_nit=test_mg_nit, list_csvDir=list_csvDir_mg, resVar=\"Exclusive\")\n",
    "print(_tmp_DF.head())\n",
    "\n",
    "trainDF_EP :pd.DataFrame = ret_averaged_rawDF_ep(list_process=train_ep_process, list_size=train_ep_size, list_csvDir=list_csvDir_ep, resVar=\"Exclusive\")\n",
    "print(trainDF_EP.head())\n",
    "\n",
    "trainDF_EP :pd.DataFrame = ret_averaged_rawDF_ep(list_process=test_ep_process, list_size=test_ep_size, list_csvDir=list_csvDir_ep, resVar=\"Exclusive\")\n",
    "print(trainDF_EP.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 必要な結果\n",
    "\n",
    "* 関数コール回数予測\n",
    "    * モデル適合度\n",
    "    * モデル予測精度\n",
    "* 実行時間予測\n",
    "    * モデル適合度\n",
    "    * モデル予測精度\n",
    "\n",
    "# 必要なブツ\n",
    "\n",
    "* モデル構築用データ\n",
    "* 予測対象用データ\n",
    "* 関数コール回数の予測モデル\n",
    "* 関数の総実行時間の予測モデル\n",
    "* 1コール当たりの関数の総実行時間の予測モデル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentsForExtraP:\n",
    "    \"\"\"class ContentsForExtraP\n",
    "\n",
    "    ExtraPによるモデルの生成\n",
    "\n",
    "    生成されるモデルは次の通り。\n",
    "\n",
    "    * 関数コール回数の予測モデル\n",
    "    * 関数の総実行時間の予測モデル\n",
    "    * 1コール当たりの関数の総実行時間の予測モデル\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        trainDF: pd.DataFrame,\n",
    "        testDF: pd.DataFrame,\n",
    "        expVars: list[str],\n",
    "        resVars: list[str],\n",
    "        resVarsPerCall: list[str],\n",
    "    ):\n",
    "        \"\"\"__init__()\n",
    "\n",
    "        初期化変数\n",
    "\n",
    "        Args:\n",
    "            trainDF(pd.DataFrame):モデル構築用データ\n",
    "            testDF(pd.DataFrame):予測対象用データ\n",
    "            expVars(list[str]):説明変数を格納したリスト\n",
    "            resVars(list[str]):目的変数を格納したリスト\n",
    "            resVarsPerCall(list[str]):1コール当たりの目的変数を格納したリスト\n",
    "\n",
    "        \"\"\"\n",
    "        self.trainDF = trainDF\n",
    "        self.testDF = testDF\n",
    "        self.expVars = expVars\n",
    "        self.resVars = resVars\n",
    "        self.resVarsPerCall = resVarsPerCall\n",
    "\n",
    "    def _build_model(self, resVar: str):\n",
    "        \"\"\"_build_model()\n",
    "\n",
    "        引数から指定した条件でモデルを構築する。\n",
    "\n",
    "        Args:\n",
    "            resVar(str):目的変数\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def build_all_models(self):\n",
    "        \"\"\"build_all_models()\n",
    "\n",
    "        モデルを構築する関数。目的変数はself.resVars, self.resVarsPerCallを利用。\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def return_models(self):\n",
    "        \"\"\"return_models()\n",
    "\n",
    "        構築した各種モデルを返す関数。\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
