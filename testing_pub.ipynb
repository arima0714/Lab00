{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:hello\n",
      "DEBUG:lib.lab_lib:hello\n"
     ]
    }
   ],
   "source": [
    "jupyter_pwd = %pwd\n",
    "if jupyter_pwd == \"/\":\n",
    "    %cd /workspace\n",
    "\n",
    "# %pdb on\n",
    "\n",
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib/lib.ipynb\n",
    "\n",
    "# ipynb形式のライブラリノートを.py形式に変更したものをインポート\n",
    "import lib\n",
    "import lib.lab_lib\n",
    "from lib.lab_lib import *\n",
    "\n",
    "# 生データの入ったCSVファイルの保持されたディレクトリ名を格納している変数\n",
    "csvDirPath = \"./csv_files/\"\n",
    "\n",
    "# NPBのベンチマーク名のリスト\n",
    "benchmarkNames = [\"cg\", \"ep\", \"ft\", \"is\", \"lu\", \"mg\"]\n",
    "\n",
    "# NPBのプロセス数\n",
    "npb_process :list[int] = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "train_npb_process :list[int] = npb_process[:-1]\n",
    "test_npb_process :list[int] = npb_process[-1:]\n",
    "# NPBのCGの初期変数\n",
    "cg_na: list[int] = [14000, 30000, 75000, 100000, 1500000]\n",
    "cg_nonzer: list[int] = [11, 12, 13, 14, 15, 18, 21]\n",
    "cg_niter: list[int] = [15, 30, 75, 90, 100]\n",
    "cg_shift: list[int] = [20, 40, 60, 80, 110, 200]\n",
    "\n",
    "train_cg_na: list[int] = cg_na[:-1]\n",
    "train_cg_nonzer: list[int] = cg_nonzer[:-1]\n",
    "train_cg_niter: list[int] = cg_niter[:-1]\n",
    "train_cg_shift: list[int] = cg_shift[:-1]\n",
    "\n",
    "test_cg_na: list[int] = cg_na[-1:]\n",
    "test_cg_nonzer: list[int] = cg_nonzer[-1:]\n",
    "test_cg_niter: list[int] = cg_niter[-1:]\n",
    "test_cg_shift: list[int] = cg_shift[-1:]\n",
    "\n",
    "# NPBのEPの初期変数\n",
    "train_ep_process :list[int] = [4, 8, 16, 32, 64]\n",
    "train_ep_size :list[int] = [24, 25, 28, 30, 32]\n",
    "test_ep_process :list[int] = [128, 256, 512]\n",
    "test_ep_size :list[int] = [36, 40, 44]\n",
    "\n",
    "# NPBのFTの初期変数\n",
    "train_ft_process :list[int] = [2, 4, 8, 16, 32, 64]\n",
    "train_ft_grid_size :list[int] = [32, 64, 128, 256, 512]\n",
    "train_ft_nit :list[int] = [5, 10, 15, 20, 25]\n",
    "\n",
    "test_ft_process :list[int] = [128, 256, 512]\n",
    "test_ft_grid_size :list[int] = [1024, 2048, 4096]\n",
    "test_ft_nit :list[int] = [30, 40, 50]\n",
    "\n",
    "# NPBのISの初期変数\n",
    "train_is_process :list[int] = [2, 4, 8, 16]\n",
    "train_is_no_of_keys :list[int] = [18, 20, 22, 24, 26]\n",
    "train_is_max_value :list[int] = [9, 11, 13, 15]\n",
    "\n",
    "test_is_process :list[int] = [32, 64, 128]\n",
    "test_is_no_of_keys :list[int] = [28, 29, 30]\n",
    "test_is_max_value :list[int] = [18, 19, 20]\n",
    "\n",
    "# NPBのMGの初期変数\n",
    "mg_size :list[int] = [32, 64, 128, 256, 512]\n",
    "mg_nit: list[int] = [4, 10, 20, 35, 50]\n",
    "\n",
    "train_mg_process :list[int] = [4, 8, 16, 32, 64]\n",
    "train_mg_size :list[int] = [4, 8, 16, 32, 64]\n",
    "train_mg_nit :list[int] = [5, 10, 15, 20, 25]\n",
    "\n",
    "test_mg_process :list[int] = [128, 256, 512]\n",
    "test_mg_size :list[int] = [128, 256, 512]\n",
    "test_mg_nit :list[int] = [30, 40, 50]\n",
    "\n",
    "# LULESH ベンチマークプログラムのプロセス数・問題サイズ・イテレーション数\n",
    "lulesh_processes: list[int] = [8, 27, 64, 125, 216, 343, 512]\n",
    "lulesh_iterations: list[int] = [8, 16, 32, 64, 128, 256]\n",
    "lulesh_sizes: list[int] = [16, 24, 32, 48, 64, 128]\n",
    "\n",
    "train_lulesh_processes: list[int] = [8, 27, 64, 125, 216, 343]\n",
    "train_lulesh_iterations: list[int] = [8, 16, 32, 64, 128]\n",
    "train_lulesh_sizes: list[int] = [16, 24, 32, 48]\n",
    "\n",
    "test_lulesh_processes: list[int] = [512, 729, 1000]\n",
    "test_lulesh_iterations: list[int] = [256, 512, 1024]\n",
    "test_lulesh_sizes: list[int] = [64, 96, 128]\n",
    "\n",
    "# Extra-Pのオプション\n",
    "modelerNames: list[str] = [\n",
    "    # \"refining\", \n",
    "    \"multi-parameter\",\n",
    "    \"default\", \n",
    "    # \"basic --options poly_exponents=-1,0,1,2,3 log_exponents=0,1 force_combination_exponents=1 allow_negative_exponents=1\"\n",
    "    ]\n",
    "\n",
    "modelerOption: str = \"\"\" --options \\#spm=Basic \\#spo=poly_exponents=-1,0,1,2,3,log_exponents=0,1,force_combination_exponents=1,allow_negative_exponents=True\"\"\"\n",
    "\n",
    "list_csvDir = [\n",
    "    \"./csv_files/lulesh_1st/\",\n",
    "    \"./csv_files/lulesh_2nd/\",\n",
    "    \"./csv_files/lulesh_3rd/\",\n",
    "]\n",
    "\n",
    "list_csvDir_mg = [\n",
    "    \"./csv_files/mg_1st/\",\n",
    "    \"./csv_files/mg_2nd/\",\n",
    "    \"./csv_files/mg_3rd/\",\n",
    "]\n",
    "\n",
    "list_csvDir_ft :list[str] = [\n",
    "    \"./csv_files/ft_1st/\",\n",
    "    \"./csv_files/ft_2nd/\",\n",
    "    \"./csv_files/ft_3rd/\",\n",
    "]\n",
    "\n",
    "list_csvDir_ep :list[str] = [\n",
    "    \"./csv_files/ep_1st/\",\n",
    "    \"./csv_files/ep_2nd/\",\n",
    "    \"./csv_files/ep_3rd/\",\n",
    "]\n",
    "\n",
    "list_csvDir_is :list[str] = [\n",
    "    \"./csv_files/is_1st/\",\n",
    "    \"./csv_files/is_2nd/\",\n",
    "    \"./csv_files/is_3rd/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rawDF_is(\n",
    "    list_process: list[int],\n",
    "    list_no_of_keys: list[int],\n",
    "    list_key_max_value :list[int],\n",
    "    csvDir: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"return_rawDF_is()\n",
    "\n",
    "    ベンチマークプログラムISの手動で変更した初期変数におけるプロファイルを取得する関数\n",
    "\n",
    "    Args:\n",
    "        list_process(list[int]):プロセス数のリスト\n",
    "        list_no_of_keys(list[int]):初期変数no_of_keysのリスト\n",
    "        list_key_max_value(list[int]):初期変数key_max_valueのリスト\n",
    "        csvDir(str):CSVファイルの保持されているディレクトリ\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    list_before_concat_DF: list[pd.DataFrame] = []\n",
    "\n",
    "    for elem_process in list_process:\n",
    "        for elem_no_of_keys in list_no_of_keys:\n",
    "            for elem_key_max_value in list_key_max_value:\n",
    "                filePath: str = f\"{csvDir}is_no_of_keys{elem_no_of_keys}_key_max_value{elem_key_max_value}_process{elem_process}.csv\"\n",
    "                if os.path.isfile(filePath):\n",
    "                    try:\n",
    "                        DF_read_raw: pd.DataFrame = pd.read_csv(filePath)\n",
    "                        DF_read_raw[\"process\"] = elem_process\n",
    "                        DF_read_raw[\"no_of_keys\"] = elem_no_of_keys\n",
    "                        DF_read_raw[\"key_max_value\"] = elem_key_max_value\n",
    "                        list_before_concat_DF.append(DF_read_raw)\n",
    "                    except:\n",
    "                        warnings.warn(f\"{filePath} is empty.\")\n",
    "                else:\n",
    "                    warnings.warn(f\"{filePath} doesn't exist\")\n",
    "                    continue\n",
    "    return pd.concat(objs=list_before_concat_DF, axis=0)\n",
    "\n",
    "\n",
    "def ret_averaged_rawDF_is(\n",
    "    list_process: list[int],\n",
    "    list_no_of_keys: list[int],\n",
    "    list_key_max_value :list[int],\n",
    "    list_csvDir: list[str],\n",
    "    resVar: str,\n",
    "):\n",
    "    \"\"\"複数のCSVからDFを取得する関数（ベンチマークプログラムEP）\n",
    "\n",
    "    列Inclusiveおよび列Exclusiveが秒に変換され、InclusivePerCallもしくはExclusivePerCall列が生成される。\n",
    "\n",
    "    Args:\n",
    "        list_process(list[int]):プロセス数のリスト\n",
    "        list_no_of_keys(list[int]):初期変数no_of_keysのリスト\n",
    "        list_key_max_value(list[int]):初期変数key_max_valueのリスト\n",
    "        list_csvDir(list[str]):CSVを保持したディレクトリ名のリスト\n",
    "        resVar(str):説明変数の文字列\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    list_DFs_for_return: list[pd.DataFrame] = []\n",
    "    for elem_process in list_process:\n",
    "        for elem_no_of_keys in list_no_of_keys:\n",
    "            for elem_key_max_value in list_key_max_value:\n",
    "                list_inputDFs_for_averaged: list[pd.DataFrame] = []\n",
    "                for elem_csvDir in list_csvDir:\n",
    "                    try:\n",
    "                        _raw_DF: pd.DataFrame = return_rawDF_is(\n",
    "                            list_process=[elem_process],\n",
    "                            list_no_of_keys=[elem_no_of_keys],\n",
    "                            list_key_max_value=[elem_key_max_value],\n",
    "                            csvDir=elem_csvDir,\n",
    "                        )\n",
    "\n",
    "                        if resVar in [\"Exclusive\", \"Inclusive\", \"#Call\", \"#Subrs\"]:\n",
    "                            # resVar 列の整形\n",
    "                            if resVar in [\"Exclusive\", \"Inclusive\"]:\n",
    "                                _tmp_converted = map(\n",
    "                                    convertPprofTime, list(_raw_DF[resVar])\n",
    "                                )\n",
    "                                _raw_DF[resVar] = list(_tmp_converted)\n",
    "                            # {resVar}PerCall 列の生成\n",
    "                            _raw_DF = add_perCallColumn(\n",
    "                                inputDF=_raw_DF,\n",
    "                                divisorColName=\"#Call\",\n",
    "                                dividendColName=resVar,\n",
    "                                targetColumnName=f\"{resVar}PerCall\",\n",
    "                            )\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    list_inputDFs_for_averaged.append(_raw_DF)\n",
    "                list_DFs_for_return.append(\n",
    "                    ret_averagedDF(inputDFs=list_inputDFs_for_averaged, resVar=resVar)\n",
    "                )\n",
    "    return pd.concat(objs=list_DFs_for_return, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF_FT :pd.DataFrame = ret_averaged_rawDF_ft(list_process=train_ft_process, list_grid_size=train_ft_grid_size, list_nit=train_ft_nit, list_csvDir=list_csvDir_ft, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "testDF_FT :pd.DataFrame = ret_averaged_rawDF_ft(list_process=test_ft_process, list_grid_size=test_ft_grid_size, list_nit=test_ft_nit, list_csvDir=list_csvDir_ft, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "trainDF_MG :pd.DataFrame = ret_averaged_rawDF_mg(list_process=train_mg_process, list_size=train_mg_size, list_nit=train_mg_nit, list_csvDir=list_csvDir_mg, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "testDF_MG :pd.DataFrame = ret_averaged_rawDF_mg(list_process=test_mg_process, list_size=test_mg_size, list_nit=test_mg_nit, list_csvDir=list_csvDir_mg, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "trainDF_EP :pd.DataFrame = ret_averaged_rawDF_ep(list_process=train_ep_process, list_size=train_ep_size, list_csvDir=list_csvDir_ep, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "testDF_EP :pd.DataFrame = ret_averaged_rawDF_ep(list_process=test_ep_process, list_size=test_ep_size, list_csvDir=list_csvDir_ep, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "trainDF_IS :pd.DataFrame = ret_averaged_rawDF_is(list_process=train_is_process, list_key_max_value=train_is_max_value, list_no_of_keys=train_is_no_of_keys, list_csvDir=list_csvDir_is, resVar=\"Exclusive\")\n",
    "\n",
    "\n",
    "testDF_IS :pd.DataFrame = ret_averaged_rawDF_is(list_process=test_is_process, list_key_max_value=test_is_max_value, list_no_of_keys=test_is_no_of_keys, list_csvDir=list_csvDir_is, resVar=\"Exclusive\")\n",
    "\n",
    "trainDF_lulesh :pd.DataFrame = ret_averaged_rawDF_lulesh(\n",
    "    list_process=train_lulesh_processes,\n",
    "    list_iteration=train_lulesh_iterations,\n",
    "    list_size = train_lulesh_sizes,\n",
    "    list_csvDir=list_csvDir,\n",
    "    resVar=\"Exclusive\"\n",
    ")\n",
    "\n",
    "testDF_lulesh :pd.DataFrame = ret_averaged_rawDF_lulesh(\n",
    "    list_process=test_lulesh_processes,\n",
    "    list_iteration=test_lulesh_iterations,\n",
    "    list_size = test_lulesh_sizes,\n",
    "    list_csvDir=list_csvDir,\n",
    "    resVar=\"Exclusive\"\n",
    ")\n",
    "\n",
    "expVars_ep :list[str] = [\"process\", \"size\"]\n",
    "expVars_ft :list[str] = [\"process\", \"grid_size\", \"nit\"]\n",
    "expVars_is :list[str] = [\"process\", \"no_of_keys\", \"key_max_value\"]\n",
    "expVars_mg :list[str] = [\"process\", \"problem_size\", \"nit\"]\n",
    "expVars_lulesh :list[str] = [\"process\", \"iteration\", \"size\"]\n",
    "\n",
    "resVar_in :str = \"Inclusive\"\n",
    "resVar_ex :str = \"Exclusive\"\n",
    "\n",
    "trainDF_in_FT :pd.DataFrame = ret_averaged_rawDF_ft(list_process=train_ft_process, list_grid_size=train_ft_grid_size, list_nit=train_ft_nit, list_csvDir=list_csvDir_ft, resVar=resVar_in)\n",
    "\n",
    "\n",
    "testDF_in_FT :pd.DataFrame = ret_averaged_rawDF_ft(list_process=test_ft_process, list_grid_size=test_ft_grid_size, list_nit=test_ft_nit, list_csvDir=list_csvDir_ft, resVar=resVar_in)\n",
    "\n",
    "\n",
    "trainDF_in_MG :pd.DataFrame = ret_averaged_rawDF_mg(list_process=train_mg_process, list_size=train_mg_size, list_nit=train_mg_nit, list_csvDir=list_csvDir_mg, resVar=resVar_in)\n",
    "\n",
    "\n",
    "testDF_in_MG :pd.DataFrame = ret_averaged_rawDF_mg(list_process=test_mg_process, list_size=test_mg_size, list_nit=test_mg_nit, list_csvDir=list_csvDir_mg, resVar=resVar_in)\n",
    "\n",
    "\n",
    "trainDF_in_EP :pd.DataFrame = ret_averaged_rawDF_ep(list_process=train_ep_process, list_size=train_ep_size, list_csvDir=list_csvDir_ep, resVar=resVar_in)\n",
    "\n",
    "\n",
    "testDF_in_EP :pd.DataFrame = ret_averaged_rawDF_ep(list_process=test_ep_process, list_size=test_ep_size, list_csvDir=list_csvDir_ep, resVar=resVar_in)\n",
    "\n",
    "\n",
    "trainDF_in_IS :pd.DataFrame = ret_averaged_rawDF_is(list_process=train_is_process, list_key_max_value=train_is_max_value, list_no_of_keys=train_is_no_of_keys, list_csvDir=list_csvDir_is, resVar=resVar_in)\n",
    "\n",
    "\n",
    "testDF_in_IS :pd.DataFrame = ret_averaged_rawDF_is(list_process=test_is_process, list_key_max_value=test_is_max_value, list_no_of_keys=test_is_no_of_keys, list_csvDir=list_csvDir_is, resVar=resVar_in)\n",
    "\n",
    "trainDF_in_lulesh :pd.DataFrame = ret_averaged_rawDF_lulesh(\n",
    "    list_process=train_lulesh_processes,\n",
    "    list_iteration=train_lulesh_iterations,\n",
    "    list_size = train_lulesh_sizes,\n",
    "    list_csvDir=list_csvDir,\n",
    "    resVar=resVar_in\n",
    ")\n",
    "\n",
    "testDF_in_lulesh :pd.DataFrame = ret_averaged_rawDF_lulesh(\n",
    "    list_process=test_lulesh_processes,\n",
    "    list_iteration=test_lulesh_iterations,\n",
    "    list_size = test_lulesh_sizes,\n",
    "    list_csvDir=list_csvDir,\n",
    "    resVar=resVar_in\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 必要な結果\n",
    "\n",
    "* 関数コール回数予測\n",
    "    * モデル適合度(MAPE表)\n",
    "    * モデル予測精度(MAPEが縦軸のグラフ、重み付きMAPEが縦軸のグラフ)\n",
    "* 実行時間予測\n",
    "    * モデル適合度(MAPE表)\n",
    "    * モデル予測精度(MAPEが縦軸のグラフ、重み付きMAPEが縦軸のグラフ)\n",
    "\n",
    "# 必要なブツ\n",
    "\n",
    "* ✅モデル構築用データ\n",
    "* ✅予測対象用データ\n",
    "* ✅関数コール回数の予測モデル\n",
    "* ✅関数の総実行時間の予測モデル\n",
    "* ✅1コール当たりの関数の総実行時間の予測モデル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ret_query (list_expVar :list[str], list_product :list[int]) -> str:\n",
    "    retStr :str= \"\"\n",
    "    for i_expVar in range(len(list_expVar)):\n",
    "        retStr += f\"{list_expVar[i_expVar]}=={list_product[i_expVar]}\"\n",
    "        if i_expVar != len(list_expVar)-1:\n",
    "            retStr += \" & \"\n",
    "    return retStr\n",
    "\n",
    "class ContentsForExtraP:\n",
    "    \"\"\"class ContentsForExtraP\n",
    "\n",
    "    ExtraPによるモデルの生成\n",
    "\n",
    "    生成されるモデルは次の通り。\n",
    "\n",
    "    * 関数コール回数の予測モデル\n",
    "    * 関数の総実行時間の予測モデル\n",
    "    * 1コール当たりの関数の総実行時間の予測モデル\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        trainDF: pd.DataFrame,\n",
    "        testDF: pd.DataFrame,\n",
    "        expVars: list[str],\n",
    "        resVar: str,\n",
    "        resVarPerCall: str,\n",
    "        benchmarkName :str,\n",
    "        modelerName :str = \"multi-parameter\",\n",
    "        modelerOption :str = \"\"\" --options \\#spm=Basic \\#spo=poly_exponents=-1,0,1,2,3,log_exponents=0,1,force_combination_exponents=1,allow_negative_exponents=True\"\"\"\n",
    "    ):\n",
    "        \"\"\"__init__()\n",
    "\n",
    "        初期化変数\n",
    "\n",
    "        Args:\n",
    "            trainDF(pd.DataFrame):モデル構築用データ\n",
    "            testDF(pd.DataFrame):予測対象用データ\n",
    "            expVars(list[str]):説明変数を格納したリスト\n",
    "            resVar(str):目的変数を示した文字列\n",
    "            resVarsPerCall(str):1コール当たりの目的変数を示した文字列\n",
    "\n",
    "        \"\"\"\n",
    "        self.trainDF = trainDF.reset_index()\n",
    "        self.testDF = testDF.reset_index()\n",
    "        self.expVars = expVars\n",
    "        self.resVar = resVar\n",
    "        self.resVarPerCall = resVarPerCall\n",
    "        self.functionNames :list[str] = sorted(list(set(trainDF[\"Name\"].to_list())))\n",
    "        self.benchmarkName :str = benchmarkName\n",
    "        self.modelerName :str = modelerName\n",
    "        self.modelerOption :str = modelerOption\n",
    "        self.dict_symbols :dict[str, str] = {}\n",
    "        for elem in expVars:\n",
    "            self.dict_symbols[elem] = symbols(elem, real=True)\n",
    "        \n",
    "        self.dict_resVar = {}\n",
    "        self.dict_resVarPerCall = {}\n",
    "        self.dict_call = {}\n",
    "\n",
    "    def build_all_models(self):\n",
    "        \"\"\"build_all_models()\n",
    "\n",
    "        モデルを構築する関数。目的変数はself.resVars, self.resVarsPerCallを利用。\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        for functionName in self.functionNames:\n",
    "            trainDF_perFunc :pd.DataFrame = self.trainDF[self.trainDF[\"Name\"] == functionName]\n",
    "\n",
    "            model_resVar :str = get_ExtraP_model(\n",
    "                inputDF_perFunc=trainDF_perFunc,\n",
    "                expVar = self.expVars,\n",
    "                resVar = self.resVar,\n",
    "                functionName = functionName,\n",
    "                dict_symbols=self.dict_symbols,\n",
    "                benchmarkName = self.benchmarkName,\n",
    "                modelerName = self.modelerName,\n",
    "                modelerOption = self.modelerOption\n",
    "            )\n",
    "\n",
    "            model_resVarPerCall :str = get_ExtraP_model(\n",
    "                inputDF_perFunc=trainDF_perFunc,\n",
    "                expVar = self.expVars,\n",
    "                resVar = self.resVarPerCall,\n",
    "                functionName = functionName,\n",
    "                dict_symbols=self.dict_symbols,\n",
    "                benchmarkName = self.benchmarkName,\n",
    "                modelerName = self.modelerName,\n",
    "                modelerOption = self.modelerOption\n",
    "            )\n",
    "\n",
    "            model_call :str = get_ExtraP_model(\n",
    "                inputDF_perFunc=trainDF_perFunc,\n",
    "                expVar = self.expVars,\n",
    "                resVar = \"#Call\",\n",
    "                functionName = functionName,\n",
    "                dict_symbols=self.dict_symbols,\n",
    "                benchmarkName = self.benchmarkName,\n",
    "                modelerName = self.modelerName,\n",
    "                modelerOption = self.modelerOption\n",
    "            )\n",
    "\n",
    "            self.dict_resVar[functionName] = model_resVar\n",
    "            self.dict_resVarPerCall[functionName] = model_resVarPerCall\n",
    "            self.dict_call[functionName] = model_call\n",
    "\n",
    "    def predict_train(self):\n",
    "        \"\"\"predict_train(self)\n",
    "\n",
    "        学習データに対して予測を実施する関数\n",
    "\n",
    "        列構成は下記の通り\n",
    "\n",
    "        |<expVar>|Name(関数名)|#Call(コール回数実測値)|predicted_resVar（）|predicted_ExclusivePerCall\tpredicted_#Call>|<>|\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        _list_series :list[pd.Series] = []\n",
    "        for index, _sr in self.trainDF.iterrows():\n",
    "            _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "            functionName :str = _sr[\"Name\"]\n",
    "\n",
    "            _target_env :list[set[any]] = []\n",
    "            for _expVar in self.expVars:\n",
    "                _series[_expVar] = _sr[_expVar]\n",
    "                _target_env.append((self.dict_symbols[_expVar], _sr[_expVar]))\n",
    "\n",
    "            _series[\"Name\"] = _sr[\"Name\"]\n",
    "            _series[\"#Call\"] = _sr[\"#Call\"]\n",
    "            _series[f\"{self.resVar}\"] = _sr[f\"{self.resVar}\"]\n",
    "\n",
    "            _predicted_resVar: float\n",
    "            _predicted_resVarPerCall :float\n",
    "            _predicted_call :float\n",
    "\n",
    "            _predicted_resVar = self.dict_resVar[functionName].subs(_target_env).evalf()\n",
    "            _predicted_resVarPerCall = self.dict_resVarPerCall[functionName].subs(_target_env).evalf()\n",
    "            _predicted_call = self.dict_call[functionName].subs(_target_env).evalf()\n",
    "\n",
    "            _series[f\"predicted_{self.resVar}\"] = _predicted_resVar\n",
    "            _series[f\"predicted_{self.resVarPerCall}\"] = _predicted_resVarPerCall\n",
    "            _series[f\"predicted_#Call\"] = _predicted_call\n",
    "            _series[f\"predicted_{self.resVar}_indirectly\"] = _predicted_resVarPerCall * _predicted_call\n",
    "\n",
    "            _list_series.append(_series)\n",
    "\n",
    "        self.DF_predicted_by_train :pd.DataFrame = pd.DataFrame(data=_list_series).astype({\n",
    "            f\"predicted_{self.resVar}\": float,\n",
    "            f\"predicted_{self.resVarPerCall}\": float,\n",
    "            f\"predicted_#Call\": float,\n",
    "            f\"predicted_{self.resVar}_indirectly\": float,\n",
    "        })\n",
    "\n",
    "    def predict_test(self):\n",
    "        \"\"\"predict_test(self)\n",
    "        \n",
    "        予測対象データに対して予測を実施する関数\n",
    "        \"\"\"\n",
    "\n",
    "        _list_series :list[pd.Series] = []\n",
    "\n",
    "        for index, _sr in self.testDF.iterrows():\n",
    "            _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "            functionName :str = _sr[\"Name\"]\n",
    "\n",
    "            _target_env :list[set[any]] = []\n",
    "            for _expVar in self.expVars:\n",
    "                _series[_expVar] = _sr[_expVar]\n",
    "                _target_env.append((self.dict_symbols[_expVar], _sr[_expVar]))\n",
    "\n",
    "            _series[\"Name\"] = functionName\n",
    "            _series[\"#Call\"] = _sr[\"#Call\"]\n",
    "            _series[f\"{self.resVar}\"] = _sr[f\"{self.resVar}\"]\n",
    "\n",
    "            _predicted_resVar :float = self.dict_resVar[functionName].subs(_target_env).evalf()\n",
    "            _predicted_resVarPerCall :float = self.dict_resVarPerCall[functionName].subs(_target_env).evalf()\n",
    "            _predicted_call :float = self.dict_call[functionName].subs(_target_env).evalf()\n",
    "\n",
    "            _series[f\"predicted_{self.resVar}\"] = _predicted_resVar\n",
    "            _series[f\"predicted_{self.resVarPerCall}\"] = _predicted_resVarPerCall\n",
    "            _series[f\"predicted_#Call\"] = _predicted_call\n",
    "            _series[f\"predicted_{self.resVar}_indirectly\"] = _predicted_resVarPerCall * _predicted_call\n",
    "\n",
    "            _list_series.append(_series)\n",
    "\n",
    "        self.DF_predicted_by_test :pd.DataFrame = pd.DataFrame(data=_list_series)\n",
    "\n",
    "    def get_result_of_predict_train(self):\n",
    "        return self.DF_predicted_by_train\n",
    "\n",
    "    def get_result_of_predict_test(self):\n",
    "        return self.DF_predicted_by_test\n",
    "\n",
    "    def get_DF_all_fitness_with_relativeErrorRate(self) -> pd.DataFrame:\n",
    "        \"\"\"get_DF_all_fitness_with_relativeErrorRate()\n",
    "        \n",
    "        モデル適合度のテーブルを返す関数\n",
    "\n",
    "        列APE～の平均をとるとMAPEになる。\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        _returnDF :pd.DataFrame = add_relativeErrorRateCol(\n",
    "            inputDF = self.DF_predicted_by_train,\n",
    "            real_colName=\"#Call\",\n",
    "            predicted_colName=\"predicted_#Call\",\n",
    "            targetColName=\"APE_#Call\"\n",
    "        )\n",
    "        _returnDF = add_relativeErrorRateCol(\n",
    "            inputDF = _returnDF,\n",
    "            real_colName=f\"{self.resVar}\",\n",
    "            predicted_colName=f\"predicted_{self.resVar}\",\n",
    "            targetColName=f\"APE_{self.resVar}\",\n",
    "        )\n",
    "        _returnDF = add_relativeErrorRateCol(\n",
    "            inputDF = _returnDF,\n",
    "            real_colName=f\"{self.resVar}\",\n",
    "            predicted_colName=f\"predicted_{self.resVar}_indirectly\",\n",
    "            targetColName=f\"APE_{self.resVarPerCall}\",\n",
    "        )\n",
    "\n",
    "        return _returnDF\n",
    "\n",
    "    def return_products(self):\n",
    "        \"\"\"return_products()\n",
    "\n",
    "        予測対象の組合せを返す関数\n",
    "        \n",
    "        \"\"\"\n",
    "        _dict_expVar_set :dict[str, set[int]]= {}\n",
    "        for _expVar in self.expVars:\n",
    "            _dict_expVar_set[_expVar] = set(sorted(self.testDF[_expVar]))\n",
    "\n",
    "        if len(self.expVars) == 2:\n",
    "            _product = itertools.product(\n",
    "                _dict_expVar_set[self.expVars[0]],\n",
    "                _dict_expVar_set[self.expVars[1]]\n",
    "            )\n",
    "        elif len(self.expVars) == 3:\n",
    "            _product = itertools.product(\n",
    "                _dict_expVar_set[self.expVars[0]],\n",
    "                _dict_expVar_set[self.expVars[1]],\n",
    "                _dict_expVar_set[self.expVars[2]]\n",
    "            )\n",
    "        else:\n",
    "            warnings.warn(f\"self.expVars == {len(self.expVars)}\")\n",
    "            return -1\n",
    "\n",
    "        return _product\n",
    "\n",
    "    def get_DF_weightedMAPE(self) -> pd.DataFrame:\n",
    "        \"\"\"get_DF_all_fitness_with_weightedMAPE()\n",
    "        \n",
    "        予測対象環境における重み付きMAPEをまとめたDFを返す関数\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        _product = self.return_products()\n",
    "\n",
    "        _list_series :pd.Series = []\n",
    "        for _elem_product in _product:\n",
    "\n",
    "            _query :str = ret_query(list_expVar = self.expVars, list_product=list(_elem_product))\n",
    "\n",
    "            _targetDF :pd.DataFrame = self.testDF.query(_query)\n",
    "            _target_env :list[set[any]] = []\n",
    "\n",
    "            _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "\n",
    "            for i_expVar in range(len(self.expVars)):\n",
    "                _target_env.append((self.dict_symbols[self.expVars[i_expVar]], _elem_product[i_expVar]))\n",
    "                _series[self.expVars[i_expVar]] = _elem_product[i_expVar]\n",
    "\n",
    "            _c_sum :float = sum(_targetDF[\"#Call\"].tolist())\n",
    "            _target_weightedMAPE_resVar :float = 0.0\n",
    "            _target_weightedMAPE_resVarPerCall :float = 0.0\n",
    "            _target_weightedMAPE_call :float = 0.0\n",
    "            for i, sr in _targetDF.iterrows():\n",
    "                _c_t :float = sr[\"#Call\"]\n",
    "                functionName :str = sr[\"Name\"]\n",
    "\n",
    "                _A_t_resVar :float = sr[self.resVar]\n",
    "                _A_t_resVarPerCall :float = sr[self.resVarPerCall]\n",
    "                _A_t_call :float = sr[\"#Call\"]\n",
    "\n",
    "                _F_t_resVar :float = self.dict_resVar[functionName].subs(_target_env).evalf()\n",
    "                _F_t_resVarPerCall :float = self.dict_resVarPerCall[functionName].subs(_target_env).evalf()\n",
    "                _F_t_call :float = self.dict_call[functionName].subs(_target_env).evalf()\n",
    "\n",
    "                \n",
    "                _target_weightedMAPE_resVar += abs(_A_t_resVar - _F_t_resVar)/_A_t_resVar\n",
    "                _target_weightedMAPE_resVarPerCall += abs(_A_t_resVarPerCall - _F_t_resVarPerCall)/_A_t_resVarPerCall\n",
    "                _target_weightedMAPE_call += abs(_A_t_call - _F_t_call)/_A_t_call\n",
    "\n",
    "            _target_weightedMAPE_resVar *= 100/_c_sum\n",
    "            _target_weightedMAPE_resVarPerCall *= 100/_c_sum\n",
    "            _target_weightedMAPE_call *= 100/_c_sum\n",
    "            \n",
    "            _series[f\"weightedMAPE_{self.resVar}\"] = _target_weightedMAPE_resVar\n",
    "            _series[f\"weightedMAPE_{self.resVarPerCall}\"] = _target_weightedMAPE_resVarPerCall\n",
    "            _series[f\"weightedMAPE_#Call\"] = _target_weightedMAPE_call\n",
    "\n",
    "            _list_series.append(_series)\n",
    "        self.DF_weightedMAPE :pd.DataFrame = pd.DataFrame(data=_list_series)\n",
    "        # self.DF_weightedMAPE :pd.DataFrame = pd.DataFrame(data=_list_series).astype({f\"weightedMAPE_{self.resVar}\": float, f\"weightedMAPE_{self.resVarPerCall}\": float, f\"weightedMAPE_call\": float})\n",
    "        return self.DF_weightedMAPE\n",
    "\n",
    "    def get_DF_MAPE(self) -> pd.DataFrame:\n",
    "        \"\"\"get_DF_MAPE()\n",
    "\n",
    "        予測対象環境におけるMAPEをまとめたDFを返す関数\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        _product = self.return_products()\n",
    "\n",
    "        _list_series :pd.Series = []\n",
    "        for _elem_product in _product:\n",
    "\n",
    "            _query :str = ret_query(list_expVar = self.expVars, list_product=list(_elem_product))\n",
    "\n",
    "            _targetDF :pd.DataFrame = self.get_result_of_predict_test().query(_query)\n",
    "\n",
    "            _targetDF :pd.DataFrame = add_relativeErrorRateCol(\n",
    "                inputDF = _targetDF,\n",
    "                real_colName=\"#Call\",\n",
    "                predicted_colName=\"predicted_#Call\",\n",
    "                targetColName=\"APE_#Call\"\n",
    "            )\n",
    "            _targetDF = add_relativeErrorRateCol(\n",
    "                inputDF = _targetDF,\n",
    "                real_colName=f\"{self.resVar}\",\n",
    "                predicted_colName=f\"predicted_{self.resVar}\",\n",
    "                targetColName=f\"APE_{self.resVar}\",\n",
    "            )\n",
    "            _targetDF = add_relativeErrorRateCol(\n",
    "                inputDF = _targetDF,\n",
    "                real_colName=f\"{self.resVar}\",\n",
    "                predicted_colName=f\"predicted_{self.resVar}_indirectly\",\n",
    "                targetColName=f\"APE_{self.resVarPerCall}\",\n",
    "            )\n",
    "\n",
    "            _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "\n",
    "            for i_expVar in range(len(self.expVars)):\n",
    "                _series[self.expVars[i_expVar]] = _elem_product[i_expVar]\n",
    "            _series[f\"MAPE_{self.resVar}\"] = np.mean(_targetDF[f\"APE_{self.resVar}\"].to_list())\n",
    "            _series[f\"MAPE_{self.resVarPerCall}\"] = np.mean(_targetDF[f\"APE_{self.resVarPerCall}\"].to_list())\n",
    "            _series[f\"MAPE_#Call\"] = np.mean(_targetDF[f\"APE_#Call\"].to_list())\n",
    "\n",
    "            _list_series.append(_series)\n",
    "\n",
    "        return pd.DataFrame(data=_list_series)\n",
    "    \n",
    "    def exec_all(self) -> dict[str, pd.DataFrame]:\n",
    "        \"\"\"exec_all()\n",
    "        \n",
    "        個別で実施していた\n",
    "        1. モデルの構築\n",
    "        2. 学習データへの予測\n",
    "        3. 予測対象データへの予測\n",
    "        4. 各種表への整形\n",
    "        一貫して行う関数\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        self.build_all_models()\n",
    "        self.predict_train()\n",
    "        self.predict_test()\n",
    "\n",
    "        _適合度 :pd.DataFrame = self.get_DF_all_fitness_with_relativeErrorRate()\n",
    "        _重み付きMAPE :pd.DataFrame = self.get_DF_weightedMAPE()\n",
    "        _MAPE :pd.DataFrame = self.get_DF_MAPE()\n",
    "        _予測精度 :pd.DataFrame = self.get_result_of_predict_test()\n",
    "        _関数ごとのMAPE :pd.DataFrame = return_summarizedDF_on_functionName(inputDF = _適合度, resVar = self.resVar)\n",
    "\n",
    "        returnDict :dict[str, pd.DataFrame] = {\n",
    "            \"適合度\": _適合度,\n",
    "            \"重み付きMAPE\": _重み付きMAPE,\n",
    "            \"MAPE\": _MAPE,\n",
    "            \"予測精度\": _予測精度,\n",
    "            \"関数ごとのMAPE\" : _関数ごとのMAPE,\n",
    "        }\n",
    "\n",
    "        return returnDict\n",
    "\n",
    "def return_summarizedDF_on_functionName(\n",
    "    inputDF :pd.DataFrame,\n",
    "    resVar :str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"return_summarizedDF_on_functionName()\n",
    "\n",
    "    入力されたDFを関数ごとにまとめ、各数値を平均値化し、そのDFを返す関数\n",
    "\n",
    "    Args:\n",
    "        inputDF(pd.DataFrame): 入力DF\n",
    "        resVar(string): 目的変数名\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    functionNames :list[str] = list(set(inputDF[\"Name\"].to_list()))\n",
    "    _list_series :list[pd.Series] = []\n",
    "    for functionName in functionNames:\n",
    "        inputDF_perFunc :pd.DataFrame = inputDF[inputDF[\"Name\"] == functionName]\n",
    "        list_APE_resVar :list[float] = inputDF_perFunc[f\"APE_{resVar}\"].to_list()\n",
    "        list_APE_resVarPerCall :list[float] = inputDF_perFunc[f\"APE_{resVar}PerCall\"].to_list()\n",
    "        list_APE_call :list[float] = inputDF_perFunc[f\"APE_#Call\"].to_list()\n",
    "\n",
    "        float_MAPE_resVar :float = np.mean(list_APE_resVar)\n",
    "        float_MAPE_resVarPerCall :float = np.mean(list_APE_resVarPerCall)\n",
    "        float_MAPE_call :float = np.mean(list_APE_call)\n",
    "\n",
    "        _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "        _series[\"Name\"] = functionName\n",
    "        _series[f\"MAPE_#Call\"] = float_MAPE_call\n",
    "        _series[f\"MAPE_{resVar}\"] = float_MAPE_resVar\n",
    "        _series[f\"MAPE_{resVar}PerCall\"] = float_MAPE_resVarPerCall\n",
    "\n",
    "        _list_series.append(_series)\n",
    "\n",
    "    return pd.DataFrame(data=_list_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_now = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarkName :str = \"mg\"\n",
    "\n",
    "mg_contents = ContentsForExtraP(trainDF = trainDF_MG, testDF= testDF_MG, resVar = \"Exclusive\", expVars= expVars_mg ,resVarPerCall = \"ExclusivePerCall\", benchmarkName = benchmarkName)\n",
    "\n",
    "mg_dict = mg_contents.exec_all()\n",
    "\n",
    "mg_ex_適合度 :pd.DataFrame = mg_dict[\"適合度\"]\n",
    "mg_ex_重み付きMAPE :pd.DataFrame = mg_dict[\"重み付きMAPE\"]\n",
    "mg_ex_MAPE :pd.DataFrame = mg_dict[\"MAPE\"]\n",
    "mg_ex_予測精度 :pd.DataFrame = mg_dict[\"予測精度\"]\n",
    "mg_ex_MAPE_on_functionName :pd.DataFrame = mg_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_ex.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in mg_dict.keys():\n",
    "        mg_dict[_key].to_excel(writer, sheet_name=_key)\n",
    "\n",
    "mg_in_contents = ContentsForExtraP(trainDF = trainDF_in_MG, testDF = testDF_in_MG, resVar = resVar_in, expVars = expVars_mg, resVarPerCall=f\"{resVar_in}PerCall\", benchmarkName=benchmarkName)\n",
    "mg_in_dict :dict[str, pd.DataFrame] = mg_in_contents.exec_all()\n",
    "mg_in_適合度 :pd.DataFrame = mg_in_dict[\"適合度\"]\n",
    "mg_in_重み付きMAPE :pd.DataFrame = mg_in_dict[\"重み付きMAPE\"]\n",
    "mg_in_MAPE :pd.DataFrame = mg_in_dict[\"MAPE\"]\n",
    "mg_in_予測精度 :pd.DataFrame = mg_in_dict[\"予測精度\"]\n",
    "mg_in_MAPE_on_functionName :pd.DataFrame = mg_in_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_in.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in mg_in_dict.keys():\n",
    "        mg_in_dict[_key].to_excel(writer, sheet_name=_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt_now = datetime.datetime.now()\n",
    "\n",
    "benchmarkName :str = \"ep\"\n",
    "\n",
    "ep_contents = ContentsForExtraP(trainDF = trainDF_EP, testDF= testDF_EP, resVar = \"Exclusive\", expVars= expVars_ep ,resVarPerCall = \"ExclusivePerCall\", benchmarkName = benchmarkName)\n",
    "\n",
    "ep_dict = ep_contents.exec_all()\n",
    "\n",
    "ep_ex_適合度 :pd.DataFrame = ep_dict[\"適合度\"]\n",
    "ep_ex_重み付きMAPE :pd.DataFrame = ep_dict[\"重み付きMAPE\"]\n",
    "ep_ex_MAPE :pd.DataFrame = ep_dict[\"MAPE\"]\n",
    "ep_ex_予測精度 :pd.DataFrame = ep_dict[\"予測精度\"]\n",
    "ep_ex_MAPE_on_functionName :pd.DataFrame = ep_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{benchmarkName}_{dt_now.strftime('%Y%m%d%H%M%S')}.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in ep_dict.keys():\n",
    "        ep_dict[_key].to_excel(writer, sheet_name=_key)\n",
    "\n",
    "ep_in_contents = ContentsForExtraP(trainDF = trainDF_in_EP, testDF = testDF_in_EP, resVar = resVar_in, expVars = expVars_ep, resVarPerCall=f\"{resVar_in}PerCall\", benchmarkName=benchmarkName)\n",
    "ep_in_dict :dict[str, pd.DataFrame] = ep_in_contents.exec_all()\n",
    "ep_in_適合度 :pd.DataFrame = ep_in_dict[\"適合度\"]\n",
    "ep_in_重み付きMAPE :pd.DataFrame = ep_in_dict[\"重み付きMAPE\"]\n",
    "ep_in_MAPE :pd.DataFrame = ep_in_dict[\"MAPE\"]\n",
    "ep_in_予測精度 :pd.DataFrame = ep_in_dict[\"予測精度\"]\n",
    "ep_in_MAPE_on_functionName :pd.DataFrame = ep_in_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_in.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in ep_in_dict.keys():\n",
    "        ep_in_dict[_key].to_excel(writer, sheet_name=_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarkName :str = \"ft\"\n",
    "\n",
    "ft_contents = ContentsForExtraP(trainDF = trainDF_FT, testDF= testDF_FT, resVar = \"Exclusive\", expVars= expVars_ft ,resVarPerCall = \"ExclusivePerCall\", benchmarkName = benchmarkName)\n",
    "\n",
    "ft_dict = ft_contents.exec_all()\n",
    "\n",
    "ft_ex_適合度 :pd.DataFrame = ft_dict[\"適合度\"]\n",
    "ft_ex_重み付きMAPE :pd.DataFrame = ft_dict[\"重み付きMAPE\"]\n",
    "ft_ex_MAPE :pd.DataFrame = ft_dict[\"MAPE\"]\n",
    "ft_ex_予測精度 :pd.DataFrame = ft_dict[\"予測精度\"]\n",
    "ft_ex_MAPE_on_functionName :pd.DataFrame = ft_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{benchmarkName}_{dt_now.strftime('%Y%m%d%H%M%S')}.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "    # ft_適合度.to_excel(writer, sheet_name=\"適合度\"),\n",
    "    # ft_MAPE.to_excel(writer, sheet_name=\"MAPE\"),\n",
    "    # ft_重み付きMAPE.to_excel(writer, sheet_name=\"重み付きMAPE\"),\n",
    "    # ft_予測精度.to_excel(writer, sheet_name=\"予測精度\"),\n",
    "\n",
    "    for _key in ft_dict.keys():\n",
    "        ft_dict[_key].to_excel(writer, sheet_name=_key)\n",
    "\n",
    "ft_in_contents = ContentsForExtraP(trainDF = trainDF_in_FT, testDF = testDF_in_FT, resVar = resVar_in, expVars = expVars_ft, resVarPerCall=f\"{resVar_in}PerCall\", benchmarkName=benchmarkName)\n",
    "ft_in_dict :dict[str, pd.DataFrame] = ft_in_contents.exec_all()\n",
    "ft_in_適合度 :pd.DataFrame = ft_in_dict[\"適合度\"]\n",
    "ft_in_重み付きMAPE :pd.DataFrame = ft_in_dict[\"重み付きMAPE\"]\n",
    "ft_in_MAPE :pd.DataFrame = ft_in_dict[\"MAPE\"]\n",
    "ft_in_予測精度 :pd.DataFrame = ft_in_dict[\"予測精度\"]\n",
    "ft_in_MAPE_on_functionName :pd.DataFrame = ft_in_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_in.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in ft_in_dict.keys():\n",
    "        ft_in_dict[_key].to_excel(writer, sheet_name=_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarkName :str = \"is\"\n",
    "\n",
    "is_contents = ContentsForExtraP(trainDF = trainDF_IS, testDF= testDF_IS, resVar = \"Exclusive\", expVars= expVars_is, resVarPerCall = \"ExclusivePerCall\", benchmarkName = benchmarkName)\n",
    "\n",
    "is_dict = is_contents.exec_all()\n",
    "\n",
    "is_ex_適合度 :pd.DataFrame = is_dict[\"適合度\"]\n",
    "is_ex_重み付きMAPE :pd.DataFrame = is_dict[\"重み付きMAPE\"]\n",
    "is_ex_MAPE :pd.DataFrame = is_dict[\"MAPE\"]\n",
    "is_ex_予測精度 :pd.DataFrame = is_dict[\"予測精度\"]\n",
    "is_ex_MAPE_on_functionName :pd.DataFrame = is_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{benchmarkName}_{dt_now.strftime('%Y%m%d%H%M%S')}.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "    # is_適合度.to_excel(writer, sheet_name=\"適合度\"),\n",
    "    # is_MAPE.to_excel(writer, sheet_name=\"MAPE\"),\n",
    "    # is_重み付きMAPE.to_excel(writer, sheet_name=\"重み付きMAPE\"),\n",
    "    # is_予測精度.to_excel(writer, sheet_name=\"予測精度\"),\n",
    "\n",
    "    for _key in is_dict.keys():\n",
    "        is_dict[_key].to_excel(writer, sheet_name=_key)\n",
    "\n",
    "is_in_contents = ContentsForExtraP(trainDF = trainDF_in_IS, testDF = testDF_in_IS, resVar = resVar_in, expVars = expVars_is, resVarPerCall=f\"{resVar_in}PerCall\", benchmarkName=benchmarkName)\n",
    "is_in_dict :dict[str, pd.DataFrame] = is_in_contents.exec_all()\n",
    "is_in_適合度 :pd.DataFrame = is_in_dict[\"適合度\"]\n",
    "is_in_重み付きMAPE :pd.DataFrame = is_in_dict[\"重み付きMAPE\"]\n",
    "is_in_MAPE :pd.DataFrame = is_in_dict[\"MAPE\"]\n",
    "is_in_予測精度 :pd.DataFrame = is_in_dict[\"予測精度\"]\n",
    "is_in_MAPE_on_functionName :pd.DataFrame = is_in_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_in.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in is_in_dict.keys():\n",
    "        is_in_dict[_key].to_excel(writer, sheet_name=_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarkName :str = \"lulesh\"\n",
    "\n",
    "lulesh_contents = ContentsForExtraP(trainDF = trainDF_lulesh, testDF= testDF_lulesh, resVar = \"Exclusive\", expVars= expVars_lulesh ,resVarPerCall = \"ExclusivePerCall\", benchmarkName = \"lulesh\")\n",
    "\n",
    "lulesh_dict = lulesh_contents.exec_all()\n",
    "\n",
    "lulesh_ex_適合度 :pd.DataFrame = lulesh_dict[\"適合度\"]\n",
    "lulesh_ex_重み付きMAPE :pd.DataFrame = lulesh_dict[\"重み付きMAPE\"]\n",
    "lulesh_ex_MAPE :pd.DataFrame = lulesh_dict[\"MAPE\"]\n",
    "lulesh_ex_予測精度 :pd.DataFrame = lulesh_dict[\"予測精度\"]\n",
    "lulesh_ex_MAPE_on_functionName :pd.DataFrame = lulesh_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{benchmarkName}_{dt_now.strftime('%Y%m%d%H%M%S')}.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "    # lulesh_適合度.to_excel(writer, sheet_name=\"適合度\"),\n",
    "    # lulesh_MAPE.to_excel(writer, sheet_name=\"MAPE\"),\n",
    "    # lulesh_重み付きMAPE.to_excel(writer, sheet_name=\"重み付きMAPE\"),\n",
    "    # lulesh_予測精度.to_excel(writer, sheet_name=\"予測精度\"),\n",
    "\n",
    "    for _key in lulesh_dict.keys():\n",
    "        lulesh_dict[_key].to_excel(writer, sheet_name=_key)\n",
    "\n",
    "lulesh_in_contents = ContentsForExtraP(trainDF = trainDF_in_lulesh, testDF = testDF_in_lulesh, resVar = resVar_in, expVars = expVars_lulesh, resVarPerCall=f\"{resVar_in}PerCall\", benchmarkName=benchmarkName)\n",
    "lulesh_in_dict :dict[str, pd.DataFrame] = lulesh_in_contents.exec_all()\n",
    "lulesh_in_適合度 :pd.DataFrame = lulesh_in_dict[\"適合度\"]\n",
    "lulesh_in_重み付きMAPE :pd.DataFrame = lulesh_in_dict[\"重み付きMAPE\"]\n",
    "lulesh_in_MAPE :pd.DataFrame = lulesh_in_dict[\"MAPE\"]\n",
    "lulesh_in_予測精度 :pd.DataFrame = lulesh_in_dict[\"予測精度\"]\n",
    "lulesh_in_MAPE_on_functionName :pd.DataFrame = lulesh_in_dict[\"関数ごとのMAPE\"]\n",
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_{benchmarkName}_in.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    for _key in lulesh_in_dict.keys():\n",
    "        lulesh_in_dict[_key].to_excel(writer, sheet_name=_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ベンチマーク名</th>\n",
       "      <th>コール回数</th>\n",
       "      <th>排他的な総実行時間（直接方式）</th>\n",
       "      <th>排他的な総実行時間（分離方式）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EP</td>\n",
       "      <td>324.788035</td>\n",
       "      <td>603.094144</td>\n",
       "      <td>578.133169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FT</td>\n",
       "      <td>1.327231</td>\n",
       "      <td>20107.307838</td>\n",
       "      <td>385.155521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IS</td>\n",
       "      <td>64.667726</td>\n",
       "      <td>535.749682</td>\n",
       "      <td>516.144029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MG</td>\n",
       "      <td>11.575241</td>\n",
       "      <td>110.614697</td>\n",
       "      <td>47.061738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LULESH</td>\n",
       "      <td>2.638311</td>\n",
       "      <td>152.021226</td>\n",
       "      <td>106.569120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ベンチマーク名       コール回数  排他的な総実行時間（直接方式）  排他的な総実行時間（分離方式）\n",
       "0      EP  324.788035       603.094144       578.133169\n",
       "1      FT    1.327231     20107.307838       385.155521\n",
       "2      IS   64.667726       535.749682       516.144029\n",
       "3      MG   11.575241       110.614697        47.061738\n",
       "4  LULESH    2.638311       152.021226       106.569120"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_ex_適合度_mean :pd.Series = ep_ex_MAPE_on_functionName.mean(numeric_only=True)\n",
    "ft_ex_適合度_mean :pd.Series = ft_ex_MAPE_on_functionName.mean(numeric_only=True)\n",
    "is_ex_適合度_mean :pd.Series = is_ex_MAPE_on_functionName.mean(numeric_only=True)\n",
    "mg_ex_適合度_mean :pd.Series = mg_ex_MAPE_on_functionName.mean(numeric_only=True)\n",
    "lulesh_ex_適合度_mean :pd.Series = lulesh_ex_MAPE_on_functionName.mean(numeric_only=True)\n",
    "\n",
    "_list :list[pd.Series] = [\n",
    "    pd.Series([\"EP\", ep_ex_適合度_mean[\"MAPE_#Call\"], ep_ex_適合度_mean[\"MAPE_Exclusive\"], ep_ex_適合度_mean[\"MAPE_ExclusivePerCall\"]],index=[\"benchmarkName\", \"MAPE_#Call\", \"MAPE_Exclusive\", \"MAPE_ExclusivePerCall\"]),\n",
    "    pd.Series([\"FT\", ft_ex_適合度_mean[\"MAPE_#Call\"], ft_ex_適合度_mean[\"MAPE_Exclusive\"], ft_ex_適合度_mean[\"MAPE_ExclusivePerCall\"]],index=[\"benchmarkName\", \"MAPE_#Call\", \"MAPE_Exclusive\", \"MAPE_ExclusivePerCall\"]),\n",
    "    pd.Series([\"IS\", is_ex_適合度_mean[\"MAPE_#Call\"], is_ex_適合度_mean[\"MAPE_Exclusive\"], is_ex_適合度_mean[\"MAPE_ExclusivePerCall\"]],index=[\"benchmarkName\", \"MAPE_#Call\", \"MAPE_Exclusive\", \"MAPE_ExclusivePerCall\"]),\n",
    "    pd.Series([\"MG\", mg_ex_適合度_mean[\"MAPE_#Call\"], mg_ex_適合度_mean[\"MAPE_Exclusive\"], mg_ex_適合度_mean[\"MAPE_ExclusivePerCall\"]],index=[\"benchmarkName\", \"MAPE_#Call\", \"MAPE_Exclusive\", \"MAPE_ExclusivePerCall\"]),\n",
    "    pd.Series([\"LULESH\", lulesh_ex_適合度_mean[\"MAPE_#Call\"], lulesh_ex_適合度_mean[\"MAPE_Exclusive\"], lulesh_ex_適合度_mean[\"MAPE_ExclusivePerCall\"]],index=[\"benchmarkName\", \"MAPE_#Call\", \"MAPE_Exclusive\", \"MAPE_ExclusivePerCall\"]),\n",
    "]\n",
    "適合度_ex_mape :pd.DataFrame = pd.DataFrame(data=_list)\n",
    "\n",
    "適合度_ex_mape_JP :pd.DataFrame = 適合度_ex_mape.rename(columns={\n",
    "    \"benchmarkName\": \"ベンチマーク名\", \n",
    "    \"MAPE_#Call\": \"コール回数\",\n",
    "    \"MAPE_Exclusive\": \"排他的な総実行時間（直接方式）\",\n",
    "    \"MAPE_ExclusivePerCall\": \"排他的な総実行時間（分離方式）\",\n",
    "})\n",
    "\n",
    "適合度_ex_mape_JP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{ベンチマークごとのモデル適合度}\n",
      "\\label{2022年12月30日_ベンチマークごとのモデル適合度}\n",
      "\\begin{tabular}{llSSS}\n",
      "\\toprule\n",
      " & ベンチマーク名 & コール回数 & 排他的な総実行時間（直接方式） & 排他的な総実行時間（分離方式） \\\\\n",
      "\\midrule\n",
      "0 & EP & 324.79 & 603.09 & 578.13 \\\\\n",
      "1 & FT & 1.33 & 20107.31 & 385.16 \\\\\n",
      "2 & IS & 64.67 & 535.75 & 516.14 \\\\\n",
      "3 & MG & 11.58 & 110.61 & 47.06 \\\\\n",
      "4 & LULESH & 2.64 & 152.02 & 106.57 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(適合度_ex_mape_JP.style.format({\n",
    "    \"コール回数\":'{:.2f}',\n",
    "    \"排他的な総実行時間（直接方式）\":'{:.2f}',\n",
    "    \"排他的な総実行時間（分離方式）\":'{:.2f}',\n",
    "}).to_latex(\n",
    "    column_format=\"llSSS\",\n",
    "    label=\"2022年12月30日_ベンチマークごとのモデル適合度\",\n",
    "    caption=\"ベンチマークごとのモデル適合度\",\n",
    "    hrules=True,\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "適合度(コール回数)の表を作成\n",
    "\n",
    "構成は下記の通り\n",
    "\n",
    "| ベンチマーク名 | 平均 | 最小 | 最大 |\n",
    "|---------|----|----|----|\n",
    "|         |    |    |    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_DF_fitness_benchmarkName_mean_min_max(dict_DF :dict[str, pd.DataFrame], resVar :str):\n",
    "    _list_series :list[pd.Series] = []\n",
    "    for _key_dict_DF in dict_DF.keys():\n",
    "        _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "        _series[\"ベンチマーク名\"] = _key_dict_DF\n",
    "        columns :list[str]= dict_DF[_key_dict_DF].columns\n",
    "        _series[\"平均値\"] = dict_DF[_key_dict_DF][f\"APE_{resVar}\"].mean()\n",
    "        _series[\"最低値\"] = dict_DF[_key_dict_DF][f\"APE_{resVar}\"].min()\n",
    "        _series[\"最大値\"] = dict_DF[_key_dict_DF][f\"APE_{resVar}\"].max()\n",
    "\n",
    "        _list_series.append(_series)\n",
    "\n",
    "    return pd.DataFrame(data=_list_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{ベンチマークごとの関数コール回数モデルの適合度}\n",
      "\\label{2023年1月2日_ベンチマークごとの関数コール回数モデルの適合度}\n",
      "\\begin{tabular}{llSSS}\n",
      "\\toprule\n",
      " & ベンチマーク名 & 平均値 & 最低値 & 最大値 \\\\\n",
      "\\midrule\n",
      "0 & EP & 324.79 & 0.00 & 13775.78 \\\\\n",
      "1 & FT & 1.58 & 0.00 & 283.65 \\\\\n",
      "2 & IS & 64.67 & 0.00 & 6719.75 \\\\\n",
      "3 & MG & 10.92 & 0.00 & 903.92 \\\\\n",
      "4 & LULESH & 2.64 & 0.00 & 94.32 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ベンチマーク名</th>\n",
       "      <th>平均値</th>\n",
       "      <th>最低値</th>\n",
       "      <th>最大値</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EP</td>\n",
       "      <td>324.788035</td>\n",
       "      <td>1.110223e-14</td>\n",
       "      <td>13775.777710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FT</td>\n",
       "      <td>1.583628</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>283.652344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IS</td>\n",
       "      <td>64.667726</td>\n",
       "      <td>1.480297e-14</td>\n",
       "      <td>6719.753726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MG</td>\n",
       "      <td>10.921127</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>903.923425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LULESH</td>\n",
       "      <td>2.638311</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>94.317078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ベンチマーク名         平均値           最低値           最大値\n",
       "0      EP  324.788035  1.110223e-14  13775.777710\n",
       "1      FT    1.583628  0.000000e+00    283.652344\n",
       "2      IS   64.667726  1.480297e-14   6719.753726\n",
       "3      MG   10.921127  0.000000e+00    903.923425\n",
       "4  LULESH    2.638311  0.000000e+00     94.317078"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input_dict :dict[str, pd.DataFrame] = {\n",
    "    \"EP\": ep_ex_適合度,\n",
    "    \"FT\": ft_ex_適合度,\n",
    "    \"IS\": is_ex_適合度,\n",
    "    \"MG\": mg_ex_適合度,\n",
    "    \"LULESH\": lulesh_ex_適合度,\n",
    "}\n",
    "\n",
    "DF_fitness_benchmarkName_mean_min_max :pd.DataFrame = return_DF_fitness_benchmarkName_mean_min_max(dict_DF=_input_dict, resVar=\"#Call\")\n",
    "\n",
    "print(DF_fitness_benchmarkName_mean_min_max.style.format({\n",
    "    \"平均値\":'{:.2f}',\n",
    "    \"最低値\":'{:.2f}',\n",
    "    \"最大値\":'{:.2f}',\n",
    "}).to_latex(\n",
    "    column_format=\"llSSS\",\n",
    "    label=\"2023年1月2日_ベンチマークごとの関数コール回数モデルの適合度\",\n",
    "    caption=\"ベンチマークごとの関数コール回数モデルの適合度\",\n",
    "    hrules=True,\n",
    "))\n",
    "\n",
    "DF_fitness_benchmarkName_mean_min_max"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "適合度（総実行時間）の表を作成\n",
    "\n",
    "構成は下記の通り\n",
    "\n",
    "|         | Ex           | Ex           | In           | In           |\n",
    "|---------|--------------|--------------|--------------|--------------|\n",
    "| ベンチマーク名 |  直接方式        | 分離方式         | 直接方式         | 分離方式         |\n",
    "|         | 平均値（最小値ー最大値） | 平均値（最小値ー最大値） | 平均値（最小値ー最大値） | 平均値（最小値ー最大値） |\n",
    "\n",
    "下記の構成のDFを作成し結合する\n",
    "\n",
    "\n",
    "\n",
    "|         | Ex or In     | Ex or In      |\n",
    "|---------|--------------|--------------|\n",
    "| ベンチマーク名 |  直接方式        | 分離方式         |\n",
    "|         | 平均値（最小値ー最大値） | 平均値（最小値ー最大値） |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ベンチマーク名           平均値       最低値           最大値\n",
      "0      EP    539.178969  0.136773  1.559976e+04\n",
      "1      FT  20711.595307  0.020261  4.125477e+06\n",
      "2      IS    502.057241  0.021280  3.039975e+04\n",
      "3      MG    104.060638  0.001647  1.104249e+04\n",
      "4  LULESH    152.021226  0.000340  1.521629e+04\n",
      "  ベンチマーク名         平均値       最低値           最大値\n",
      "0      EP  516.849396  0.078627  14251.434951\n",
      "1      FT  409.516766  0.001116  51945.343698\n",
      "2      IS  483.837822  0.026386  18001.966504\n",
      "3      MG   46.452634  0.013055   1015.196642\n",
      "4  LULESH  106.569120  0.000083  13155.787492\n"
     ]
    }
   ],
   "source": [
    "_input_dict :dict[str, pd.DataFrame] = {\n",
    "    \"EP\": ep_ex_適合度,\n",
    "    \"FT\": ft_ex_適合度,\n",
    "    \"IS\": is_ex_適合度,\n",
    "    \"MG\": mg_ex_適合度,\n",
    "    \"LULESH\": lulesh_ex_適合度,\n",
    "}\n",
    "\n",
    "DF_fitness_ex_benchmarkName_mean_min_max :pd.DataFrame = return_DF_fitness_benchmarkName_mean_min_max(dict_DF=_input_dict, resVar=f\"{resVar_ex}\")\n",
    "DF_fitness_exPerCall_benchmarkName_mean_min_max :pd.DataFrame = return_DF_fitness_benchmarkName_mean_min_max(dict_DF=_input_dict, resVar=f\"{resVar_ex}PerCall\")\n",
    "\n",
    "print(DF_fitness_ex_benchmarkName_mean_min_max)\n",
    "print(DF_fitness_exPerCall_benchmarkName_mean_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ベンチマーク名         平均値           最低値           最大値\n",
      "0      EP  439.776632  3.138075e-01  15599.759869\n",
      "1      FT  415.204292  2.168404e-14  84141.522135\n",
      "2      IS  474.301023  3.305111e-03  14213.408011\n",
      "3      MG  120.582720  8.257483e-03  26427.560834\n",
      "4  LULESH  145.280166  8.502370e-04  15816.067457\n",
      "  ベンチマーク名         平均値       最低値           最大値\n",
      "0      EP  417.696151  0.078627  14251.434951\n",
      "1      FT  472.659761  0.001116  51527.308809\n",
      "2      IS  469.747804  0.026386  14443.740979\n",
      "3      MG  138.322194  0.011259  42872.938916\n",
      "4  LULESH  146.162156  0.000083  13155.787492\n"
     ]
    }
   ],
   "source": [
    "_input_dict :dict[str, pd.DataFrame] = {\n",
    "    \"EP\": ep_in_適合度,\n",
    "    \"FT\": ft_in_適合度,\n",
    "    \"IS\": is_in_適合度,\n",
    "    \"MG\": mg_in_適合度,\n",
    "    \"LULESH\": lulesh_in_適合度,\n",
    "}\n",
    "\n",
    "DF_fitness_in_benchmarkName_mean_min_max :pd.DataFrame = return_DF_fitness_benchmarkName_mean_min_max(dict_DF=_input_dict, resVar=f\"{resVar_in}\")\n",
    "DF_fitness_inPerCall_benchmarkName_mean_min_max :pd.DataFrame = return_DF_fitness_benchmarkName_mean_min_max(dict_DF=_input_dict, resVar=f\"{resVar_in}PerCall\")\n",
    "\n",
    "print(DF_fitness_in_benchmarkName_mean_min_max)\n",
    "print(DF_fitness_inPerCall_benchmarkName_mean_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_DF_about_fitness_mean_min_max(inputDF :pd.DataFrame, dict_colName :list[str], formatted_colName :str) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"format_DF_about_fitness_mean_min_max()\n",
    "    \n",
    "    引数のDFから指定のフォーマットに変換する関数\n",
    "\n",
    "    出力DFフォーマットは下記の通り\n",
    "\n",
    "    |<ベンチマーク名>|<平均(最小, 最大)>|\n",
    "\n",
    "    Args:\n",
    "        inputDF(pd.DataFrame):入力DF\n",
    "        dict_colName(dict[str, str]):辞書。inputDFにおけるどの列名の対応を記録している。{\"benchmarkName\":<ベンチマーク名>, \"mean\":<平均>, \"min\":<最小>, \"max\":<最大>}\n",
    "        formatted_colName(str):まとめたカラム名\n",
    "\n",
    "    　Returns:\n",
    "        pd.DataFrame: 出力DF\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    _col_mea :str = dict_colName[\"mean\"]\n",
    "    _col_min :str = dict_colName[\"min\"]\n",
    "    _col_max :str = dict_colName[\"max\"]\n",
    "    _col_benchmarkName :str = dict_colName[\"benchmarkName\"]\n",
    "\n",
    "    _list_series :list[pd.Series] = []\n",
    "    \n",
    "    for _it_index, _it_series in inputDF.iterrows():\n",
    "        _series :pd.Series = pd.Series(dtype=\"object\")\n",
    "        \n",
    "\n",
    "        _series[\"benchmarkname\"] = _it_series[colName_benchmark]\n",
    "        _mea :str = str(int(_it_series[_col_mea] * 1000) /1000)\n",
    "        _min :str = str(int(_it_series[_col_min] * 1000) /1000)\n",
    "        _max :str = str(int(_it_series[_col_max] * 1000) /1000)\n",
    "        _series[formatted_colName] = f\"{_mea}({_min},{_max})\"\n",
    "        \n",
    "        _list_series.append(_series)\n",
    "    \n",
    "    return pd.DataFrame(data=_list_series)\n",
    "\n",
    "\n",
    "def integrateDF_about_fitness_mean_min_max(inputDict :dict[str, pd.DataFrame], list_columnName_as_exception :list[str]):\n",
    "    \"\"\"integrateDF_about_fitness_mean_min_max()\n",
    "    \n",
    "    入力された複数のDFをmulti columnでまとめて返す関数\n",
    "\n",
    "    Args:\n",
    "        inputDict(dict[str, pd.DataFrame]): 入力辞書。キーがまとめるカラム名（大くくり）\n",
    "        list_columnName_as_exception(list[str]): 説明変数\n",
    "    \"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "_inputDict :dict[str, pd.DataFrame] = {\n",
    "    \"exclusive\": DF_fitness_ex_benchmarkName_mean_min_max,\n",
    "    \"inclusive\": DF_fitness_in_benchmarkName_mean_min_max,\n",
    "}\n",
    "\n",
    "colName_benchmark :str = \"ベンチマーク名\"\n",
    "\n",
    "target_colName :list[str] = [\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_colName :dict[str, str] = {\n",
    "    \"benchmarkName\": \"ベンチマーク名\",\n",
    "    \"mean\": \"平均値\",\n",
    "    \"min\": \"最低値\",\n",
    "    \"max\": \"最大値\",\n",
    "}\n",
    "\n",
    "DF_Exclude_直接方式_適合度 :pd.DataFrame = format_DF_about_fitness_mean_min_max(inputDF = DF_fitness_ex_benchmarkName_mean_min_max, dict_colName = dict_colName, formatted_colName=\"exclusive\")\n",
    "DF_Exclude_分離方式_適合度 :pd.DataFrame = format_DF_about_fitness_mean_min_max(inputDF = DF_fitness_exPerCall_benchmarkName_mean_min_max, dict_colName = dict_colName, formatted_colName=\"exclusive\")\n",
    "DF_Include_直接方式_適合度 :pd.DataFrame = format_DF_about_fitness_mean_min_max(inputDF = DF_fitness_in_benchmarkName_mean_min_max, dict_colName = dict_colName, formatted_colName=\"inclusive\")\n",
    "DF_Include_分離方式_適合度 :pd.DataFrame = format_DF_about_fitness_mean_min_max(inputDF = DF_fitness_inPerCall_benchmarkName_mean_min_max, dict_colName = dict_colName, formatted_colName=\"inclusive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  benchmarkname                    exclusive\n",
      "0            EP     539.178(0.136,15599.759)\n",
      "1            FT  20711.595(0.02,4125476.677)\n",
      "2            IS     502.057(0.021,30399.747)\n",
      "3            MG      104.06(0.001,11042.485)\n",
      "4        LULESH       152.021(0.0,15216.289)\n",
      "  benchmarkname                 exclusive\n",
      "0            EP  516.849(0.078,14251.434)\n",
      "1            FT  409.516(0.001,51945.343)\n",
      "2            IS  483.837(0.026,18001.966)\n",
      "3            MG    46.452(0.013,1015.196)\n",
      "4        LULESH    106.569(0.0,13155.787)\n",
      "  benchmarkname                 inclusive\n",
      "0            EP  439.776(0.313,15599.759)\n",
      "1            FT    415.204(0.0,84141.522)\n",
      "2            IS  474.301(0.003,14213.408)\n",
      "3            MG   120.582(0.008,26427.56)\n",
      "4        LULESH     145.28(0.0,15816.067)\n",
      "  benchmarkname                 inclusive\n",
      "0            EP  417.696(0.078,14251.434)\n",
      "1            FT  472.659(0.001,51527.308)\n",
      "2            IS   469.747(0.026,14443.74)\n",
      "3            MG  138.322(0.011,42872.938)\n",
      "4        LULESH    146.162(0.0,13155.787)\n"
     ]
    }
   ],
   "source": [
    "print(DF_Exclude_直接方式_適合度)\n",
    "print(DF_Exclude_分離方式_適合度)\n",
    "print(DF_Include_直接方式_適合度)\n",
    "print(DF_Include_分離方式_適合度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Exclude_適合度 :pd.DataFrame = pd.merge(left = DF_Exclude_直接方式_適合度.rename(columns={\"benchmarkname\": \"ベンチマーク名\", \"exclusive\": \"直接方式\"}).set_index(\"ベンチマーク名\"), right = DF_Exclude_分離方式_適合度.rename(columns={\"benchmarkname\": \"ベンチマーク名\", \"exclusive\": \"分離方式\"}).set_index(\"ベンチマーク名\"), on = \"ベンチマーク名\")\n",
    "DF_Include_適合度 :pd.DataFrame = pd.merge(left = DF_Include_直接方式_適合度.rename(columns={\"benchmarkname\": \"ベンチマーク名\", \"inclusive\": \"直接方式\"}).set_index(\"ベンチマーク名\"), right = DF_Include_分離方式_適合度.rename(columns={\"benchmarkname\": \"ベンチマーク名\", \"inclusive\": \"分離方式\"}).set_index(\"ベンチマーク名\"), on = \"ベンチマーク名\")\n",
    "\n",
    "DF_適合度 :pd.DataFrame = pd.concat({\"exclusive\": DF_Exclude_適合度, \"inclusive\": DF_Include_適合度}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{ベンチマークごとのモデル適合度}\n",
      "\\label{2022年12月30日_ベンチマークごとのモデル適合度}\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      " & \\multicolumn{2}{r}{exclusive} & \\multicolumn{2}{r}{inclusive} \\\\\n",
      " & 直接方式 & 分離方式 & 直接方式 & 分離方式 \\\\\n",
      "ベンチマーク名 &  &  &  &  \\\\\n",
      "\\midrule\n",
      "EP & 539.178(0.136,15599.759) & 516.849(0.078,14251.434) & 439.776(0.313,15599.759) & 417.696(0.078,14251.434) \\\\\n",
      "FT & 20711.595(0.02,4125476.677) & 409.516(0.001,51945.343) & 415.204(0.0,84141.522) & 472.659(0.001,51527.308) \\\\\n",
      "IS & 502.057(0.021,30399.747) & 483.837(0.026,18001.966) & 474.301(0.003,14213.408) & 469.747(0.026,14443.74) \\\\\n",
      "MG & 104.06(0.001,11042.485) & 46.452(0.013,1015.196) & 120.582(0.008,26427.56) & 138.322(0.011,42872.938) \\\\\n",
      "LULESH & 152.021(0.0,15216.289) & 106.569(0.0,13155.787) & 145.28(0.0,15816.067) & 146.162(0.0,13155.787) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">exclusive</th>\n",
       "      <th colspan=\"2\" halign=\"left\">inclusive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>直接方式</th>\n",
       "      <th>分離方式</th>\n",
       "      <th>直接方式</th>\n",
       "      <th>分離方式</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ベンチマーク名</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>539.178(0.136,15599.759)</td>\n",
       "      <td>516.849(0.078,14251.434)</td>\n",
       "      <td>439.776(0.313,15599.759)</td>\n",
       "      <td>417.696(0.078,14251.434)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>20711.595(0.02,4125476.677)</td>\n",
       "      <td>409.516(0.001,51945.343)</td>\n",
       "      <td>415.204(0.0,84141.522)</td>\n",
       "      <td>472.659(0.001,51527.308)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>502.057(0.021,30399.747)</td>\n",
       "      <td>483.837(0.026,18001.966)</td>\n",
       "      <td>474.301(0.003,14213.408)</td>\n",
       "      <td>469.747(0.026,14443.74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>104.06(0.001,11042.485)</td>\n",
       "      <td>46.452(0.013,1015.196)</td>\n",
       "      <td>120.582(0.008,26427.56)</td>\n",
       "      <td>138.322(0.011,42872.938)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LULESH</th>\n",
       "      <td>152.021(0.0,15216.289)</td>\n",
       "      <td>106.569(0.0,13155.787)</td>\n",
       "      <td>145.28(0.0,15816.067)</td>\n",
       "      <td>146.162(0.0,13155.787)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           exclusive                            \\\n",
       "                                直接方式                      分離方式   \n",
       "ベンチマーク名                                                          \n",
       "EP          539.178(0.136,15599.759)  516.849(0.078,14251.434)   \n",
       "FT       20711.595(0.02,4125476.677)  409.516(0.001,51945.343)   \n",
       "IS          502.057(0.021,30399.747)  483.837(0.026,18001.966)   \n",
       "MG           104.06(0.001,11042.485)    46.452(0.013,1015.196)   \n",
       "LULESH        152.021(0.0,15216.289)    106.569(0.0,13155.787)   \n",
       "\n",
       "                        inclusive                            \n",
       "                             直接方式                      分離方式  \n",
       "ベンチマーク名                                                      \n",
       "EP       439.776(0.313,15599.759)  417.696(0.078,14251.434)  \n",
       "FT         415.204(0.0,84141.522)  472.659(0.001,51527.308)  \n",
       "IS       474.301(0.003,14213.408)   469.747(0.026,14443.74)  \n",
       "MG        120.582(0.008,26427.56)  138.322(0.011,42872.938)  \n",
       "LULESH      145.28(0.0,15816.067)    146.162(0.0,13155.787)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(DF_適合度.style.to_latex(\n",
    "    label=\"2022年12月30日_ベンチマークごとのモデル適合度\",\n",
    "    caption=\"ベンチマークごとのモデル適合度\",\n",
    "    hrules=True,\n",
    "))\n",
    "\n",
    "DF_適合度"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コール回数の予測精度のグラフを作成する。\n",
    "\n",
    "プロセス以外の説明変数のどちらかを選んで、\n",
    "* small\n",
    "* medium\n",
    "* large\n",
    "1枚のグラフに5つのベンチマークを併記する。\n",
    "\n",
    "| ベンチマーク名 | プロセス数以外の説明変数名 |\n",
    "|---------|---------------|\n",
    "| EP      | 問題サイズ         |\n",
    "| FT      | グリッドサイズ       |\n",
    "| IS      | No Of Keys    |\n",
    "| MG      | 問題サイズ         |\n",
    "| LULESH  | メッシュサイズ       |\n",
    "\n",
    "| ベンチマーク名 | small                                   | medium                                  | large                                   |\n",
    "|---------|-----------------------------------------|-----------------------------------------|-----------------------------------------|\n",
    "| EP      | process=512, size=36                    | process=512, size=40                    | process=512, size=44                    |\n",
    "| FT      | process=64, grid_size=128, nit=25       | process=64, grid_size=256, nit=25       | process=64, grid_size=512, nit=25       |\n",
    "| IS      | process=64, no_of_keys=28, max_value=20 | process=64, no_of_keys=29, max_value=20 | process=64, no_of_keys=30, max_value=20 |\n",
    "| MG      | process=64, size=16, nit=25             | process=64, size=32, nit=25             | process=64, size=64, nit=25             |\n",
    "| LULESH  | process=1000, iteration=48, size=32     | process=1000, iteration=48, size=64     | process=1000, iteration=48, size=128    |\n",
    "\n",
    "✔予測精度の表から、MAPE, 重み付きMAPEを算出\n",
    "\n",
    "✔各ベンチマークプログラムでまとまったものから取得したい値を取得\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dict_MAPE_DF :dict[str, pd.DataFrame] = {\n",
    "    \"EP\": ep_ex_MAPE,\n",
    "    \"FT\": ft_ex_MAPE,\n",
    "    \"IS\": is_ex_MAPE,\n",
    "    \"MG\": mg_ex_MAPE,\n",
    "    \"LULESH\": lulesh_ex_MAPE,\n",
    "}\n",
    "\n",
    "dict_MAPE_ex_perCall_EP :dict[str, float] = {\n",
    "    \"small\" : ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == 512)&(ep_ex_MAPE[\"size\"] == 36)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == 512)&(ep_ex_MAPE[\"size\"] == 40)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == 512)&(ep_ex_MAPE[\"size\"] == 44)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_ex_perCall_FT :dict[str, float] = {\n",
    "    \"small\" : ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == 512)&(ft_ex_MAPE[\"grid_size\"] == 1024)&(ft_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == 512)&(ft_ex_MAPE[\"grid_size\"] == 2048)&(ft_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == 512)&(ft_ex_MAPE[\"grid_size\"] == 4096)&(ft_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_ex_perCall_IS :dict[str, float] = {\n",
    "    \"small\" : is_ex_MAPE[(is_ex_MAPE[\"process\"] == 128) &(is_ex_MAPE[\"no_of_keys\"] == 28) &(is_ex_MAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": is_ex_MAPE[(is_ex_MAPE[\"process\"] == 128) &(is_ex_MAPE[\"no_of_keys\"] == 29) &(is_ex_MAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : is_ex_MAPE[(is_ex_MAPE[\"process\"] == 128) &(is_ex_MAPE[\"no_of_keys\"] == 30) &(is_ex_MAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_ex_perCall_MG :dict[str, float] = {\n",
    "    \"small\" : mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == 512) &(mg_ex_MAPE[\"problem_size\"] == 128) &(mg_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == 512) &(mg_ex_MAPE[\"problem_size\"] == 256) &(mg_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == 512) &(mg_ex_MAPE[\"problem_size\"] == 512) &(mg_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_MAPE_ex_perCall_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == 1000) &(lulesh_ex_MAPE[\"size\"] == 64) &(lulesh_ex_MAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"medium\": lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == 1000) &(lulesh_ex_MAPE[\"size\"] == 96) &(lulesh_ex_MAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "    \"large\" : lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == 1000) &(lulesh_ex_MAPE[\"size\"] == 128)&(lulesh_ex_MAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"MAPE_ExclusivePerCall\"],\n",
    "}\n",
    "\n",
    "dict_MAPE_ex_perCall :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_MAPE_ex_perCall_EP,\n",
    "    \"FT\": dict_MAPE_ex_perCall_FT,\n",
    "    \"IS\": dict_MAPE_ex_perCall_IS,\n",
    "    \"MG\": dict_MAPE_ex_perCall_MG,\n",
    "    \"LULESH\": dict_MAPE_ex_perCall_LULESH\n",
    "}\n",
    "\n",
    "dict_weightedMAPE_ex_perCall_EP :dict[str, float] = {\n",
    "    \"small\" : ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == 512)&(ep_ex_重み付きMAPE[\"size\"] == 36)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == 512)&(ep_ex_重み付きMAPE[\"size\"] == 40)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == 512)&(ep_ex_重み付きMAPE[\"size\"] == 44)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall_FT :dict[str, float] = {\n",
    "    \"small\" : ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == 512)&(ft_ex_重み付きMAPE[\"grid_size\"] == 1024)&(ft_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == 512)&(ft_ex_重み付きMAPE[\"grid_size\"] == 2048)&(ft_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == 512)&(ft_ex_重み付きMAPE[\"grid_size\"] == 4096)&(ft_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall_IS :dict[str, float] = {\n",
    "    \"small\" : is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == 128) &(is_ex_重み付きMAPE[\"no_of_keys\"] == 28) &(is_ex_重み付きMAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == 128) &(is_ex_重み付きMAPE[\"no_of_keys\"] == 29) &(is_ex_重み付きMAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == 128) &(is_ex_重み付きMAPE[\"no_of_keys\"] == 30) &(is_ex_重み付きMAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall_MG :dict[str, float] = {\n",
    "    \"small\" : mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == 512) &(mg_ex_重み付きMAPE[\"problem_size\"] == 128) &(mg_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == 512) &(mg_ex_重み付きMAPE[\"problem_size\"] == 256) &(mg_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == 512) &(mg_ex_重み付きMAPE[\"problem_size\"] == 512) &(mg_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"]\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == 1000) &(lulesh_ex_重み付きMAPE[\"size\"] == 64) &(lulesh_ex_重み付きMAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"medium\": lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == 1000) &(lulesh_ex_重み付きMAPE[\"size\"] == 96) &(lulesh_ex_重み付きMAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "    \"large\" : lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == 1000) &(lulesh_ex_重み付きMAPE[\"size\"] == 128)&(lulesh_ex_重み付きMAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"weightedMAPE_ExclusivePerCall\"],\n",
    "}\n",
    "dict_weightedMAPE_ex_perCall :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_weightedMAPE_ex_perCall_EP,\n",
    "    \"FT\": dict_weightedMAPE_ex_perCall_FT,\n",
    "    \"IS\": dict_weightedMAPE_ex_perCall_IS,\n",
    "    \"MG\": dict_weightedMAPE_ex_perCall_MG,\n",
    "    \"LULESH\": dict_weightedMAPE_ex_perCall_LULESH\n",
    "}\n",
    "\n",
    "DF_to_plot_MAPE_ex_perCall_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "DF_to_plot_weightedMAPE_ex_perCall_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "\n",
    "for benchmarkName in DF_to_plot_MAPE_ex_perCall_chart.index.tolist():\n",
    "    for columnName in DF_to_plot_MAPE_ex_perCall_chart.columns.tolist():\n",
    "        DF_to_plot_MAPE_ex_perCall_chart.loc[benchmarkName, columnName] = dict_MAPE_ex_perCall[benchmarkName][columnName]\n",
    "        DF_to_plot_weightedMAPE_ex_perCall_chart.loc[benchmarkName, columnName] = dict_weightedMAPE_ex_perCall[benchmarkName][columnName]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>small</th>\n",
       "      <th>medium</th>\n",
       "      <th>large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>54.1698385892566</td>\n",
       "      <td>61.9122293863539</td>\n",
       "      <td>58.9541195154365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>401400.495981994</td>\n",
       "      <td>3247677.85038714</td>\n",
       "      <td>26364249.1816045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>113.450763728557</td>\n",
       "      <td>103.580926596315</td>\n",
       "      <td>108.647697566932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>531.023795092643</td>\n",
       "      <td>1799.08054037095</td>\n",
       "      <td>2761.85614345787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LULESH</th>\n",
       "      <td>100.938776641633</td>\n",
       "      <td>105.331270167168</td>\n",
       "      <td>76.1867733617256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   small            medium             large\n",
       "EP      54.1698385892566  61.9122293863539  58.9541195154365\n",
       "FT      401400.495981994  3247677.85038714  26364249.1816045\n",
       "IS      113.450763728557  103.580926596315  108.647697566932\n",
       "MG      531.023795092643  1799.08054037095  2761.85614345787\n",
       "LULESH  100.938776641633  105.331270167168  76.1867733617256"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_to_plot_MAPE_ex_perCall_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>small</th>\n",
       "      <th>medium</th>\n",
       "      <th>large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>0.0157797692528926</td>\n",
       "      <td>0.00101380084353213</td>\n",
       "      <td>5.59138008110530e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>8.48865959393587</td>\n",
       "      <td>51.3245551011494</td>\n",
       "      <td>339.890735934620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>0.000367371975078749</td>\n",
       "      <td>0.000186281508055120</td>\n",
       "      <td>8.51692734655457e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>0.387063059859349</td>\n",
       "      <td>0.631488000433693</td>\n",
       "      <td>0.644445146834842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LULESH</th>\n",
       "      <td>1.20003650342787e-5</td>\n",
       "      <td>3.72447150065013e-6</td>\n",
       "      <td>1.76988826212904e-6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       small                medium                large\n",
       "EP        0.0157797692528926   0.00101380084353213  5.59138008110530e-5\n",
       "FT          8.48865959393587      51.3245551011494     339.890735934620\n",
       "IS      0.000367371975078749  0.000186281508055120  8.51692734655457e-5\n",
       "MG         0.387063059859349     0.631488000433693    0.644445146834842\n",
       "LULESH   1.20003650342787e-5   3.72447150065013e-6  1.76988826212904e-6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_to_plot_weightedMAPE_ex_perCall_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_MAPE_call_EP :dict[str, float] = {\n",
    "    \"small\" : ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == 512)&(ep_ex_MAPE[\"size\"] == 36)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"medium\": ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == 512)&(ep_ex_MAPE[\"size\"] == 40)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"large\" : ep_ex_MAPE[(ep_ex_MAPE[\"process\"] == 512)&(ep_ex_MAPE[\"size\"] == 44)].reset_index().iloc[0,:][\"MAPE_#Call\"]\n",
    "}\n",
    "dict_MAPE_call_FT :dict[str, float] = {\n",
    "    \"small\" : ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == 512)&(ft_ex_MAPE[\"grid_size\"] == 1024)&(ft_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"medium\": ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == 512)&(ft_ex_MAPE[\"grid_size\"] == 2048)&(ft_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"large\" : ft_ex_MAPE[(ft_ex_MAPE[\"process\"] == 512)&(ft_ex_MAPE[\"grid_size\"] == 4096)&(ft_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_#Call\"]\n",
    "}\n",
    "dict_MAPE_call_IS :dict[str, float] = {\n",
    "    \"small\" : is_ex_MAPE[(is_ex_MAPE[\"process\"] == 128) &(is_ex_MAPE[\"no_of_keys\"] == 28) &(is_ex_MAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"medium\": is_ex_MAPE[(is_ex_MAPE[\"process\"] == 128) &(is_ex_MAPE[\"no_of_keys\"] == 29) &(is_ex_MAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"large\" : is_ex_MAPE[(is_ex_MAPE[\"process\"] == 128) &(is_ex_MAPE[\"no_of_keys\"] == 30) &(is_ex_MAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"MAPE_#Call\"]\n",
    "}\n",
    "dict_MAPE_call_MG :dict[str, float] = {\n",
    "    \"small\" : mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == 512) &(mg_ex_MAPE[\"problem_size\"] == 128) &(mg_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"medium\": mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == 512) &(mg_ex_MAPE[\"problem_size\"] == 256) &(mg_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"large\" : mg_ex_MAPE[(mg_ex_MAPE[\"process\"] == 512) &(mg_ex_MAPE[\"problem_size\"] == 512) &(mg_ex_MAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"MAPE_#Call\"]\n",
    "}\n",
    "dict_MAPE_call_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == 1000) &(lulesh_ex_MAPE[\"size\"] == 64) &(lulesh_ex_MAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"medium\": lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == 1000) &(lulesh_ex_MAPE[\"size\"] == 96) &(lulesh_ex_MAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "    \"large\" : lulesh_ex_MAPE[(lulesh_ex_MAPE[\"process\"] == 1000) &(lulesh_ex_MAPE[\"size\"] == 128)&(lulesh_ex_MAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"MAPE_#Call\"],\n",
    "}\n",
    "\n",
    "dict_MAPE_call :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_MAPE_call_EP,\n",
    "    \"FT\": dict_MAPE_call_FT,\n",
    "    \"IS\": dict_MAPE_call_IS,\n",
    "    \"MG\": dict_MAPE_call_MG,\n",
    "    \"LULESH\": dict_MAPE_call_LULESH\n",
    "}\n",
    "\n",
    "dict_weightedMAPE_call_EP :dict[str, float] = {\n",
    "    \"small\" : ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == 512)&(ep_ex_重み付きMAPE[\"size\"] == 36)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"medium\": ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == 512)&(ep_ex_重み付きMAPE[\"size\"] == 40)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"large\" : ep_ex_重み付きMAPE[(ep_ex_重み付きMAPE[\"process\"] == 512)&(ep_ex_重み付きMAPE[\"size\"] == 44)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"]\n",
    "}\n",
    "dict_weightedMAPE_call_FT :dict[str, float] = {\n",
    "    \"small\" : ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == 512)&(ft_ex_重み付きMAPE[\"grid_size\"] == 1024)&(ft_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"medium\": ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == 512)&(ft_ex_重み付きMAPE[\"grid_size\"] == 2048)&(ft_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"large\" : ft_ex_重み付きMAPE[(ft_ex_重み付きMAPE[\"process\"] == 512)&(ft_ex_重み付きMAPE[\"grid_size\"] == 4096)&(ft_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"]\n",
    "}\n",
    "dict_weightedMAPE_call_IS :dict[str, float] = {\n",
    "    \"small\" : is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == 128) &(is_ex_重み付きMAPE[\"no_of_keys\"] == 28) &(is_ex_重み付きMAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"medium\": is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == 128) &(is_ex_重み付きMAPE[\"no_of_keys\"] == 29) &(is_ex_重み付きMAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"large\" : is_ex_重み付きMAPE[(is_ex_重み付きMAPE[\"process\"] == 128) &(is_ex_重み付きMAPE[\"no_of_keys\"] == 30) &(is_ex_重み付きMAPE[\"key_max_value\"] == 20)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"]\n",
    "}\n",
    "dict_weightedMAPE_call_MG :dict[str, float] = {\n",
    "    \"small\" : mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == 512) &(mg_ex_重み付きMAPE[\"problem_size\"] == 128) &(mg_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"medium\": mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == 512) &(mg_ex_重み付きMAPE[\"problem_size\"] == 256) &(mg_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"large\" : mg_ex_重み付きMAPE[(mg_ex_重み付きMAPE[\"process\"] == 512) &(mg_ex_重み付きMAPE[\"problem_size\"] == 512) &(mg_ex_重み付きMAPE[\"nit\"] == 50)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"]\n",
    "}\n",
    "dict_weightedMAPE_call_LULESH :dict[str, float] = {\n",
    "    \"small\" : lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == 1000) &(lulesh_ex_重み付きMAPE[\"size\"] == 64) &(lulesh_ex_重み付きMAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"medium\": lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == 1000) &(lulesh_ex_重み付きMAPE[\"size\"] == 96) &(lulesh_ex_重み付きMAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "    \"large\" : lulesh_ex_重み付きMAPE[(lulesh_ex_重み付きMAPE[\"process\"] == 1000) &(lulesh_ex_重み付きMAPE[\"size\"] == 128)&(lulesh_ex_重み付きMAPE[\"iteration\"] == 1024)].reset_index().iloc[0,:][\"weightedMAPE_#Call\"],\n",
    "}\n",
    "dict_weightedMAPE_call :dict[str, dict[str, float]] = {\n",
    "    \"EP\": dict_weightedMAPE_call_EP,\n",
    "    \"FT\": dict_weightedMAPE_call_FT,\n",
    "    \"IS\": dict_weightedMAPE_call_IS,\n",
    "    \"MG\": dict_weightedMAPE_call_MG,\n",
    "    \"LULESH\": dict_weightedMAPE_call_LULESH\n",
    "}\n",
    "\n",
    "DF_to_plot_MAPE_call_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "DF_to_plot_weightedMAPE_call_chart :pd.DataFrame = pd.DataFrame(\n",
    "    columns=[\"small\", \"medium\", \"large\"],\n",
    "    index=[\"EP\", \"FT\", \"IS\", \"MG\", \"LULESH\"],\n",
    ")\n",
    "\n",
    "for benchmarkName in DF_to_plot_MAPE_call_chart.index.tolist():\n",
    "    for columnName in DF_to_plot_MAPE_call_chart.columns.tolist():\n",
    "        DF_to_plot_MAPE_call_chart.loc[benchmarkName, columnName] = dict_MAPE_call[benchmarkName][columnName]\n",
    "        DF_to_plot_weightedMAPE_call_chart.loc[benchmarkName, columnName] = dict_weightedMAPE_call[benchmarkName][columnName]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>small</th>\n",
       "      <th>medium</th>\n",
       "      <th>large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>11.5866874822171</td>\n",
       "      <td>11.7544285223272</td>\n",
       "      <td>11.7641279743785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>846.932282926923</td>\n",
       "      <td>968.881332679345</td>\n",
       "      <td>1442.48554671983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>3.45703549162686</td>\n",
       "      <td>3.58037180919725</td>\n",
       "      <td>3.64204073988601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>41.3425820608501</td>\n",
       "      <td>73.8002797098333</td>\n",
       "      <td>132.244721640046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LULESH</th>\n",
       "      <td>2.72511675825220</td>\n",
       "      <td>2.72512279704510</td>\n",
       "      <td>2.72512258369738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   small            medium             large\n",
       "EP      11.5866874822171  11.7544285223272  11.7641279743785\n",
       "FT      846.932282926923  968.881332679345  1442.48554671983\n",
       "IS      3.45703549162686  3.58037180919725  3.64204073988601\n",
       "MG      41.3425820608501  73.8002797098333  132.244721640046\n",
       "LULESH  2.72511675825220  2.72512279704510  2.72512258369738"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_to_plot_MAPE_call_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>small</th>\n",
       "      <th>medium</th>\n",
       "      <th>large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>0.00331432542361967</td>\n",
       "      <td>0.000174227895953408</td>\n",
       "      <td>9.30368219814812e-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>1.31079611475855</td>\n",
       "      <td>1.49953651801906</td>\n",
       "      <td>2.23253321233814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>1.11268535011919e-5</td>\n",
       "      <td>5.76196443946887e-6</td>\n",
       "      <td>2.93060221213417e-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>0.0489320775478057</td>\n",
       "      <td>0.0690694489106718</td>\n",
       "      <td>0.0871413035337209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LULESH</th>\n",
       "      <td>3.24376693771265e-7</td>\n",
       "      <td>9.61464346476903e-8</td>\n",
       "      <td>4.05653077628884e-8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      small                medium                large\n",
       "EP      0.00331432542361967  0.000174227895953408  9.30368219814812e-6\n",
       "FT         1.31079611475855      1.49953651801906     2.23253321233814\n",
       "IS      1.11268535011919e-5   5.76196443946887e-6  2.93060221213417e-6\n",
       "MG       0.0489320775478057    0.0690694489106718   0.0871413035337209\n",
       "LULESH  3.24376693771265e-7   9.61464346476903e-8  4.05653077628884e-8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_to_plot_weightedMAPE_call_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputFilePath :str = f\"./outputs/{dt_now.strftime('%Y%m%d%H%M%S')}_chart.xlsx\"\n",
    "with pd.ExcelWriter(\n",
    "    outputFilePath,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={'options': {'strings_to_numbers': True}},\n",
    "    ) as writer:\n",
    "\n",
    "    DF_to_plot_MAPE_call_chart.to_excel(writer, sheet_name=\"コール回数（MAPE）\")\n",
    "    DF_to_plot_weightedMAPE_call_chart.to_excel(writer, sheet_name=\"コール回数（重み付きMAPE）\")\n",
    "    DF_to_plot_MAPE_ex_perCall_chart.to_excel(writer, sheet_name=\"Exclude（MAPE）\")\n",
    "    DF_to_plot_weightedMAPE_ex_perCall_chart.to_excel(writer, sheet_name=\"Exclude（重み付きMAPE）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
