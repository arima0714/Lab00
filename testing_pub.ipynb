{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:hello\n",
      "DEBUG:lib.lab_lib:hello\n"
     ]
    }
   ],
   "source": [
    "jupyter_pwd = %pwd\n",
    "if jupyter_pwd == \"/\":\n",
    "    %cd /workspace\n",
    "\n",
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib/lib.ipynb\n",
    "\n",
    "# ipynb形式のライブラリノートを.py形式に変更したものをインポート\n",
    "import lib\n",
    "import lib.lab_lib\n",
    "from lib.lab_lib import *\n",
    "\n",
    "# 生データの入ったCSVファイルの保持されたディレクトリ名を格納している変数\n",
    "csvDirPath = \"./csv_files/\"\n",
    "\n",
    "# NPBのベンチマーク名のリスト\n",
    "benchmarkNames = [\"cg\", \"ep\", \"ft\", \"is\", \"lu\", \"mg\"]\n",
    "\n",
    "# LULESH ベンチマークプログラムのプロセス数・問題サイズ・イテレーション数\n",
    "lulesh_processes: list[int] = [8, 27, 64, 125, 216, 343, 512]\n",
    "lulesh_iterations: list[int] = [8, 16, 32, 64, 128, 256]\n",
    "lulesh_sizes: list[int] = [16, 24, 32, 48, 64, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "1. ✅条件を一つ指定して、そこからデータを取得する\n",
    "2. ✅取得できた条件のデータから平均値のデータを取得\n",
    "3. すべての条件で、平均値のデータを取得\n",
    "    1. 関数 `convertPprofTime()` において `1:16:15.802` このような入力に対する変換の対応\n",
    "4. 依然と同様に予測を実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lulesh_processes: list[int] = [8, 27, 64, 125, 216, 343]\n",
    "train_lulesh_iterations: list[int] = [8, 16, 32, 64, 128]\n",
    "train_lulesh_sizes: list[int] = [16, 24, 32, 48]\n",
    "\n",
    "test_lulesh_processes: list[int] = [512, 729, 1000]\n",
    "test_lulesh_iterations: list[int] = [256, 512, 1024]\n",
    "test_lulesh_sizes: list[int] = [64, 96, 128]\n",
    "\n",
    "list_modelName: list[str] = [\n",
    "    \"modelIp\",\n",
    "    \"modelLog\",\n",
    "    \"modelLinAndIp\",\n",
    "    \"modelLinAndLog\",\n",
    "    \"modelIpAndLin\",\n",
    "    \"modelIpAndLog\",\n",
    "    \"modelLogAndLin\",\n",
    "    \"modelLogAndIp\",\n",
    "    \"modelProcessDividedByProblemSize\",\n",
    "    \"modelProblemSizeDividedByProcess\",\n",
    "    \"modelInfiniteProductOfProblemSizeMultipliedByProcesses\",\n",
    "    \"modelInfiniteProductOfProblemSizeDividedByProcesses\",\n",
    "    \"modelLinearSumOf2elementCombination\",\n",
    "    \"modelLinearSumOfElementCombinations\",\n",
    "    \"modelLinearSumOf2elementCombinationWithSquared\",\n",
    "    \"modelLinearSumOf2elementCombinationWithCubed\",\n",
    "    \"modelSquareRootOfProcess\",\n",
    "    \"modelSquareRootTimesOtherElems\",\n",
    "    \"modelObeyOneParameter\",\n",
    "    \"modelLin\"\n",
    "    # \"modelBasicTree\",\n",
    "]\n",
    "\n",
    "list_csvDir = [\"./csv_files/lulesh_1st/\", \"./csv_files/lulesh_2nd/\", \"./csv_files/lulesh_3rd/\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resVar :str = \"Inclusive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF :pd.DataFrame = ret_averaged_rawDF_lulesh(\n",
    "    list_process = train_lulesh_processes,\n",
    "    list_iteration = train_lulesh_iterations,\n",
    "    list_size = train_lulesh_sizes,\n",
    "    list_csvDir = list_csvDir,\n",
    "    resVar = resVar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '16:15.802'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testDF :pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m=\u001b[39m \u001b[43mret_averaged_rawDF_lulesh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist_process\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_lulesh_processes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist_iteration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_lulesh_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_lulesh_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist_csvDir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlist_csvDir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresVar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresVar\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/lib/lab_lib.py:10018\u001b[0m, in \u001b[0;36mret_averaged_rawDF_lulesh\u001b[0;34m(list_process, list_iteration, list_size, list_csvDir, resVar)\u001b[0m\n\u001b[1;32m  10015\u001b[0m \u001b[39mif\u001b[39;00m resVar \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInclusive\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m resVar \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mExclusive\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m  10016\u001b[0m     \u001b[39m# resVar 列の整形\u001b[39;00m\n\u001b[1;32m  10017\u001b[0m     _tmp_converted \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(convertPprofTime, \u001b[39mlist\u001b[39m(_raw_DF[resVar]))\n\u001b[0;32m> 10018\u001b[0m     _raw_DF[resVar] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(_tmp_converted)\n\u001b[1;32m  10019\u001b[0m     \u001b[39m# {resVar}PerCall 列の生成\u001b[39;00m\n\u001b[1;32m  10020\u001b[0m     _raw_DF \u001b[39m=\u001b[39m add_perCallColumn(\n\u001b[1;32m  10021\u001b[0m         inputDF\u001b[39m=\u001b[39m_raw_DF,\n\u001b[1;32m  10022\u001b[0m         divisorColName\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m#Call\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m  10023\u001b[0m         dividendColName\u001b[39m=\u001b[39mresVar,\n\u001b[1;32m  10024\u001b[0m         targetColumnName\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresVar\u001b[39m}\u001b[39;00m\u001b[39mPerCall\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m  10025\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/lib/lab_lib.py:9279\u001b[0m, in \u001b[0;36mconvertPprofTime\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   9277\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   9278\u001b[0m     minutes \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39minput\u001b[39m[:index_colon])\n\u001b[0;32m-> 9279\u001b[0m     seconds \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(\u001b[39minput\u001b[39;49m[index_colon \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m :])\n\u001b[1;32m   9281\u001b[0m \u001b[39m# print(f\"colon = {index_colon}, period = {index_period}\\ninput = {input}\\nminutes={minutes}, seconds={seconds}\")\u001b[39;00m\n\u001b[1;32m   9283\u001b[0m ret_seconds \u001b[39m=\u001b[39m \u001b[39m60\u001b[39m \u001b[39m*\u001b[39m minutes \u001b[39m+\u001b[39m seconds\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '16:15.802'"
     ]
    }
   ],
   "source": [
    "testDF :pd.DataFrame = ret_averaged_rawDF_lulesh(\n",
    "    list_process = test_lulesh_processes,\n",
    "    list_iteration = test_lulesh_iterations,\n",
    "    list_size = test_lulesh_sizes,\n",
    "    list_csvDir = list_csvDir,\n",
    "    resVar = resVar\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertPprofTime('16:15.802')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_series :list[pd.Series] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_rawDF_lulesh_actually :pd.DataFrame = ret_averaged_rawDF_lulesh(\n",
    "    list_process = [729],\n",
    "    list_iteration = [512],\n",
    "    list_size= [96],\n",
    "    list_csvDir = [\"./csv_files/lulesh_1st/\", \"./csv_files/lulesh_2nd/\", \"./csv_files/lulesh_3rd/\"],\n",
    "    resVar=\"Inclusive\"\n",
    ")\n",
    "\n",
    "averaged_rawDF_lulesh_actually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDF_lulesh :pd.DataFrame = return_rawDF_lulesh(\n",
    "    list_process = [729],\n",
    "    list_iteration = [512],\n",
    "    list_size = [96],\n",
    "    csvDir = \"./csv_files/lulesh_1st/\"\n",
    ")\n",
    "\n",
    "sampleDF2_lulesh :pd.DataFrame = return_rawDF_lulesh(\n",
    "    list_process = [729],\n",
    "    list_iteration = [512],\n",
    "    list_size = [96],\n",
    "    csvDir = \"./csv_files/lulesh_2nd/\"\n",
    ")\n",
    "\n",
    "sampleDF3_lulesh :pd.DataFrame = return_rawDF_lulesh(\n",
    "    list_process = [729],\n",
    "    list_iteration = [512],\n",
    "    list_size = [96],\n",
    "    csvDir = \"./csv_files/lulesh_3rd/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDF_lulesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inclusive の整形\n",
    "_tmp_converted :list[float ] = map(convertPprofTime, list(sampleDF_lulesh[\"Inclusive\"]))\n",
    "sampleDF_lulesh[\"Inclusive\"] = list(_tmp_converted)\n",
    "_tmp_converted :list[float ] = map(convertPprofTime, list(sampleDF2_lulesh[\"Inclusive\"]))\n",
    "sampleDF2_lulesh[\"Inclusive\"] = list(_tmp_converted)\n",
    "_tmp_converted :list[float ] = map(convertPprofTime, list(sampleDF3_lulesh[\"Inclusive\"]))\n",
    "sampleDF3_lulesh[\"Inclusive\"] = list(_tmp_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusive の整形\n",
    "_tmp_converted :list[float ] = map(convertPprofTime, list(sampleDF_lulesh[\"Exclusive\"]))\n",
    "sampleDF_lulesh[\"Exclusive\"] = list(_tmp_converted)\n",
    "_tmp_converted :list[float ] = map(convertPprofTime, list(sampleDF2_lulesh[\"Exclusive\"]))\n",
    "sampleDF2_lulesh[\"Exclusive\"] = list(_tmp_converted)\n",
    "_tmp_converted :list[float ] = map(convertPprofTime, list(sampleDF3_lulesh[\"Exclusive\"]))\n",
    "sampleDF3_lulesh[\"Exclusive\"] = list(_tmp_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDF_lulesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDF2_lulesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDF3_lulesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expVar: list[str] = [\"process\", \"iteration\", \"size\"]\n",
    "resVar: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resVar = \"Inclusive\"\n",
    "averaged_DF_lulesh_expected :pd.DataFrame = ret_averagedDF(inputDFs = [sampleDF_lulesh, sampleDF2_lulesh, sampleDF3_lulesh], resVar = resVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_DF_lulesh_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "---\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2022年4月17日～\n",
    "\n",
    "次のような表を作成する\n",
    "\n",
    "採用される割合 (MAPE の最大値 [%] ，MAPE の最小値 [%]) [%]\n",
    "\n",
    "| ベンチマークプログラム名 | 線形モデル               | 対数モデル               | 反比例モデル              |\n",
    "|--------------|---------------------|---------------------|---------------------|\n",
    "| str          | float(float, float) | float(float, float) | float(float, float) |\n",
    "\n",
    "\n",
    "目標となるのは一気にこのベンチマークプログラムを作成することだが、既存のライブラリ関数などを利用し、まずはベンチマークごとに作成可能にする。\n",
    "\n",
    "メモ\n",
    "\n",
    "## 実装予定\n",
    "\n",
    "1. 行方向に最小値を検出\n",
    "2. 最小値以外をNaNに変更\n",
    "3. 列方向に最小値と最大値を検出\n",
    "\n",
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "---\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
