{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作成した各種関数などをまとめるノート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import japanize_matplotlib\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as sp\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各種値を宣言\n",
    "benchmarks = ['bt', 'cg', 'ep', 'ft', 'is', 'lu', 'mg', 'sp']\n",
    "classes = [\"S\", \"W\", \"A\", \"B\", \"C\", \"D\"]\n",
    "processes = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "fix_process = 4\n",
    "fix_benchmark_class = \"C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_fixed_class(BenchMark=\"bt\", Processes=[1, 2, 4, 8, 16, 32, 64, 128, 256], FixedBenchMarkClass=\"C\"):\n",
    "        path = './csv_files/'\n",
    "        \n",
    "        # fixed_Class にはベンチマーククラスFixedBenchMarkClassで実行プロセス数がProcessesに該当するものの結果が入る\n",
    "        fixed_Class = []\n",
    "\n",
    "        for process in Processes:\n",
    "            file_name = (\"pprof_\"+BenchMark+FixedBenchMarkClass+str(process)+\".csv\")\n",
    "            file_path = path+file_name\n",
    "            if (os.path.exists(file_path) and os.stat(file_path).st_size != 0):\n",
    "                data_frame = pd.read_csv(path+file_name)\n",
    "                data_frame = data_frame.set_index(['Name'])\n",
    "                fixed_Class.append(data_frame.rename(columns = {'#Call': process}).sort_index())\n",
    "        return(fixed_Class)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fixed_class_graph(BenchMark=\"bt\", Processes=[1, 2, 4, 8, 16, 32, 64, 128, 256], FixedBenchMarkClass=\"C\"):\n",
    "\n",
    "        markers = [\".\", \",\", \"o\", \"v\", \"^\", \"<\", \">\", \"1\", \"2\", \"3\", \"4\", \"8\", \"s\", \"p\", \"*\", \"h\", \"H\", \"+\", \"x\", \"D\", \"d\", \"|\", \"_\", \"None\", None, \"\", \"$x$\",\n",
    "            \"$\\\\alpha$\", \"$\\\\beta$\", \"$\\\\gamma$\"]\n",
    "        colors = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628', '#f781bf'] \n",
    "        fixed_Class = return_fixed_class(BenchMark=BenchMark, Processes=Processes, FixedBenchMarkClass=FixedBenchMarkClass)\n",
    "        if(len(fixed_Class) != 0):\n",
    "            summary_fixed_Class = pd.concat(fixed_Class, axis=1)\n",
    "            summary_fixed_Class.sort_index(axis=1, inplace=True)\n",
    "            summary_fixed_Class_title = BenchMark+\"においてベンチマーククラスをCに固定し実行プロセス数を変化させたときの実行された全ての関数のコール回数\"\n",
    "\n",
    "            x_axes = summary_fixed_Class.columns.tolist()\n",
    "\n",
    "            y_axes = summary_fixed_Class.index.tolist()\n",
    "\n",
    "            plt.figure()\n",
    "            for y_axis in y_axes:\n",
    "                color = random.choice(colors)\n",
    "                label = y_axis\n",
    "                marker = random.choice(markers)\n",
    "                plt.plot(x_axes, summary_fixed_Class.T[y_axis], marker=marker, label=y_axis)\n",
    "            plt.legend()\n",
    "            plt.title(BenchMark+\"_FixedBenchMarkClass=\"+FixedBenchMarkClass)\n",
    "            plt.show()\n",
    "            \n",
    "# 使用例\n",
    "# show_fixed_class_graph(BenchMark=\"cg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_fixed_process(BenchMark=\"bt\", BenchMarkClasses=[\"S\", \"W\", \"A\", \"B\", \"C\", \"D\"], FixedProcess=32):\n",
    "    path = './csv_files/'\n",
    "\n",
    "    # fixed_process には実行プロセス数が64でベンチマーククラスがA ~ Dまでの結果が入る\n",
    "    fixed_process = list()\n",
    "\n",
    "    for bench_mark_class in BenchMarkClasses:\n",
    "        file_name = (\"pprof_\"+BenchMark+bench_mark_class+str(FixedProcess)+\".csv\")\n",
    "        file_path = path+file_name\n",
    "        if (os.path.exists(file_path) and os.stat(file_path).st_size != 0):\n",
    "            data_frame = pd.read_csv(path+file_name)\n",
    "            data_frame = data_frame.set_index(['Name'])\n",
    "            fixed_process.append(data_frame.rename(columns = {'#Call': bench_mark_class}).sort_index())\n",
    "    return(fixed_process)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "def show_fixed_process_graph(BenchMark=\"bt\", BenchMarkClasses=[\"S\", \"W\", \"A\", \"B\", \"C\", \"D\"], FixedProcess=32):\n",
    "    fixed_process = return_fixed_process(BenchMark=BenchMark, BenchMarkClasses=BenchMarkClasses, FixedProcess=FixedProcess)\n",
    "    markers = [\".\", \",\", \"o\", \"v\", \"^\", \"<\", \">\", \"1\", \"2\", \"3\", \"4\", \"8\", \"s\", \"p\", \"*\", \"h\", \"H\", \"+\", \"x\", \"D\", \"d\", \"|\", \"_\", \"None\", None, \"\", \"$x$\",\n",
    " \"$\\\\alpha$\", \"$\\\\beta$\", \"$\\\\gamma$\"]\n",
    "    colors = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628', '#f781bf']\n",
    "    if (len(fixed_process) != 0):\n",
    "            summary_fixed_process = pd.concat(fixed_process, axis=1)\n",
    "\n",
    "            x_axes = summary_fixed_process.columns.tolist()\n",
    "\n",
    "            y_axes = summary_fixed_process.index.tolist()\n",
    "\n",
    "            plt.figure()\n",
    "            for y_axis in y_axes:\n",
    "                color = random.choice(colors)\n",
    "                label = y_axis\n",
    "                marker = random.choice(markers)\n",
    "                plt.plot(x_axes, summary_fixed_process.T[y_axis], marker=marker, label=y_axis)\n",
    "            plt.legend()\n",
    "            plt.title(BenchMark+\"_FixedProcess=\"+str(FixedProcess))\n",
    "            plt.show()\n",
    "            \n",
    "# 使用例            \n",
    "# show_fixed_process_graph(BenchMark=\"cg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph(BenchMarks=[], Processes=[], BenchMarkClasses=[], fix_process=4, fix_benchmark_class=\"C\"):\n",
    "\n",
    "    if (BenchMarks==[] or Processes==[] or BenchMarkClasses==[]):\n",
    "        print(\"関数の引数となっている配列が空です。\")\n",
    "    else:\n",
    "        for bench_mark in BenchMarks:\n",
    "            show_fixed_class_graph(BenchMark=bench_mark, Processes=Processes, FixedBenchMarkClass=fix_benchmark_class)\n",
    "            show_fixed_process_graph(BenchMark=bench_mark, BenchMarkClasses=BenchMarkClasses, FixedProcess=fix_process)            \n",
    "\n",
    "bench_marks = ['bt', 'cg', 'ep', 'ft', 'is', 'lu', 'mg', 'sp']\n",
    "processes = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "classes = [\"S\", \"W\", \"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "# 使用例\n",
    "# show_graph(bench_marks, processes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_summarized_Fixed_dataframe(BenchMark_name = \"cg\", fixed=\"class\"):\n",
    "\n",
    "    def evaluate_dataframes(df1, df2):\n",
    "        for i in range(len(df1.values.tolist()[0])):\n",
    "            if(df1.values.tolist()[0][i] != df2.values.tolist()[0][i]):\n",
    "                return False\n",
    "        return True\n",
    "    fixed_df = 0\n",
    "    if (fixed == \"class\"):\n",
    "        fixed_df = return_fixed_class(BenchMark=BenchMark_name)\n",
    "    elif (fixed == \"process\"):\n",
    "        fixed_df = return_fixed_process(BenchMark=BenchMark_name)\n",
    "    summary_fixed_df = pd.concat(fixed_df, axis=1)\n",
    "    dropped_summary_fixed_df = summary_fixed_df.drop_duplicates()\n",
    "    dropped_summary_fixed_df_renamed = dropped_summary_fixed_df\n",
    "\n",
    "    for dropped_index_name in dropped_summary_fixed_df.index.values:\n",
    "        dropped_index_name_data = summary_fixed_df.loc[[dropped_index_name]]\n",
    "        replace_name = dropped_index_name\n",
    "        for all_index_name in summary_fixed_df.index.values:\n",
    "            all_index_name_data = summary_fixed_df.loc[[all_index_name]]\n",
    "            if(dropped_index_name == all_index_name):\n",
    "                pass\n",
    "            elif(evaluate_dataframes(dropped_index_name_data, all_index_name_data)):\n",
    "                replace_name += f\", {all_index_name}\"\n",
    "        dropped_summary_fixed_df_renamed = dropped_summary_fixed_df_renamed.rename(index={dropped_index_name: replace_name})\n",
    "    \n",
    "    return dropped_summary_fixed_df_renamed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平均絶対パーセント誤差 (MAPE)(Mean Absolute Percent Error (MAPE))を返す関数\n",
    "# 引数として長さの同じ二つのリストをとる\n",
    "# 引数l1: 実測値のリスト\n",
    "# 引数l2: 予測値のリスト\n",
    "\n",
    "def mape_score(l1, l2):\n",
    "    return_num = 0\n",
    "    if(len(l1) != len(l2)):\n",
    "        print(\"引数のリストの長さが異なります\", end=\", \")\n",
    "        return -1\n",
    "    for i in range(len(l1)):\n",
    "        l1_num = l1[i]\n",
    "        l2_num = l2[i]\n",
    "        \n",
    "        return_num += abs((l1_num - l2_num)/l1_num)\n",
    "\n",
    "    return_num /= len(l1)\n",
    "    return_num *= 100\n",
    "    return return_num\n",
    "\n",
    "# 使用例：mape_score([1,2,3,4], [4,3,2,1])\n",
    "type(mape_score([1,2,3,4], [4,3,2,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_ratio(base_list :list, test_ratio :float):\n",
    "    test_index = math.floor(len(base_list) * test_ratio)\n",
    "    train_list = base_list[:-test_index]\n",
    "    test_list = base_list[-test_index:]\n",
    "    return train_list, test_list\n",
    "\n",
    "class ModelBase:\n",
    "    def __init__(self, raw_x, raw_y, benchmark_name=\"benchmark_name\", function_name=\"function_name\", test_ratio=0.3):\n",
    "        self.benchmark_name = benchmark_name\n",
    "        self.function_name = function_name\n",
    "        self.xlabel = \"実行時のプロセス数\"\n",
    "        self.ylabel = \"関数のコール回数\"\n",
    "\n",
    "        self.raw_x = np.reshape(raw_x, (-1, 1))\n",
    "        self.raw_y = np.reshape(raw_y, (-1, 1))\n",
    "        self.train_x, self.test_x = split_by_ratio(self.raw_x, test_ratio)\n",
    "        self.train_y, self.test_y = split_by_ratio(self.raw_y, test_ratio)\n",
    "        \n",
    "        if(len(self.train_x) == 0 or len(self.train_y) == 0 or len(self.test_x) == 0 or len(self.test_y) == 0):\n",
    "            print(\"学習用とテスト用にデータを分割するのに問題が生じています。\")\n",
    "        \n",
    "        self.x_model_line = np.random.rand(1024, 1) * self.raw_x.max()\n",
    "        self.x_model_line.sort(axis=0)\n",
    "        self.y_model_line = 0\n",
    "        \n",
    "        self.lr = 0\n",
    "        self.r2_score = 0\n",
    "        \n",
    "    def calc_lr(self):\n",
    "        self.lr = 0\n",
    "     \n",
    "    def calc_r2_score(self):\n",
    "        self.r2_score = 0\n",
    "        \n",
    "    def calc_mae_score(self):\n",
    "        self.mae_score = 0\n",
    "        \n",
    "    def calc_mse_score(self):\n",
    "        self.mse_score = 0\n",
    "        \n",
    "    def calc_rmse_score(self):\n",
    "        self.rmse_score = 0\n",
    "    \n",
    "    def calc_mape_score(self):\n",
    "        self.mape_score = 0\n",
    "        \n",
    "    def plot_graph(self):\n",
    "        plt.figure()\n",
    "        plt.plot(self.raw_x, self.raw_y, color=\"red\")\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLin(ModelBase):\n",
    "    def calc_lr(self):\n",
    "        self.lr = LinearRegression()\n",
    "        self.lr.fit(self.train_x, self.train_y)\n",
    "        \n",
    "    def calc_r2_score(self):\n",
    "        test_y_predicted = self.lr.predict(self.test_x)\n",
    "        self.r2_score = r2_score(self.test_y, test_y_predicted)\n",
    "        \n",
    "    def calc_mae_score(self):\n",
    "        test_y_predicted = self.lr.predict(self.test_x)\n",
    "        self.mae_score = mean_absolute_error(self.test_y, test_y_predicted)\n",
    "        \n",
    "    def calc_mse_score(self):\n",
    "        test_y_predicted = self.lr.predict(self.test_x)\n",
    "        self.mse_score = mean_squared_error(self.test_y, test_y_predicted)\n",
    "        \n",
    "    def calc_rmse_score(self):\n",
    "        self.calc_mse_score()\n",
    "        self.rmse_score = np.sqrt(self.mse_score)\n",
    "        \n",
    "    def calc_mape_score(self):\n",
    "        test_y_predicted = self.lr.predict(self.test_x)\n",
    "        self.mape_score = float(mape_score(self.test_y, test_y_predicted))\n",
    "\n",
    "    def calc_mape_score_InTrain(self):\n",
    "        train_y_predicted = self.lr.predict(self.train_x)\n",
    "        self.mape_score_InTrain = float(mape_score(self.train_y, train_y_predicted))\n",
    "        \n",
    "    def plot_graph(self):\n",
    "        plt.figure()\n",
    "        plt.scatter(self.raw_x, self.raw_y)\n",
    "        self.y_model_line = self.lr.predict(self.x_model_line)\n",
    "        plt.plot(self.x_model_line, self.y_model_line, color=\"red\")\n",
    "        plt.xlabel(self.xlabel)\n",
    "        plt.ylabel(self.ylabel)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverter_log10_func(x):\n",
    "    return 10**x\n",
    "\n",
    "class ModelLog10(ModelBase):\n",
    "    \n",
    "    def calc_lr(self):\n",
    "        self.transformer_log10 = sp.FunctionTransformer(func=np.log10, inverse_func=inverter_log10_func)\n",
    "        x_train_log10 = self.transformer_log10.transform(self.train_x)\n",
    "        y_train_log10 = self.transformer_log10.transform(self.train_y)\n",
    "        \n",
    "        self.lr = LinearRegression()\n",
    "        self.lr.fit(x_train_log10, y_train_log10)\n",
    "        \n",
    "    def calc_r2_score(self):\n",
    "        train_x_log10 = self.transformer_log10.transform(self.train_x)\n",
    "        train_y_predicted_log10 = self.lr.predict(train_x_log10)\n",
    "        train_y_predicted = self.transformer_log10.inverse_transform(train_y_predicted_log10)\n",
    "        self.r2_score = r2_score(self.train_y, train_y_predicted)\n",
    "        \n",
    "    def calc_mae_score(self):\n",
    "        train_x_log10 = self.transformer_log10.transform(self.train_x)\n",
    "        train_y_predicted_log10 = self.lr.predict(train_x_log10)\n",
    "        train_y_predicted = self.transformer_log10.inverse_transform(train_y_predicted_log10)\n",
    "        self.mae_score = mean_absolute_error(self.train_y, train_y_predicted)\n",
    "        \n",
    "    def calc_mse_score(self):\n",
    "        train_x_log10 = self.transformer_log10.transform(self.train_x)\n",
    "        train_y_predicted_log10 = self.lr.predict(train_x_log10)\n",
    "        train_y_predicted = self.transformer_log10.inverse_transform(train_y_predicted_log10)\n",
    "        self.mse_score = mean_squared_error(self.train_y, train_y_predicted)\n",
    "        \n",
    "    def calc_rmse_score(self):\n",
    "        self.calc_mse_score()\n",
    "        self.rmse_score = np.sqrt(self.mse_score)\n",
    "        \n",
    "    def calc_mape_score(self):\n",
    "        test_x_log10 = self.transformer_log10.transform(self.test_x)\n",
    "        test_y_predicted_log10 = self.lr.predict(test_x_log10)\n",
    "        test_y_predicted = self.transformer_log10.inverse_transform(test_y_predicted_log10)\n",
    "        self.mape_score = float(mape_score(self.test_y, test_y_predicted))\n",
    "\n",
    "    def calc_mape_score_InTrain(self):\n",
    "        train_x_log10 = self.transformer_log10.transform(self.train_x)\n",
    "        train_y_predicted_log10 = self.lr.predict(train_x_log10)\n",
    "        train_y_predicted = self.transformer_log10.inverse_transform(train_y_predicted_log10)\n",
    "        self.mape_score_InTrain = float(mape_score(self.train_y, train_y_predicted))\n",
    "        \n",
    "    def plot_graph(self):\n",
    "        plt.figure()\n",
    "        plt.scatter(self.raw_x, self.raw_y)\n",
    "        x_model_line_log10 = self.transformer_log10.transform(self.x_model_line)\n",
    "        y_model_line_log10 = self.lr.predict(x_model_line_log10)\n",
    "        self.y_model_line = self.transformer_log10.inverse_transform(y_model_line_log10)\n",
    "        plt.plot(self.x_model_line, self.y_model_line, color=\"red\")\n",
    "        plt.xlabel(self.xlabel)\n",
    "        plt.ylabel(self.ylabel)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse proportion\n",
    "def ip_func(x):\n",
    "    return 1/x\n",
    "\n",
    "class ModelIP(ModelBase):\n",
    "    \n",
    "    def calc_lr(self):\n",
    "        self.transformer_ip = sp.FunctionTransformer(func=ip_func, inverse_func=ip_func)\n",
    "        y_train_ip = self.transformer_ip.transform(self.train_y)        \n",
    "        self.lr = LinearRegression()\n",
    "        self.lr.fit(self.train_x, y_train_ip)\n",
    "        \n",
    "    def calc_r2_score(self):\n",
    "        train_y_predicted_ip = self.lr.predict(self.train_x)\n",
    "        train_y_predicted = self.transformer_ip.inverse_transform(train_y_predicted_ip)\n",
    "        self.r2_score = r2_score(self.train_y, train_y_predicted)\n",
    "        \n",
    "    def calc_mae_score(self):\n",
    "        train_y_predicted_ip = self.lr.predict(self.train_x)\n",
    "        train_y_predicted = self.transformer_ip.inverse_transform(train_y_predicted_ip)\n",
    "        self.mae_score = mean_absolute_error(self.train_y, train_y_predicted)\n",
    "        \n",
    "    def calc_mse_score(self):\n",
    "        train_y_predicted_ip = self.lr.predict(self.train_x)\n",
    "        train_y_predicted = self.transformer_ip.inverse_transform(train_y_predicted_ip)\n",
    "        self.mse_score = mean_squared_error(self.train_y, train_y_predicted)\n",
    "        \n",
    "    def calc_rmse_score(self):\n",
    "        self.calc_mse_score()\n",
    "        self.rmse_score = np.sqrt(self.mse_score)\n",
    "        \n",
    "    def calc_mape_score(self):\n",
    "        test_y_predicted_ip = self.lr.predict(self.test_x)\n",
    "        test_y_predicted = self.transformer_ip.inverse_transform(test_y_predicted_ip)\n",
    "        self.mape_score = float(mape_score(self.test_y, test_y_predicted))\n",
    "\n",
    "    def calc_mape_score_InTrain(self):\n",
    "        train_y_predicted_ip = self.lr.predict(self.train_x)\n",
    "        train_y_predicted = self.transformer_ip.inverse_transform(train_y_predicted_ip)\n",
    "        self.mape_score_InTrain = float(mape_score(self.train_y, train_y_predicted))\n",
    "        \n",
    "    def plot_graph(self):\n",
    "        plt.figure()\n",
    "        plt.scatter(self.raw_x, self.raw_y)\n",
    "        y_model_line_ip = self.lr.predict(self.x_model_line)\n",
    "        self.y_model_line = self.transformer_ip.inverse_transform(y_model_line_ip)\n",
    "        plt.plot(self.x_model_line, self.y_model_line, color=\"red\")\n",
    "        plt.xlabel(self.xlabel)\n",
    "        plt.ylabel(self.ylabel)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBranch(ModelBase):\n",
    "    \n",
    "    def calc_lr(self):\n",
    "        # 後述する t を算出するための処理\n",
    "        max_in_train_y = max(self.train_y)\n",
    "        max_in_train_y_first_index = self.train_y.tolist().index(max_in_train_y)\n",
    "        # 分岐点のインデックスを t とする\n",
    "        t = max_in_train_y_first_index\n",
    "        self.t = t\n",
    "        if(self.t == 0 or self.t == len(self.train_y) - 1):\n",
    "            self.lr1 = LinearRegression()\n",
    "            self.lr1.fit(self.train_x, self.train_y)\n",
    "            self.lr2 = LinearRegression()\n",
    "            self.lr2.fit(self.train_x, self.train_y)\n",
    "        else:\n",
    "            x_train_1 = self.train_x[:t]\n",
    "            x_train_2 = self.train_x[t:]\n",
    "            y_train_1 = self.train_y[:t]\n",
    "            y_train_2 = self.train_y[t:]\n",
    "            self.lr1 = LinearRegression()\n",
    "            self.lr1.fit(x_train_1, y_train_1)\n",
    "            self.lr2 = LinearRegression()\n",
    "            self.lr2.fit(x_train_2, y_train_2)\n",
    "        \n",
    "    def calc_mape_score(self):\n",
    "        if(self.t == 0 or self.t == len(self.train_y) - 1):\n",
    "            test_y_predicted = self.lr1.predict(self.test_x)\n",
    "            self.mape_score = float(mape_score(self.test_y, test_y_predicted))\n",
    "        else:\n",
    "            x_test = self.test_x\n",
    "            y_test = self.test_y\n",
    "            y_test_predicted = self.lr2.predict(x_test)\n",
    "            self.mape_score = float(mape_score(y_test, y_test_predicted))\n",
    "        \n",
    "    def plot_graph(self):\n",
    "        plt.figure()\n",
    "        plt.scatter(self.raw_x, self.raw_y)\n",
    "\n",
    "        if(self.t == 0 or self.t == len(self.train_y) - 1):\n",
    "            y_model_line = self.lr.predict(x_model_line)\n",
    "            plt.plot(self.x_model_line, y_model_line, color=\"red\")\n",
    "        else:\n",
    "            # 回帰曲線を二つのモデルで分割するための処理\n",
    "            x_model_line = self.x_model_line\n",
    "            t_in_model_line = 0\n",
    "            for i in range(len(x_model_line)):\n",
    "                if (self.train_x[self.t] < x_model_line[i]):\n",
    "                    t_in_model_line = i\n",
    "                    break\n",
    "                else:\n",
    "                    t_in_model_line = i\n",
    "            \n",
    "            x_model_line1 = self.x_model_line[:t_in_model_line]\n",
    "            x_model_line2 = self.x_model_line[t_in_model_line:]\n",
    "            y_model_line1 = self.lr1.predict(x_model_line1)\n",
    "            y_model_line2 = self.lr2.predict(x_model_line2)\n",
    "\n",
    "            plt.plot(x_model_line1, y_model_line1, color=\"red\")\n",
    "            plt.plot(x_model_line2, y_model_line2, color=\"red\")\n",
    "    #         plt.plot(self.test_x, self.test_y, color=\"yellow\")\n",
    "        plt.xlabel(self.xlabel)\n",
    "        plt.ylabel(self.ylabel)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def return_dict_summary_fixed(benchmark_name=\"cg\", fixed=\"class\"):\n",
    "    if (fixed == \"class\"):\n",
    "        fixed_ = return_fixed_class(BenchMark=benchmark_name)\n",
    "    else:\n",
    "        fixed_ = return_fixed_process(BenchMark=benchmark_name)\n",
    "    summary_fixed_ = pd.concat(fixed_ , axis=1)\n",
    "    columns = summary_fixed_.columns.to_numpy()\n",
    "    index = summary_fixed_.index.to_numpy()\n",
    "    if(fixed == \"class\"):\n",
    "        dict_summary_fixed_ = {\"processes\":columns}\n",
    "    else:\n",
    "        dict_summary_fixed_ = {\"class\":columns}\n",
    "    for index_name in index:\n",
    "        dict_summary_fixed_[index_name] = summary_fixed_.T[index_name].to_numpy()\n",
    "    return dict_summary_fixed_\n",
    "\n",
    "# NaNが入った引数のリストをNaNのみを0にして返す関数\n",
    "def return_non_NaN_list(target_list):\n",
    "    for i in range(len(target_list)):\n",
    "        if (math.isnan(target_list[i])):\n",
    "            target_list[i] = 0\n",
    "    return target_list\n",
    "# NaNが入ったリストが引数として渡されるとTrueを返す関数\n",
    "def does_include_nan(target_list):\n",
    "    for i in range(len(target_list)):\n",
    "        if(math.isnan(target_list[i])):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形・対数・反比例モデルでフィッティングを行い、MAPE値をまとめたCSVファイルを作成する関数\n",
    "def generateScoreTable(benchmark_name=\"cg\"):\n",
    "    list_ScoreTable = []\n",
    "    dict_summary_fixed_class = return_dict_summary_fixed(benchmark_name=benchmark_name, fixed=\"class\")\n",
    "    raw_x = dict_summary_fixed_class[\"processes\"]\n",
    "    for content in dict_summary_fixed_class:\n",
    "        if(content == \"processes\"):\n",
    "            continue\n",
    "        raw_y = dict_summary_fixed_class[content]\n",
    "        if(does_include_nan(raw_y)):\n",
    "            continue\n",
    "        # 線形モデル\n",
    "        model_lin = ModelLin(raw_x, raw_y, benchmark_name, content)\n",
    "        model_lin.calc_lr()\n",
    "        model_lin.calc_r2_score()\n",
    "        model_lin.calc_mae_score()\n",
    "        model_lin.calc_mse_score()\n",
    "        model_lin.calc_rmse_score()\n",
    "        model_lin.calc_mape_score()\n",
    "        # logモデル\n",
    "        model_log10 = ModelLog10(raw_x, raw_y, benchmark_name, content)\n",
    "        model_log10.calc_lr()\n",
    "        model_log10.calc_r2_score()\n",
    "        model_log10.calc_mae_score()\n",
    "        model_log10.calc_mse_score()\n",
    "        model_log10.calc_rmse_score()\n",
    "        model_log10.calc_mape_score()\n",
    "        # 反比例モデル\n",
    "        model_ip = ModelIP(raw_x, raw_y, benchmark_name, content)\n",
    "        model_ip.calc_lr()\n",
    "        model_ip.calc_r2_score()\n",
    "        model_ip.calc_mae_score()\n",
    "        model_ip.calc_mse_score()\n",
    "        model_ip.calc_rmse_score()\n",
    "        model_ip.calc_mape_score()\n",
    "        \n",
    "        list_ScoreTable.append([content, model_lin.mape_score, model_log10.mape_score, model_ip.mape_score])\n",
    "    df_ScoreTable = pd.DataFrame(list_ScoreTable)\n",
    "    df_ScoreTable.columns = [\"\", \"x mape\", \"logx mape\", \"1/x mape\"]\n",
    "    df_ScoreTable.set_index(\"\",inplace=True)\n",
    "    df_ScoreTable.to_csv(\"./tmp_GenerateScoreTable/\"+benchmark_name+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行の内容が同じものをまとめ、行タイトルに重複した行タイトルがまとめられた、データフレームが返される関数\n",
    "\n",
    "def return_summarized_Fixed_dataframe(BenchMark_name = \"cg\", fixed=\"class\"):\n",
    "\n",
    "    def evaluate_dataframes(df1, df2):\n",
    "        for i in range(len(df1.values.tolist()[0])):\n",
    "            if(df1.values.tolist()[0][i] != df2.values.tolist()[0][i]):\n",
    "                return False\n",
    "        return True\n",
    "    fixed_df = 0\n",
    "    if (fixed == \"class\"):\n",
    "        fixed_df = return_fixed_class(BenchMark=BenchMark_name)\n",
    "    elif (fixed == \"process\"):\n",
    "        fixed_df = return_fixed_process(BenchMark=BenchMark_name)\n",
    "    summary_fixed_df = pd.concat(fixed_df, axis=1)\n",
    "    dropped_summary_fixed_df = summary_fixed_df.drop_duplicates()\n",
    "    dropped_summary_fixed_df_renamed = dropped_summary_fixed_df\n",
    "\n",
    "    for dropped_index_name in dropped_summary_fixed_df.index.values:\n",
    "        dropped_index_name_data = summary_fixed_df.loc[[dropped_index_name]]\n",
    "        replace_name = dropped_index_name\n",
    "        for all_index_name in summary_fixed_df.index.values:\n",
    "            all_index_name_data = summary_fixed_df.loc[[all_index_name]]\n",
    "            if(dropped_index_name == all_index_name):\n",
    "                pass\n",
    "            elif(evaluate_dataframes(dropped_index_name_data, all_index_name_data)):\n",
    "                replace_name += f\", {all_index_name}\"\n",
    "        dropped_summary_fixed_df_renamed = dropped_summary_fixed_df_renamed.rename(index={dropped_index_name: replace_name})\n",
    "    \n",
    "    return dropped_summary_fixed_df_renamed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~_excludeBTSP, ~~~_onlyBTSP はそれぞれのベンチマークで取得したプロセス数\n",
    "processes_excludeBTSP = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "processes_onlyBTSP = [1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 169, 196, 225]\n",
    "\n",
    "# 引数に横軸：プロセス数orベンチマーククラス, 縦軸：関数名となっているデータフレームを取る\n",
    "# 返値として\n",
    "# rowData:プロセス数のリスト もしくは プロセス数のリスト (引数に由来)\n",
    "# 各種関数名：実行回数のリスト\n",
    "# 以上のような関係の辞書を返す\n",
    "\n",
    "def return_dict_Data(DataFrame):\n",
    "    columns = DataFrame.columns.to_numpy()\n",
    "    index = DataFrame.index.to_numpy()\n",
    "    # 返値となる辞書return_dictに引数のデータフレームの列名(プロセス数orベンチマーククラス)を格納\n",
    "    return_dict = {\"rowData\":columns}\n",
    "    for index_name in index:\n",
    "        return_dict[index_name] = DataFrame.T[index_name].to_numpy()\n",
    "    \n",
    "    return return_dict\n",
    "\n",
    "\n",
    "### 引数にx軸となる値のリスト, y軸となる値のリスト, 関数名の文字列の三つをとる\n",
    "### 返り値は次のようなリスト\n",
    "### [<関数名の文字列>, <線形モデルのMAPE値>, <対数モデルのMAPE値>, <反比例モデルのMAPE値>, <分岐モデルのMAPE値>]\n",
    "def return_Mape_row_list(x :list, y :list, function_name :str, test_ratio=0.3):\n",
    "\n",
    "    # 変数：model_lin\n",
    "    # 線形モデル\n",
    "    model_lin = ModelLin(x, y, test_ratio=test_ratio)\n",
    "    model_lin.calc_lr()\n",
    "    model_lin.calc_mape_score()\n",
    "\n",
    "    # 変数：model_log\n",
    "    # 対数モデル\n",
    "    model_log = ModelLog10(x, y, test_ratio=test_ratio)\n",
    "    model_log.calc_lr()\n",
    "    model_log.calc_mape_score()\n",
    "\n",
    "    # 変数：model_ip\n",
    "    # 反比例モデル\n",
    "    model_ip = ModelIP(x, y, test_ratio=test_ratio)\n",
    "    model_ip.calc_lr()\n",
    "    model_ip.calc_mape_score()\n",
    "\n",
    "    # 変数：model_branch\n",
    "    # 特異点付き条件分岐モデル\n",
    "    model_branch = ModelBranch(x, y, test_ratio=test_ratio)\n",
    "    model_branch.calc_lr()\n",
    "    model_branch.calc_mape_score()\n",
    "\n",
    "    # 変数：return_list\n",
    "    # 返り値となるリスト\n",
    "    return_list = [function_name, model_lin.mape_score, model_log.mape_score, model_ip.mape_score, model_branch.mape_score]\n",
    "    return(return_list)\n",
    "\n",
    "### 引数に「return_dict_DataFrame()」の返り値をとる\n",
    "### 返り値は行・列がモデル名・関数名で要素がMAPE値となっているDataFrame\n",
    "def return_MapeTable_per_benchmark(dict_data :dict, test_ratio):\n",
    "\n",
    "    # 変数：_names\n",
    "    # 引数の辞書のプロセス数もしくはベンチマーククラスの文字列のリスト\n",
    "    _names = dict_data['rowData']\n",
    "    # 変数：function_names\n",
    "    # 引数の辞書の関数名の文字列のリスト\n",
    "    function_names = list(dict_data.keys())\n",
    "    function_names.remove('rowData')\n",
    "\n",
    "    # リスト変数：before_DataFrame_list\n",
    "    # 最終的にDataFrameとする元となるリスト\n",
    "    before_DataFrame_list = []\n",
    "    collumn_names = [\"function name\", \"Linear model\", \"Log10 model\", \"Inverse model\", \"Branch model\"]\n",
    "    for function_name in function_names:\n",
    "        if(does_include_nan(dict_data[function_name])):\n",
    "            continue\n",
    "        before_DataFrame_list.append(return_Mape_row_list(x = _names,y = dict_data[function_name],function_name = function_name, test_ratio=test_ratio))\n",
    "    \n",
    "    # 変数：return_df\n",
    "    # 返り値となるリスト\n",
    "    return_df = pd.DataFrame(before_DataFrame_list)\n",
    "    return_df.columns = collumn_names\n",
    "    return_df = return_df.set_index(\"function name\")\n",
    "\n",
    "    return(return_df)\n",
    "\n",
    "\n",
    "### 構造体的に利用可能なクラス MapeData\n",
    "### 各ベンチマークの各モデルごとに作成される。\n",
    "### 要素として、割合, 最大値, 最小値 がある。\n",
    "class MapeData:\n",
    "    def __init__(self):\n",
    "        self.ratio = 0\n",
    "        self.max = np.nan\n",
    "        self.min = np.nan\n",
    "        self.appearance = 0\n",
    "\n",
    "    def printData(self):\n",
    "        print(f\"{self.ratio}({self.min}, {self.max})\")\n",
    "\n",
    "    def return_Data(self):\n",
    "        max_min = \"\"\n",
    "        if(self.min is np.nan):\n",
    "            max_min = \"(NoData)\"\n",
    "        else:\n",
    "            max_min = f\"({self.min}, {self.max})\"\n",
    "        return(f\"{self.ratio}%{max_min}\")\n",
    "\n",
    "### 引数に「return_MapeTable_per_benchmark()」の返り値, ベンチマーク名, (オプショナル)中間データの詳細をとる\n",
    "### 返り値として次のようなリストを返す\n",
    "### [<線形モデルのMAPEに関する奴>, <対数モデルのMAPEに関する奴>, <反比例モデルのMAPEに関する奴>, <ベンチマーク名>]\n",
    "\n",
    "def return_MapeTable_row(MapeDataframe_detail, benchmark_name:str):\n",
    "    \n",
    "    # 引数として渡されたデータフレームの行列名をindex, columnsに格納\n",
    "    columns = MapeDataframe_detail.columns.to_numpy()\n",
    "    index = MapeDataframe_detail.index.to_numpy()\n",
    "\n",
    "    # この関数で返すリストの要素の準備\n",
    "    MapeLin = MapeData()\n",
    "    MapeLog = MapeData()\n",
    "    MapeIP = MapeData()\n",
    "    MapeBr = MapeData()\n",
    "    return_list = [MapeLin, MapeLog, MapeIP, MapeBr, benchmark_name ]\n",
    "\n",
    "    # 返り値のリストの各要素の値を更新\n",
    "    for function_name in index:\n",
    "        MapeData_per_function = MapeDataframe_detail.loc[function_name].to_list()\n",
    "        min_mape = min(MapeData_per_function)\n",
    "        min_mape_index = MapeData_per_function.index(min_mape)\n",
    "        rounded_min_mape = int(min_mape * 10) / 10\n",
    "        return_list[min_mape_index].appearance += 1\n",
    "        if(return_list[min_mape_index].max is np.nan):\n",
    "            return_list[min_mape_index].max = rounded_min_mape\n",
    "            return_list[min_mape_index].min = rounded_min_mape\n",
    "        if(return_list[min_mape_index].min > min_mape):\n",
    "            return_list[min_mape_index].min = rounded_min_mape\n",
    "        elif(return_list[min_mape_index].max < min_mape):\n",
    "            return_list[min_mape_index].max = rounded_min_mape\n",
    "    sum_num = 0\n",
    "    # 集計データから割合を算出\n",
    "    for i in range(return_list.index(benchmark_name)):\n",
    "        sum_num += return_list[i].appearance\n",
    "    for i in range(return_list.index(benchmark_name)):\n",
    "        return_list[i].ratio = int(100 * return_list[i].appearance/sum_num)\n",
    "    # 割合の合計が100になるように調整\n",
    "    exclude_index0_ratios = 0\n",
    "    for i in range(return_list.index(benchmark_name)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        exclude_index0_ratios += return_list[i].ratio\n",
    "    return_list[0].ratio = 100 - exclude_index0_ratios\n",
    "\n",
    "    return(return_list)\n",
    "\n",
    "def save_MapeTable(MapeTable, suffix=\"\"):\n",
    "    tmp_table = MapeTable.copy()\n",
    "    columns = MapeTable.columns.to_numpy()\n",
    "    index = MapeTable.index.to_numpy()\n",
    "    for i in range(len(columns)):\n",
    "        for j in range(len(index)):\n",
    "            tmp_table.iat[j, i] = tmp_table.iat[j, i].return_Data()\n",
    "    tmp_table.to_csv(f\"./tmp_GenerateResources/MapeTable_{str(suffix)}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}