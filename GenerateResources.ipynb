{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 発表資料などの資料作成に必要な素材を生成するためのノート\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summarized_ = return_summarized_Fixed_dataframe()\n",
    "# print(summarized_)\n",
    "# indices = summarized_.index.values\n",
    "# columns = summarized_.columns.values\n",
    "# print(indices)\n",
    "# print(columns)\n",
    "\n",
    "# plt.figure()\n",
    "# for row in indices:\n",
    "#     print(summarized_.loc[row].to_numpy())\n",
    "#     plt.plot(columns, summarized_.loc[row].to_numpy())\n",
    "\n",
    "# return_summarized_Fixed_dataframe(BenchMark_name=\"cg\").to_csv(\"./tmp_GenerateResources/SummarizedFixedDataframe_cg.csv\")\n",
    "\n",
    "# path = \"./tmp_GenerateResources/\"\n",
    "\n",
    "# def generateScoreTable(benchmark_name=\"cg\"):\n",
    "#     list_ScoreTable = []\n",
    "#     dict_summary_fixed_class = return_dict_summary_fixed(benchmark_name=benchmark_name, fixed=\"class\")\n",
    "#     raw_x = dict_summary_fixed_class[\"processes\"]\n",
    "# #     print(f\"raw_x : {raw_x}, benchmark : {benchmark_name}\")\n",
    "#     for content in dict_summary_fixed_class:\n",
    "#         if(content == \"processes\"):\n",
    "#             continue\n",
    "#         raw_y = dict_summary_fixed_class[content]\n",
    "#         if(does_include_nan(raw_y)):\n",
    "#             continue\n",
    "# #         print(f\"raw_y(={content}) : {raw_y}\")\n",
    "#         # 線形モデル\n",
    "#         model_lin = ModelLin(raw_x, raw_y, benchmark_name, content)\n",
    "#         model_lin.calc_lr()\n",
    "#         model_lin.calc_r2_score()\n",
    "#         model_lin.calc_mae_score()\n",
    "#         model_lin.calc_mse_score()\n",
    "#         model_lin.calc_rmse_score()\n",
    "#         model_lin.calc_mape_score()\n",
    "#         model_lin.plot_graph()\n",
    "#         plt.title(f\"ベンチマーク名：{model_lin.benchmark_name}, 関数名：{model_lin.function_name}, MAPE : {model_lin.mape_score}\", y=-0.2)\n",
    "#         plt.show()\n",
    "#         # logモデル\n",
    "#         model_log10 = ModelLog10(raw_x, raw_y, benchmark_name, content)\n",
    "#         model_log10.calc_lr()\n",
    "#         model_log10.calc_r2_score()\n",
    "#         model_log10.calc_mae_score()\n",
    "#         model_log10.calc_mse_score()\n",
    "#         model_log10.calc_rmse_score()\n",
    "#         model_log10.calc_mape_score()\n",
    "#         model_log10.plot_graph()\n",
    "#         if(model_log10.benchmark_name == \"cg\" and model_log10.function_name == \"MPI_Irecv()\"):\n",
    "#             plt.savefig(path+model_log10.benchmark_name+'_'+model_log10.function_name+'.png')\n",
    "#         if(model_log10.benchmark_name == \"cg\" and model_log10.function_name == \"ICNVRT\"):\n",
    "#             plt.savefig(path+model_log10.benchmark_name+'_'+model_log10.function_name+'.png')\n",
    "#         plt.title(f\"ベンチマーク名：{model_log10.benchmark_name}, 関数名：{model_log10.function_name}, MAPE : {model_log10.mape_score}\", y=-0.2)\n",
    "#         plt.show()\n",
    "#         # 反比例モデル\n",
    "#         model_ip = ModelIP(raw_x, raw_y, benchmark_name, content)\n",
    "#         model_ip.calc_lr()\n",
    "#         model_ip.calc_r2_score()\n",
    "#         model_ip.calc_mae_score()\n",
    "#         model_ip.calc_mse_score()\n",
    "#         model_ip.calc_rmse_score()\n",
    "#         model_ip.calc_mape_score()\n",
    "#         model_ip.plot_graph()\n",
    "#         if(model_log10.benchmark_name == \"lu\" and model_log10.function_name == \"EXACT\"):\n",
    "#             plt.savefig(path+model_log10.benchmark_name+'_'+model_log10.function_name+'.png')\n",
    "#         plt.title(f\"ベンチマーク名：{model_ip.benchmark_name}, 関数名：{model_ip.function_name}, MAPE : {model_ip.mape_score}\", y=-0.2)\n",
    "#         plt.show()\n",
    "#         list_ScoreTable.append([content, model_lin.mape_score, model_log10.mape_score, model_ip.mape_score])\n",
    "#     df_ScoreTable = pd.DataFrame(list_ScoreTable)\n",
    "#     df_ScoreTable.columns = [\"\", \"x mape\", \"logx mape\", \"1/x mape\"]\n",
    "#     df_ScoreTable.set_index(\"\",inplace=True)\n",
    "#     df_ScoreTable\n",
    "\n",
    "# for benchmark in benchmarks:\n",
    "#     generateScoreTable(benchmark)\n",
    "\n",
    "# # 資料作成に使用する最もフィットするモデルはどれかを示すための表・グラフを作るためのプログラム\n",
    "\n",
    "\n",
    "# def return_list_of_ratio_row(input_list):\n",
    "#     sum_of_input_list = 0\n",
    "#     return_list = []\n",
    "#     for list_child in input_list:\n",
    "#         sum_of_input_list += len(list_child)\n",
    "#     for list_child in input_list:\n",
    "#         num = int(len(list_child)/sum_of_input_list*10000)/100\n",
    "#         return_list.append(num)\n",
    "#     # 総和を100にする処理\n",
    "#     # 最大になることの多い線形モデルはほかのモデルの割合の総和を100から引いたものにしている\n",
    "#     i_0 = 100\n",
    "#     for i in range(1, len(input_list)):\n",
    "#         i_0 -= return_list[i]\n",
    "#     return_list[0] = i_0\n",
    "#     return(return_list)\n",
    "\n",
    "# def return_list_of_range_row(input_list):\n",
    "#     return_list = []\n",
    "#     for list_child in input_list:\n",
    "#         if(len(list_child) == 0):\n",
    "#             data_str = \"(NoData)\"\n",
    "#         else:\n",
    "#             min_data = int(min(list_child)*100)/100\n",
    "#             max_data = int(max(list_child)*100)/100\n",
    "#             data_str = f\"({min_data}-{max_data})\"\n",
    "#         return_list.append(data_str)\n",
    "#     return(return_list)\n",
    "\n",
    "\n",
    "# def return_row_list(input_list):\n",
    "#     return_list = []\n",
    "#     # 割合の入ったリストと最小・最大値の入ったリスト\n",
    "#     list_of_ratio_row = return_list_of_ratio_row(input_list)\n",
    "#     list_of_range_row = return_list_of_range_row(input_list)\n",
    "    \n",
    "#     # 上の二つのリストの要素同士を結合させる\n",
    "#     for i in range(len(list_of_ratio_row)):\n",
    "#         return_list.append(f\"{list_of_ratio_row[i]}%{list_of_range_row[i]}\")\n",
    "    \n",
    "#     return return_list\n",
    "\n",
    "# csv_directory_path = './tmp_GenerateResources/'\n",
    "\n",
    "# result_of_all = [[], [], []]\n",
    "# list_for_csv = []\n",
    "\n",
    "# list_for_csv_ratio = []\n",
    "# list_for_csv_range = []\n",
    "\n",
    "# for benchmark in benchmarks:\n",
    "#     result_of_benchmark = [[], [], []]\n",
    "#     file_name = benchmark+'.csv'\n",
    "#     file_path = csv_directory_path+file_name\n",
    "#     # ファイルが存在しない場合は処理を飛ばす\n",
    "#     if(os.path.isfile(csv_directory_path+file_name) == False):\n",
    "#         continue\n",
    "#     # 完全に値をとれたもののみで集計するようにしている\n",
    "#     if(benchmark != \"cg\" and benchmark != \"ep\" and benchmark != \"lu\"):\n",
    "#         continue\n",
    "#     # 現在処理中のベンチマーク名を出力\n",
    "#     print(benchmark)\n",
    "#     df = pd.read_csv(file_path, index_col=0)\n",
    "#     columns = df.columns.values\n",
    "#     indices = df.index.values\n",
    "#     for index in indices:\n",
    "#         row = df.loc[index].tolist()\n",
    "#         result_of_benchmark[row.index(min(row))].append(min(row))\n",
    "#         result_of_all[row.index(min(row))].append(min(row))\n",
    "#     list_for_csv.append([benchmark]+return_row_list(result_of_benchmark))\n",
    "# list_for_csv.append([\"all\"]+return_row_list(result_of_all))\n",
    "\n",
    "# print(list_for_csv)\n",
    "\n",
    "# csv_head = [\"\", \"線形モデル\", \"対数モデル\", \"反比例モデル\"]\n",
    "# df_for_csv = pd.DataFrame(list_for_csv)\n",
    "# df_for_csv.columns = csv_head\n",
    "# df_for_csv.set_index(\"\")\n",
    "# df_for_csv\n",
    "\n",
    "# # ipynb形式のライブラリのインポート\n",
    "# %run ./lib.ipynb\n",
    "\n",
    "# for benchmark in benchmarks:\n",
    "#     SummarizedDF= return_summarized_Fixed_dataframe(BenchMark_name =benchmark, fixed=\"class\")\n",
    "#     SummarizedDFIndex = SummarizedDF.index.tolist()\n",
    "#     SummarizedDFColumns = SummarizedDF.columns.tolist()\n",
    "#     x_list = SummarizedDFColumns\n",
    "#     targetFunctions=[\"RHS\", \"CFFTZ\", \"ICNVRT\", \"BUBBLE\"]\n",
    "#     for FunctionNames in SummarizedDFIndex:\n",
    "#         y_list = SummarizedDF.loc[FunctionNames].tolist()\n",
    "#         if(FunctionNames in targetFunctions and (does_include_nan(y_list))==False):\n",
    "#             print(f\"{FunctionNames}@{benchmark}\")\n",
    "#             plt.figure()\n",
    "#             plt.title(FunctionNames)\n",
    "#             plt.plot(x_list,y_list)\n",
    "#             plt.xlabel('プロセス数')\n",
    "#             plt.ylabel('コール回数')\n",
    "#             plt.show()\n",
    "#             if(FunctionNames==\"RHS\"):\n",
    "#                 modelLin = ModelLin(raw_x=x_list, raw_y=y_list, benchmark_name=benchmark, function_name=FunctionNames)\n",
    "#                 modelLin.train_x = modelLin.raw_x\n",
    "#                 modelLin.train_y = modelLin.raw_y\n",
    "#                 modelLin.calc_lr()\n",
    "#                 modelLin.plot_graph(save=True, fileName=f\"./tmp_GenerateResources/{FunctionNames}@{benchmark}.png\")\n",
    "#             elif(FunctionNames==\"BUBBLE\"):\n",
    "#                 modelLog10 = ModelLog10(raw_x=x_list, raw_y=y_list, benchmark_name=benchmark, function_name=FunctionNames)\n",
    "#                 modelLog10.train_x = modelLog10.raw_x\n",
    "#                 modelLog10.train_y = modelLog10.raw_y\n",
    "#                 modelLog10.calc_lr()\n",
    "#                 modelLog10.plot_graph(save=True, fileName=f\"./tmp_GenerateResources/{FunctionNames}@{benchmark}.png\")\n",
    "#             elif(FunctionNames==\"CFFTZ\"):\n",
    "#                 modelIP = ModelIP(raw_x=x_list, raw_y=y_list, benchmark_name=benchmark, function_name=FunctionNames)\n",
    "#                 modelIP.train_x = modelIP.raw_x\n",
    "#                 modelIP.train_y = modelIP.raw_y\n",
    "#                 modelIP.calc_lr()\n",
    "#                 modelIP.plot_graph(save=True, fileName=f\"./tmp_GenerateResources/{FunctionNames}@{benchmark}.png\")\n",
    "#             elif(FunctionNames==\"ICNVRT\"):\n",
    "#                 modelBranch = ModelBranch(raw_x=x_list, raw_y=y_list, benchmark_name=benchmark, function_name=FunctionNames)\n",
    "#                 modelBranch.train_x = modelBranch.raw_x\n",
    "#                 modelBranch.train_y = modelBranch.raw_y\n",
    "#                 modelBranch.calc_lr()\n",
    "#                 modelBranch.plot_graph(save=True, fileName=f\"./tmp_GenerateResources/{FunctionNames}@{benchmark}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 論文で必要なグラフを生成する1\n",
    "print(\"↓プロセス数を固定したもの\")\n",
    "GenGraphAveragePerProfileNum(benchmarks=benchmarks, Fixed=\"Process\", Fix=64, Predict=\"D\", EnableTitle=True)\n",
    "print(\"↓ベンチマーククラスを固定したもの\")\n",
    "GenGraphAveragePerProfileNum(benchmarks=benchmarks, Fixed=\"Class\", Fix=\"B\", Predict=256, EnableTitle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 論文で必要なグラフを生成する2\n",
    "for benchmark in benchmarks:\n",
    "    print(benchmark)\n",
    "    print(\"↓プロセス数を固定したもの\")\n",
    "    GenGraphTotalTimePerProfileNum(benchmark=benchmark, Fixed=\"Process\", Fix=64, Predict=\"D\", EnableTitle=True)\n",
    "    print(\"↓ベンチマーククラスを固定したもの\")\n",
    "    GenGraphTotalTimePerProfileNum(benchmark=benchmark, Fixed=\"Class\", Fix=\"B\", Predict=256, EnableTitle=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 論文で必要なグラフを生成する3\n",
    "benchmarks01 = ['cg', 'ep', 'mg']\n",
    "benchmarks02 = ['ft', 'lu']\n",
    "benchmarks03 = [\"bt\", \"sp\"]\n",
    "benchmarks04 = ['is']\n",
    "print(f\"benchmarks01 = {benchmarks01}, benchmarks02 = {benchmarks02}, benchmarks03 = {benchmarks03}\")\n",
    "print(f\"↓ベンチマーククラスを固定したもの@{benchmarks01}\")\n",
    "GenGraphAveragePerProfileNum(benchmarks=benchmarks01, Fixed=\"Class\", Fix=\"B\", Predict=256, EnableTitle=True)\n",
    "print(f\"↓ベンチマーククラスを固定したもの@{benchmarks02}\")\n",
    "GenGraphAveragePerProfileNum(benchmarks=benchmarks02, Fixed=\"Class\", Fix=\"B\", Predict=256, EnableTitle=True)\n",
    "print(f\"↓ベンチマーククラスを固定したもの@{benchmarks03}\")\n",
    "GenGraphAveragePerProfileNum(benchmarks=benchmarks03, Fixed=\"Class\", Fix=\"B\", Predict=256, EnableTitle=True)\n",
    "print(f\"↓ベンチマーククラスを固定したもの@{benchmarks04}\")\n",
    "GenGraphAveragePerProfileNum(benchmarks=benchmarks04, Fixed=\"Class\", Fix=\"B\", Predict=256, EnableTitle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
