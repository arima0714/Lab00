{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二次元リストから生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1 各行を一つのリストとして並べる\n",
    "\n",
    "list = [\n",
    "    [1, 100, 0.33, 'AAA', 'AAA100'], \n",
    "    [2, 200, 0.67, 'BBB', 'BBB200'], \n",
    "    [3, 300, 1, 'CCC', 'CCC300'], \n",
    "    [4, 400, 1.33, 'DDD', 'DDD400'], \n",
    "    [5, 500, 1.67, 'EEE', 'EEE500'], \n",
    "    [6, 600, 2, 'FFF', 'FFF600']\n",
    "]\n",
    "\n",
    "# 2 表に変換\n",
    "# pd.DataFrame(list) : pandasのDataFrameで表に変換\n",
    "df = pd.DataFrame(list)\n",
    "# 行名・列名は自動で割り振られた番号になっている\n",
    "\n",
    "# 3 行名の変更\n",
    "df.index = ['row0', 'row1', 'row2', 'row3', 'row4', 'row5']\n",
    "\n",
    "# 4 列名の変更\n",
    "df.columns = ['col0', 'col1', 'col2', 'col3', 'col4']\n",
    "\n",
    "df\n",
    "\n",
    "# 1 各行を一つのリストとして並べる\n",
    "list = [\n",
    "[1, 100, 0.33, 'AAA', 'AAA100'], \n",
    "[2, 200, 0.67, 'BBB', 'BBB200'], \n",
    "[3, 300, 1, 'CCC', 'CCC300'], \n",
    "[4, 400, 1.33, 'DDD', 'DDD400'], \n",
    "[5, 500, 1.67, 'EEE', 'EEE500'], \n",
    "[6, 600, 2, 'FFF', 'FFF600']]\n",
    "\n",
    "\n",
    "#2 表に変換(オプションで行列名を指定)\n",
    "ind = ['row0', 'row1', 'row2', 'row3', 'row4', 'row5']\n",
    "col = ['col0', 'col1', 'col2', 'col3', 'col4']\n",
    "\n",
    "df = pd.DataFrame(list, index=ind, columns=col)\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "# 1 各行を一つのリストにする\n",
    "list = [\n",
    "['row0', 1, 100, 0.33, 'AAA', 'AAA100'], \n",
    "['row1', 2, 200, 0.67, 'BBB', 'BBB200'], \n",
    "['row2', 3, 300, 1, 'CCC', 'CCC300'], \n",
    "['row3', 4, 400, 1.33, 'DDD', 'DDD400'], \n",
    "['row4', 5, 500, 1.67, 'EEE', 'EEE500'], \n",
    "['row5', 6, 600, 2, 'FFF', 'FFF600'], ]\n",
    "\n",
    "# 2 表に変換\n",
    "df = pd.DataFrame(list)\n",
    "\n",
    "# 3 列名を変更\n",
    "df.columns = ['', 'col0', 'col1', 'col2', 'col3', 'col4']\n",
    "\n",
    "# 4 行名となる列を指定\n",
    "df = df.set_index('')\n",
    "\n",
    "df\n",
    "\n",
    "# 1 各行ごとのリストを作成\n",
    "\n",
    "listA = [1, 100, 0.33, 'AAA', 'AAA100']\n",
    "listB = [2, 200, 0.67, 'BBB', 'BBB200']\n",
    "listC = [3, 300, 1, 'CCC', 'CCC300']\n",
    "listD = [4, 400, 1.33, 'DDD', 'DDD400']\n",
    "listE = [5, 500, 1.67, 'EEE', 'EEE500']\n",
    "listF = [6, 600, 2, 'FFF', 'FFF600']\n",
    "\n",
    "# 2 まとめて表に変換\n",
    "\n",
    "df = pd.DataFrame([listA, listB, listC, listD, listE, listF])\n",
    "\n",
    "# 3 行名の変更\n",
    "df.index = ['row0', 'row1', 'row2', 'row3', 'row4', 'row5']\n",
    "\n",
    "# 4 列名の変更\n",
    "df.columns = ['col0', 'col1', 'col2', 'col3', 'col4']\n",
    "\n",
    "del list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_c_data = return_dict_summary_fixed()\n",
    "\n",
    "x = cg_c_data[\"processes\"]\n",
    "y = cg_c_data[\"ICNVRT\"]\n",
    "\n",
    "cg_icnvrt_lr = ModelLog10(x, y, \"CG\", \"ICNVRT\")\n",
    "\n",
    "cg_icnvrt_lr.calc_lr()\n",
    "\n",
    "cg_icnvrt_lr.plot_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_in_y = max(y)\n",
    "# 最大値の個数を取得\n",
    "y.tolist().count(max_in_y)\n",
    "# 最大値のインデックスで最小のもの\n",
    "y.tolist().index(max_in_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_branch = ModelBranch(x, y, \"CG\", \"ICNVRT\")\n",
    "\n",
    "model_branch.calc_lr()\n",
    "\n",
    "model_branch.calc_mape_score()\n",
    "\n",
    "print(model_branch.mape_score)\n",
    "\n",
    "model_branch.plot_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ハセガワ手法でMAPE表を作成するための準備\n",
    "\n",
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib.ipynb\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "# FT についてやってみる\n",
    "## FTに適した実行プロセス数を備えたリスト\n",
    "proceses = processes_excludeBTSP\n",
    "## FTの辞書を作成\n",
    "## <関数名>:<実行回数のリスト>, rowData:<実行プロセス数のリスト>\n",
    "FixedClassList_inFT = return_fixed_class(BenchMark=\"ft\", Processes=processes, FixedBenchMarkClass=\"C\")\n",
    "FixedClassDataFrame_inFT = pd.concat(FixedClassList_inFT, axis=1)\n",
    "DictData_inFT = return_dict_Data(FixedClassDataFrame_inFT)\n",
    "## 実行プロセス数のリストから組み合わせのリストを作成\n",
    "RowData_inFT = copy.deepcopy(DictData_inFT['rowData'])\n",
    "RowDataExcludeLargestProcess_inFT = RowData_inFT[:-1]\n",
    "print(f\"RowData_inFT={RowData_inFT}\")\n",
    "print(f\"RowDataExcludeLargestProcess_inFT={RowDataExcludeLargestProcess_inFT}\")\n",
    "CombinationProcesses_inFT = list(itertools.combinations(RowDataExcludeLargestProcess_inFT, 3))\n",
    "print(f\"CombinationProcesses_inFT={CombinationProcesses_inFT}\")\n",
    "\n",
    "SET_CLASS_inFT = DictData_inFT['SET_CLASS']\n",
    "SET_CLASSExcludeDataAtLargestProcess_inFT = SET_CLASS_inFT[:-1]\n",
    "print(f\"SET_CLASSExcludeDataAtLargestProcess_inFT={SET_CLASSExcludeDataAtLargestProcess_inFT}\")\n",
    "\n",
    "CombinationSET_CLASSExcludeDataAtLargestProcess_inFT = list(itertools.combinations(SET_CLASSExcludeDataAtLargestProcess_inFT, 3))\n",
    "print(f\"CombinationSET_CLASSExcludeDataAtLargestProcess_inFT={CombinationSET_CLASSExcludeDataAtLargestProcess_inFT}\")\n",
    "\n",
    "for i in range(len(CombinationSET_CLASSExcludeDataAtLargestProcess_inFT)):\n",
    "    for j in range(len(CombinationSET_CLASSExcludeDataAtLargestProcess_inFT[i])):\n",
    "        x_index = np.where(RowDataExcludeLargestProcess_inFT == CombinationProcesses_inFT[i][j])\n",
    "        y_index = np.where(SET_CLASSExcludeDataAtLargestProcess_inFT==CombinationSET_CLASSExcludeDataAtLargestProcess_inFT[i][j])\n",
    "        if(x_index != y_index):\n",
    "            print(\"E\", end=\", \")\n",
    "        else:\n",
    "            print(f\"y_index[{y_index}] == x_index[{x_index}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数：test_ratios\n",
    "# テスト用データとする割合のリスト\n",
    "test_ratios = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "##### 実行プロセス数のデータをもとにMAPE表を作成する処理 #####\n",
    "\n",
    "for test_ratio in test_ratios:\n",
    "    print(f\"test_ratio={test_ratio}\")\n",
    "    print(f\"train_list, test_list = {split_by_ratio(processes_excludeBTSP, test_ratio)} on processes_excludeBTSP\")\n",
    "    print(f\"train_list, test_list = {split_by_ratio(processes_onlyBTSP, test_ratio)} on processes_onlyBTSP\")\n",
    "    print(f\"\\n\")\n",
    "    fixed_class_list = [0] * len(benchmarks)\n",
    "    for i in range(len(fixed_class_list)):\n",
    "        if ( benchmarks[i] == \"bt\" or benchmarks[i] == \"sp\" ):\n",
    "            processes = processes_onlyBTSP\n",
    "        else:\n",
    "            processes = processes_excludeBTSP\n",
    "        fixed_class_list[i] = return_fixed_class(BenchMark = benchmarks[i], Processes = processes, FixedBenchMarkClass = \"C\")\n",
    "    fixed_class_DataFrame = [0] * len(fixed_class_list)\n",
    "    for i in range(len(fixed_class_list)):\n",
    "        fixed_class_DataFrame[i] = pd.concat(fixed_class_list[i] , axis=1)\n",
    "\n",
    "    # テーブルの元となるDataFrameを作成する\n",
    "    MapeTable_source = [0] * len(fixed_class_list)\n",
    "    for i in range(len(fixed_class_list)):\n",
    "        dict_data = return_dict_Data(fixed_class_DataFrame[i])\n",
    "        MapeTable_per_benchmark = return_MapeTable_per_benchmark(dict_data, test_ratio=test_ratio)\n",
    "        MapeTable_per_benchmark.to_csv(f\"./tmp_GenerateResources/{benchmarks[i]}_FixedClass_{test_ratio}.csv\")\n",
    "        MapeTable_row = return_MapeTable_row(MapeTable_per_benchmark, benchmarks[i])\n",
    "        MapeTable_source[i] = MapeTable_row\n",
    "    # テーブルの元となるDataFrameにつける列名のリスト\n",
    "    MapeTable_source_column_name = [\"線形モデル\", \"対数モデル\", \"反比例モデル\", \"分岐モデル\", \"ベンチマーク名\"]\n",
    "    MapeTable = pd.DataFrame(MapeTable_source)\n",
    "    MapeTable.columns = MapeTable_source_column_name\n",
    "    MapeTable = MapeTable.set_index('ベンチマーク名')\n",
    "    # テーブルを欲しい形でCSVとして出力する\n",
    "    save_MapeTable(MapeTable, suffix=f\"FixedClass{test_ratio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BenchmarkClasses = [\"A\", \"B\", \"C\", \"D\"]\n",
    "BenchmarkClasses_on_num = [1, 4, 16, 256]\n",
    "test_ratios = [0.3, 0.5, 0.8]\n",
    "\n",
    "##### ベンチマーククラスをもとにMAPE表を作成する処理 #####\n",
    "\n",
    "for test_ratio in test_ratios:\n",
    "    print(f\"test_ratio={test_ratio}\")\n",
    "    print(f\"train_list, test_list = {split_by_ratio(BenchmarkClasses, test_ratio)} on BenchmarkClasses\")\n",
    "    print(f\"train_list, test_list = {split_by_ratio(BenchmarkClasses_on_num, test_ratio)} on BenchmarkClasses_on_num\")\n",
    "    fixed_process_list = [0] * len(benchmarks)\n",
    "    for i in range(len(benchmarks)):\n",
    "        fixed_process_list[i] = return_fixed_process(BenchMark=benchmarks[i], BenchMarkClasses=BenchmarkClasses, FixedProcess=32)\n",
    "\n",
    "    fixed_process_DataFrame = [0] * len(benchmarks)\n",
    "    for i in range(len(benchmarks)):\n",
    "        fixed_process_DataFrame[i] = pd.concat(fixed_process_list[i], axis=1)\n",
    "\n",
    "    # テーブルの元となるDataFrameを作成する\n",
    "    MapeTable_source = []\n",
    "    for i in range(len(fixed_process_list)):\n",
    "        dict_data = return_dict_Data(fixed_process_DataFrame[i])\n",
    "        dict_data['rowData'] = BenchmarkClasses_on_num\n",
    "\n",
    "        try:\n",
    "            MapeTable_per_benchmark = return_MapeTable_per_benchmark(dict_data, test_ratio=test_ratio)\n",
    "        except:\n",
    "            print(f\"MAPEを算出するのに問題が生じました。@{benchmarks[i]}\")\n",
    "            continue\n",
    "        \n",
    "        MapeTable_per_benchmark = return_MapeTable_per_benchmark(dict_data, test_ratio=test_ratio)\n",
    "        MapeTable_per_benchmark.to_csv(f\"./tmp_GenerateResources/{benchmarks[i]}_FixedProcess_{test_ratio}.csv\")\n",
    "        MapeTable_row = return_MapeTable_row(MapeTable_per_benchmark, benchmarks[i])\n",
    "        MapeTable_source.append(MapeTable_row)\n",
    "    # テーブルの元となるDataFrameにつける列名のリスト\n",
    "    MapeTable_source_column_name = [\"線形モデル\", \"対数モデル\", \"反比例モデル\", \"分岐モデル\", \"ベンチマーク名\"]\n",
    "    MapeTable = pd.DataFrame(MapeTable_source)\n",
    "    MapeTable.columns = MapeTable_source_column_name\n",
    "    MapeTable = MapeTable.set_index('ベンチマーク名')\n",
    "    # テーブルを欲しい形でCSVとして出力する\n",
    "    save_MapeTable(MapeTable, suffix=f\"FixedProcess{test_ratio}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib.ipynb\n",
    "\n",
    "##### 訓練データでクラスを固定した際のMAPE表を作成する処理 #####\n",
    "\n",
    "# 変数：test_ratios\n",
    "# テスト用データとする割合のリスト\n",
    "test_ratios = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "for test_ratio in test_ratios:\n",
    "    print(f\"test_ratio={test_ratio}\")\n",
    "    print(f\"train_list, test_list = {split_by_ratio(processes_excludeBTSP, test_ratio)} on processes_excludeBTSP\")\n",
    "    print(f\"train_list, test_list = {split_by_ratio(processes_onlyBTSP, test_ratio)} on processes_onlyBTSP\")\n",
    "    print(f\"\\n\")\n",
    "    fixed_class_list = [0] * len(benchmarks)\n",
    "    for i in range(len(fixed_class_list)):\n",
    "        if ( benchmarks[i] == \"bt\" or benchmarks[i] == \"sp\" ):\n",
    "            processes = processes_onlyBTSP\n",
    "        else:\n",
    "            processes = processes_excludeBTSP\n",
    "        fixed_class_list[i] = return_fixed_class(BenchMark = benchmarks[i], Processes = processes, FixedBenchMarkClass = \"C\")\n",
    "    fixed_class_DataFrame = [0] * len(fixed_class_list)\n",
    "    for i in range(len(fixed_class_list)):\n",
    "        fixed_class_DataFrame[i] = pd.concat(fixed_class_list[i] , axis=1)\n",
    "\n",
    "    # テーブルの元となるDataFrameを作成する\n",
    "    MapeTable_source = [0] * len(fixed_class_list)\n",
    "    for i in range(len(fixed_class_list)):\n",
    "        dict_data = return_dict_Data(fixed_class_DataFrame[i])\n",
    "        MapeTable_per_benchmark = return_MapeTable_per_benchmark(dict_data, test_ratio=test_ratio, train=True)\n",
    "        MapeTable_per_benchmark.to_csv(f\"./tmp_GenerateResources/{benchmarks[i]}_FixedClassTrain_{test_ratio}.csv\")\n",
    "        MapeTable_row = return_MapeTable_row(MapeTable_per_benchmark, benchmarks[i])\n",
    "        MapeTable_source[i] = MapeTable_row\n",
    "    # テーブルの元となるDataFrameにつける列名のリスト\n",
    "    MapeTable_source_column_name = [\"線形モデル\", \"対数モデル\", \"反比例モデル\", \"分岐モデル\", \"ベンチマーク名\"]\n",
    "    MapeTable = pd.DataFrame(MapeTable_source)\n",
    "    MapeTable.columns = MapeTable_source_column_name\n",
    "    MapeTable = MapeTable.set_index('ベンチマーク名')\n",
    "    # テーブルを欲しい形でCSVとして出力する\n",
    "    save_MapeTable(MapeTable, suffix=f\"FixedClass{test_ratio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test_ratio=0.3\n",
      "train_list, test_list = (['A', 'B', 'C'], ['D']) on BenchmarkClasses\n",
      "\n",
      "\n",
      "学習用とテスト用にデータを分割するのに問題が生じています。\n",
      "len(self.train_x) == 3\n",
      "len(self.train_y) ==  0\n",
      "len(self.test_x) == 1\n",
      "len(self.test_y) == 1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-af0679905eb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdict_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_Process_DataFrame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdict_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rowData'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBenchmarkClasses_on_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mMapeTable_per_benchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_MapeTable_per_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mMapeTable_per_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./tmp_GenerateResources/{benchmarks[i]}_FixedProcessTrain_{test_ratio}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mMapeTable_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_MapeTable_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMapeTable_per_benchmark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2c32dac066ac>\u001b[0m in \u001b[0;36mreturn_MapeTable_per_benchmark\u001b[0;34m(dict_data, test_ratio, train)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoes_include_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunction_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mbefore_DataFrame_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_Mape_row_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunction_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfunction_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# 変数：return_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2c32dac066ac>\u001b[0m in \u001b[0;36mreturn_Mape_row_list\u001b[0;34m(x, y, function_name, test_ratio, train)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# 線形モデル\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmodel_lin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelLin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel_lin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mmodel_lin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_mape_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmodel_lin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_mape_score_InTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-055ac31e2d00>\u001b[0m in \u001b[0;36mcalc_lr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_r2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[1;32m    506\u001b[0m                                    y_numeric=True, multi_output=True)\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    802\u001b[0m                     estimator=estimator)\n\u001b[1;32m    803\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n\u001b[0m\u001b[1;32m    805\u001b[0m                         ensure_2d=False, dtype=None)\n\u001b[1;32m    806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001b[0m\u001b[1;32m    651\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib.ipynb\n",
    "\n",
    "##### 訓練データでプロセスを固定した際のMAPE表を作成する処理 #####\n",
    "\n",
    "# 変数：test_ratios\n",
    "# テスト用データとする割合のリスト\n",
    "BenchmarkClasses = [\"A\", \"B\", \"C\", \"D\"]\n",
    "BenchmarkClasses_on_num = [1, 4, 16, 256]\n",
    "test_ratios = [0.3, 0.5, 0.8]\n",
    "\n",
    "for test_ratio in test_ratios:\n",
    "    print(f\"test_ratio={test_ratio}\")\n",
    "    print(f\"train_list, test_list = {split_by_ratio(BenchmarkClasses, test_ratio)} on BenchmarkClasses\")\n",
    "    print(f\"\\n\")\n",
    "    fixed_Process_list = [0] * len(benchmarks)\n",
    "    for i in range(len(fixed_Process_list)):\n",
    "        fixed_Process_list[i] = return_fixed_process(BenchMark = benchmarks[i], BenchMarkClasses = BenchmarkClasses, FixedProcess = 256)\n",
    "    fixed_Process_DataFrame = [0] * len(fixed_Process_list)\n",
    "    for i in range(len(fixed_Process_list)):\n",
    "        fixed_Process_DataFrame[i] = pd.concat(fixed_Process_list[i] , axis=1)\n",
    "\n",
    "    # テーブルの元となるDataFrameを作成する\n",
    "    MapeTable_source = [0] * len(fixed_Process_list)\n",
    "    for i in range(len(fixed_Process_list)):\n",
    "        dict_data = return_dict_Data(fixed_Process_DataFrame[i])\n",
    "        dict_data['rowData'] = BenchmarkClasses_on_num\n",
    "        MapeTable_per_benchmark = return_MapeTable_per_benchmark(dict_data, test_ratio=test_ratio, train=True)\n",
    "        MapeTable_per_benchmark.to_csv(f\"./tmp_GenerateResources/{benchmarks[i]}_FixedProcessTrain_{test_ratio}.csv\")\n",
    "        MapeTable_row = return_MapeTable_row(MapeTable_per_benchmark, benchmarks[i])\n",
    "        MapeTable_source[i] = MapeTable_row\n",
    "    # テーブルの元となるDataFrameにつける列名のリスト\n",
    "    MapeTable_source_column_name = [\"線形モデル\", \"対数モデル\", \"反比例モデル\", \"分岐モデル\", \"ベンチマーク名\"]\n",
    "    MapeTable = pd.DataFrame(MapeTable_source)\n",
    "    MapeTable.columns = MapeTable_source_column_name\n",
    "    MapeTable = MapeTable.set_index('ベンチマーク名')\n",
    "    # テーブルを欲しい形でCSVとして出力する\n",
    "    save_MapeTable(MapeTable, suffix=f\"FixedClass{test_ratio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib.ipynb\n",
    "\n",
    "##### ベンチマーククラスをCに固定して各関数で最も予測に適したモデルを算出する処理 #####\n",
    "\n",
    "# 変数：test_ratios\n",
    "# テスト用データとする割合のリスト\n",
    "test_ratios = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "i = 3\n",
    "test_ratio = test_ratios[i]\n",
    "\n",
    "# 変数：MapeTable_AtFt\n",
    "# ベンチマークFTのMAPE表\n",
    "MapeTable_AtFt = pd.read_csv(f\"./tmp_GenerateResources/{benchmarks[i]}_FixedClassTrain_{test_ratio}.csv\")\n",
    "MapeTable_AtFt = MapeTable_AtFt.set_index(\"function name\")\n",
    "# 変数：MapeTableColumns_AtFt, MapeTableIndex_AtFt\n",
    "# ベンチマークFTのMAPE表の列名・行名\n",
    "MapeTableColumns_AtFt= MapeTable_AtFt.columns.to_numpy()\n",
    "MapeTableIndex_AtFt = MapeTable_AtFt.index.to_numpy()\n",
    "\n",
    "# 変数：ModelDataFrame_AtFt\n",
    "# ベンチマークFTにおける各関数の学習済みモデルが格納されている\n",
    "if ( benchmarks[i] == \"bt\" or benchmarks[i] == \"sp\" ):\n",
    "    processes = processes_onlyBTSP\n",
    "else:\n",
    "    processes = processes_excludeBTSP\n",
    "FixedClassList_AtFt = return_fixed_class(BenchMark = benchmarks[i], Processes = processes, FixedBenchMarkClass = \"C\")\n",
    "FixedClassDataFrame_AtFt = pd.concat(FixedClassList_AtFt , axis=1)\n",
    "DictData_AtFt = return_dict_Data(FixedClassDataFrame_AtFt)\n",
    "ModelDataFrameSourceList_AtFt = []\n",
    "x_list = DictData_AtFt['rowData']\n",
    "for FunctionName in MapeTableIndex_AtFt:\n",
    "    y_list = DictData_AtFt[FunctionName]\n",
    "    ModelDataFrameSourceList_AtFt.append(return_Model_row_list(x=x_list, y=y_list, function_name=FunctionName, test_ratio=test_ratio, train=True))\n",
    "MapeTable_AtFt\n",
    "ModelDataFrameSourceListCollumnsName = [\"FunctionName\", \"ModelLin\", \"ModelLog\", \"ModelIp\", \"ModelBranch\"]\n",
    "ModelDataFrame_AtFt = pd.DataFrame(ModelDataFrameSourceList_AtFt)\n",
    "ModelDataFrame_AtFt.columns = ModelDataFrameSourceListCollumnsName\n",
    "ModelDataFrame_AtFt = ModelDataFrame_AtFt.set_index(\"FunctionName\")\n",
    "\n",
    "# 変数：BestModelsDict\n",
    "# ベンチマークFTの各関数における最適なモデルが格納されている\n",
    "# 辞書の形式は次の通り\n",
    "# <関数名>:<自作クラスによる最適モデル>\n",
    "BestModelsDict = {}\n",
    "ModelNames = copy.deepcopy(ModelDataFrameSourceListCollumnsName)\n",
    "ModelNames.remove(\"FunctionName\")\n",
    "for FunctionName in MapeTableIndex_AtFt:\n",
    "    MapeInFunction = MapeTable_AtFt.loc[FunctionName].to_list()\n",
    "    SmallestModelIndex = MapeInFunction.index(min(MapeInFunction))\n",
    "    SmallestModelName = ModelNames[SmallestModelIndex]\n",
    "    BestModelsDict[FunctionName] = ModelDataFrame_AtFt.at[FunctionName, SmallestModelName]\n",
    "\n",
    "BestModelsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib.ipynb\n",
    "\n",
    "##### 実行プロセス数を256に固定して各関数で最も予測に適したモデルを算出する処理 #####\n",
    "\n",
    "# 変数：test_ratios\n",
    "# テスト用データとする割合のリスト\n",
    "BenchmarkClasses = [\"A\", \"B\", \"C\", \"D\"]\n",
    "BenchmarkClasses_on_num = [1, 4, 16, 256]\n",
    "test_ratios = [0.3, 0.5, 0.8]\n",
    "\n",
    "i = 3\n",
    "test_ratio = test_ratios[i]\n",
    "\n",
    "# 変数：MapeTable_AtFt\n",
    "# ベンチマークFTのMAPE表\n",
    "MapeTable_AtFt = pd.read_csv(f\"./tmp_GenerateResources/{benchmarks[i]}_FixedProcessTrain_{test_ratio}.csv\")\n",
    "MapeTable_AtFt = MapeTable_AtFt.set_index(\"function name\")\n",
    "# 変数：MapeTableColumns_AtFt, MapeTableIndex_AtFt\n",
    "# ベンチマークFTのMAPE表の列名・行名\n",
    "MapeTableColumns_AtFt= MapeTable_AtFt.columns.to_numpy()\n",
    "MapeTableIndex_AtFt = MapeTable_AtFt.index.to_numpy()\n",
    "\n",
    "# 変数：ModelDataFrame_AtFt\n",
    "# ベンチマークFTにおける各関数の学習済みモデルが格納されている\n",
    "if ( benchmarks[i] == \"bt\" or benchmarks[i] == \"sp\" ):\n",
    "    processes = processes_onlyBTSP\n",
    "else:\n",
    "    processes = processes_excludeBTSP\n",
    "FixedClassList_AtFt = return_fixed_class(BenchMark = benchmarks[i], Processes = processes, FixedBenchMarkClass = \"C\")\n",
    "FixedClassDataFrame_AtFt = pd.concat(FixedClassList_AtFt , axis=1)\n",
    "DictData_AtFt = return_dict_Data(FixedClassDataFrame_AtFt)\n",
    "ModelDataFrameSourceList_AtFt = []\n",
    "x_list = DictData_AtFt['rowData']\n",
    "for FunctionName in MapeTableIndex_AtFt:\n",
    "    y_list = DictData_AtFt[FunctionName]\n",
    "    ModelDataFrameSourceList_AtFt.append(return_Model_row_list(x=x_list, y=y_list, function_name=FunctionName, test_ratio=test_ratio, train=True))\n",
    "MapeTable_AtFt\n",
    "ModelDataFrameSourceListCollumnsName = [\"FunctionName\", \"ModelLin\", \"ModelLog\", \"ModelIp\", \"ModelBranch\"]\n",
    "ModelDataFrame_AtFt = pd.DataFrame(ModelDataFrameSourceList_AtFt)\n",
    "ModelDataFrame_AtFt.columns = ModelDataFrameSourceListCollumnsName\n",
    "ModelDataFrame_AtFt = ModelDataFrame_AtFt.set_index(\"FunctionName\")\n",
    "\n",
    "# 変数：BestModelsDict\n",
    "# ベンチマークFTの各関数における最適なモデルが格納されている\n",
    "# 辞書の形式は次の通り\n",
    "# <関数名>:<自作クラスによる最適モデル>\n",
    "BestModelsDict = {}\n",
    "ModelNames = copy.deepcopy(ModelDataFrameSourceListCollumnsName)\n",
    "ModelNames.remove(\"FunctionName\")\n",
    "for FunctionName in MapeTableIndex_AtFt:\n",
    "    MapeInFunction = MapeTable_AtFt.loc[FunctionName].to_list()\n",
    "    SmallestModelIndex = MapeInFunction.index(min(MapeInFunction))\n",
    "    SmallestModelName = ModelNames[SmallestModelIndex]\n",
    "    BestModelsDict[FunctionName] = ModelDataFrame_AtFt.at[FunctionName, SmallestModelName]\n",
    "\n",
    "BestModelsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ##### ベンチマーククラスをもとにMAPE表を作成する処理 #####\n",
    "\n",
    "# for test_ratio in test_ratios:\n",
    "#     print(f\"test_ratio={test_ratio}\")\n",
    "#     print(f\"train_list, test_list = {split_by_ratio(BenchmarkClasses, test_ratio)} on BenchmarkClasses\")\n",
    "#     print(f\"train_list, test_list = {split_by_ratio(BenchmarkClasses_on_num, test_ratio)} on BenchmarkClasses_on_num\")\n",
    "#     fixed_process_list = [0] * len(benchmarks)\n",
    "#     for i in range(len(benchmarks)):\n",
    "#         fixed_process_list[i] = return_fixed_process(BenchMark=benchmarks[i], BenchMarkClasses=BenchmarkClasses, FixedProcess=32)\n",
    "\n",
    "#     fixed_process_DataFrame = [0] * len(benchmarks)\n",
    "#     for i in range(len(benchmarks)):\n",
    "#         fixed_process_DataFrame[i] = pd.concat(fixed_process_list[i], axis=1)\n",
    "\n",
    "#     # テーブルの元となるDataFrameを作成する\n",
    "#     MapeTable_source = []\n",
    "#     for i in range(len(fixed_process_list)):\n",
    "#         dict_data = return_dict_Data(fixed_process_DataFrame[i])\n",
    "#         dict_data['rowData'] = BenchmarkClasses_on_num\n",
    "\n",
    "#         try:\n",
    "#             MapeTable_per_benchmark = return_MapeTable_per_benchmark(dict_data, test_ratio=test_ratio)\n",
    "#         except:\n",
    "#             print(f\"MAPEを算出するのに問題が生じました。@{benchmarks[i]}\")\n",
    "#             continue\n",
    "        \n",
    "#         MapeTable_per_benchmark = return_MapeTable_per_benchmark(dict_data, test_ratio=test_ratio)\n",
    "#         MapeTable_per_benchmark.to_csv(f\"./tmp_GenerateResources/{benchmarks[i]}_FixedProcess_{test_ratio}.csv\")\n",
    "#         MapeTable_row = return_MapeTable_row(MapeTable_per_benchmark, benchmarks[i])\n",
    "#         MapeTable_source.append(MapeTable_row)\n",
    "#     # テーブルの元となるDataFrameにつける列名のリスト\n",
    "#     MapeTable_source_column_name = [\"線形モデル\", \"対数モデル\", \"反比例モデル\", \"分岐モデル\", \"ベンチマーク名\"]\n",
    "#     MapeTable = pd.DataFrame(MapeTable_source)\n",
    "#     MapeTable.columns = MapeTable_source_column_name\n",
    "#     MapeTable = MapeTable.set_index('ベンチマーク名')\n",
    "#     # テーブルを欲しい形でCSVとして出力する\n",
    "#     save_MapeTable(MapeTable, suffix=f\"FixedProcess{test_ratio}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "20ea737a692ad9331495a19ba7cc0bf6d1e8652119322fabf661903bfd24f6c5"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}