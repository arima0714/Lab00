{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修正したモデルから卒論時に集計したデータを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 表\n",
    "\n",
    "| ベンチマーク名 | 平均誤差率(%) | コスト比(%) |\n",
    "|---------|----------|---------|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 表\n",
    "\n",
    "| ベンチマーク名 | 採用割合(最大MAPE(%), 最小MAPE(%)) |\n",
    "|---------|----------------------------|\n",
    "|         | モデル(1), モデル(2), ...        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 平均誤差率：大規模実行時の関数コール回数との比較\n",
    "* MAPE：トレーニングデータとの比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.xlabel(\"使用したプロファイル数\")\n",
    "plt.ylabel(\"平均誤差率(%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.get_option(\"display.max_columns\")\n",
    "# pd.get_option(\"display.max_rows\")\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "benchmark = \"cg\"\n",
    "fix = \"Class\"\n",
    "if benchmark == \"bt\" or benchmark == \"sp\":\n",
    "    processes = processes_onlyBTSP\n",
    "else:\n",
    "    processes = processes_excludeBTSP\n",
    "benchmarkClasses = [\"A\", \"B\", \"C\", \"D\"]\n",
    "targetNumOfProcess = 256\n",
    "fixedBenchmarkClass = \"B\"\n",
    "fixedProcess = 64\n",
    "\n",
    "# 引数の条件に合った生の実験データを取得する\n",
    "DF = returnRawDFperBenchmark(Benchmark=benchmark, fix=fix, benchmarkClass=benchmarkClasses,\n",
    "                             FixedProcess=fixedProcess, Processes=processes, FixedBenchmarkClass=fixedBenchmarkClass)\n",
    "# 取得した生の実験データから NaN が含まれる関数の実験データを削除\n",
    "noNaNDF = DF.dropna(how='any')\n",
    "# noNaNDF\n",
    "\n",
    "returnedCalculatedDF = return_calculatedDF(benchmark=benchmark, noNaNDF=noNaNDF,\n",
    "                                           targetNumOfProcess=targetNumOfProcess, targetProblemSize=fixedBenchmarkClass, fix=fix)\n",
    "# returnedCalculatedDF\n",
    "\n",
    "# numOfData列の要素一覧を作成し、ソートされたリストを、listOfNumDataに格納する\n",
    "listOfNumOfData = returnedCalculatedDF['numOfData'].tolist()\n",
    "listOfNumOfData = sorted(list(set(listOfNumOfData)))\n",
    "# listOfNumOfData\n",
    "\n",
    "\n",
    "# 使用したプロファイル数をキー・最適モデルでの相対誤差の平均をバリューとした辞書を作成する\n",
    "dictAverageRelativeErrorOfBestModel = {}\n",
    "x = []\n",
    "y = []\n",
    "for numOfData in listOfNumOfData:\n",
    "    # 使用したプロファイル数で抽出\n",
    "    extractedPerNumOfProfileDF = returnedCalculatedDF[returnedCalculatedDF['numOfData'] == numOfData]\n",
    "    meanDF = extractedPerNumOfProfileDF.mean()\n",
    "    data = meanDF.at['relativeErrorOfBestModel']\n",
    "    dictAverageRelativeErrorOfBestModel[numOfData] = data\n",
    "\n",
    "x = list(dictAverageRelativeErrorOfBestModel.keys())\n",
    "x\n",
    "y = [dictAverageRelativeErrorOfBestModel[key] for key in x]\n",
    "y\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, marker='o')\n",
    "plt.xlabel(\"使用したプロファイル数[％]\")\n",
    "plt.ylabel(\"平均絶対誤差率\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベンチマーク名・関数名・プロセス数・問題サイズを指定することで、その条件での関数コール回数を取得する関数\n",
    "\n",
    "def returnSpecificData(benchmarkName=\"cg\", functionName=\".TAU_application\", process=256, benchmarkClass=\"D\"):\n",
    "    targetRawDF = returnRawDF(Benchmark=benchmarkName, functionName=functionName, benchmarkClass=[\n",
    "                              benchmarkClass], FixedProcess=process, Processes=[process], FixedBenchmarkClass=benchmarkClass)\n",
    "    return targetRawDF.iat[0, 0]\n",
    "# returnSpecificData(benchmarkName=\"mg\", functionName=\"BUBBLE\", process=256, benchmarkClass=\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmarksからbt, spを除外する\n",
    "benchmarks = [benchmark for benchmark in benchmarks if benchmark !=\n",
    "              'bt' and benchmark != 'sp']\n",
    "# pandasのDFをprintした時の幅を広げる\n",
    "pd.set_option('display.width', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTmp = returnDictForPlotPerNumOfUsedData(Benchmark=benchmarks, fix=\"Class\", benchmarkClass=[\n",
    "    \"A\", \"B\", \"C\", \"D\"], FixedProcess=64, Processes=[1, 2, 4, 8, 16, 32, 64, 128, 256], FixedBenchmarkClass=\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.4g}'.format\n",
    "\n",
    "tmpDF = pd.DataFrame()\n",
    "for benchmark in benchmarks:\n",
    "    listToLearn = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "    listToPredict = [256]\n",
    "    benchmark_x = dictTmp[benchmark][\"x\"]\n",
    "    benchmark_y = dictTmp[benchmark][\"y\"]\n",
    "    index = benchmark_x.index(len(listToLearn))\n",
    "    MAPE = benchmark_y[index]\n",
    "    relativeCost = returnRelativeCost(benchmark=benchmark, variablesToLearn=listToLearn,\n",
    "                                      variablesToPredict=listToPredict, fixedClassOrProcess=\"Class\", fixed=\"C\")\n",
    "    dictRowData = {\"ベンチマーク名\": benchmark.upper(\n",
    "    ), \"平均絶対誤差率[％]\": MAPE, \"相対コスト[％]\": relativeCost}\n",
    "    iDF = pd.DataFrame.from_dict(dictRowData, orient='index').T\n",
    "    tmpDF = tmpDF.append(iDF)\n",
    "tmpDFMean = tmpDF.mean()\n",
    "type(tmpDFMean)\n",
    "print(tmpDF.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictTmp\n",
    "\n",
    "plt.figure(figsize=(5.72, 4), dpi=200)\n",
    "for benchmark in list(dictTmp.keys()):\n",
    "    x = dictTmp[benchmark][\"x\"]\n",
    "    y = dictTmp[benchmark][\"y\"]\n",
    "    plt.plot(x, y, marker='o', label=benchmark.upper())\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"使用したプロファイル数\")\n",
    "    plt.ylabel(\"平均絶対誤差率[％]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.72, 4), dpi=200)\n",
    "\n",
    "# Extra-PでfixProcessデータを入力して出力したモデルの図時\n",
    "plot_x = np.linspace(0.8, 256, 500)\n",
    "# -3590464.6990329633 + 3759195.349891038 * p^(1/4)\n",
    "plot_y = []\n",
    "for x in plot_x:\n",
    "    plot_y.append(2286768.3333333326 + 301997.61904761934 * math.log2(x)**(1))\n",
    "plt.plot(plot_x, plot_y, label=\"ExtraP\")\n",
    "\n",
    "x = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "y = [1984770.0, 2263540.0, 2821070.0, 3936140.0,\n",
    "     3936140.0, 3936140.0, 3936140.0, 3936140.0]\n",
    "x = np.array(x).reshape(-1, 1)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "plt.scatter(x, y, marker=\"o\", label=\"予測に用いた関数コール回数\")\n",
    "plot_x = np.array(plot_x).reshape(-1, 1)\n",
    "x_target = [256]\n",
    "y_target = [3936140]\n",
    "plt.scatter(x_target, y_target, marker=\"o\", label=\"予測したい関数コール回数の実測値\")\n",
    "\n",
    "benchmarkName = \"CG\"\n",
    "functionName = \"ICNVRT\"\n",
    "\n",
    "# 線形モデル\n",
    "# 対数モデル\n",
    "\n",
    "# 反比例モデル\n",
    "modelIpMk2 = ModelIp_mk2(train_x=x, train_y=y, target_x=x_target, target_y=y_target,\n",
    "                         benchmark_name=benchmarkName, function_name=functionName)\n",
    "modelIpMk2.calc_lr()\n",
    "plot_y_IpMk2 = modelIpMk2.predict(plot_x)\n",
    "plt.plot(plot_x, plot_y_IpMk2, label=\"反比例モデル\")\n",
    "# 線形飽和モデル\n",
    "modelBranchMk2 = ModelBranch_mk2(train_x=x, train_y=y, target_x=x_target,\n",
    "                                 target_y=y_target, benchmark_name=benchmarkName, function_name=functionName)\n",
    "modelBranchMk2.calc_lr()\n",
    "plot_y_BranchMk2 = modelBranchMk2.predict(plot_x)\n",
    "plt.plot(plot_x, plot_y_BranchMk2, label=\"線形飽和モデル\")\n",
    "# # 線形モデル\n",
    "# model_lin = ModelLin(x, y, \"CG\", \"ICNVRT\", test_ratio=0)\n",
    "# model_lin.calc_lr()\n",
    "# plot_y_lin = model_lin.predict(plot_x)\n",
    "# plt.plot(plot_x, plot_y_lin, label=\"線形モデル\")\n",
    "# # 対数モデル\n",
    "# model_log10 = ModelLog10(x, y, \"CG\", \"ICNVRT\", test_ratio=0)\n",
    "# model_log10.calc_lr()\n",
    "# plot_y_log10 = model_log10.predict(plot_x)\n",
    "# plt.plot(plot_x, plot_y_log10, label=\"対数モデル\")\n",
    "# # 反比例モデル\n",
    "# model_ip = ModelIP(x, y, \"CG\", \"ICNVRT\", test_ratio=0)\n",
    "# model_ip.calc_lr()\n",
    "# plot_y_ip = model_ip.predict(plot_x)\n",
    "# plt.plot(plot_x, plot_y_ip, label=\"反比例モデル\")\n",
    "# # 線形飽和モデル\n",
    "# model_branch = ModelBranch(x, y, \"CG\", \"ICNVRT\", test_ratio=0)\n",
    "# model_branch.calc_lr()\n",
    "# plot_y_branch = model_branch.predict(plot_x)\n",
    "# plt.plot(plot_x, plot_y_branch, label=\"線形飽和モデル\")\n",
    "# 凡例の表示\n",
    "plt.legend()\n",
    "# 軸ラベルの設定\n",
    "plt.ylabel(\"関数コール回数\")\n",
    "plt.xlabel(\"実行コア数\")\n",
    "\n",
    "plt.scatter(x, y, marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 実際にプロットする\n",
    "\n",
    "\n",
    "# print(f\"fix={fix}, benchmarkClasses={benchmarkClasses}, fixedProcess={fixedProcess}, Processes={processes}, FixedBenchmarkClass={fixedBenchmarkClass}\")\n",
    "# print(f\"targetNumOfProcess={targetNumOfProcess}, targetProblemSize={fixedBenchmarkClass}, fix={fix}\")\n",
    "\n",
    "# DF = returnRawDFperBenchmark(Benchmark=\"mg\", fix=\"Process\", benchmarkClass=[\"A\", \"B\", \"C\", \"D\"], Processes=[\n",
    "#                              1, 2, 4, 8, 16, 32, 64, 128, 256], FixedBenchmarkClass=\"B\", FixedProcess=64)\n",
    "# DF.dropna(how='any')\n",
    "# DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib/lib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmarkNamesExcludeBTSP = [\"cg\", \"ep\", \"ft\", \"is\", \"lu\", \"mg\"]\n",
    "# classes = [\"A\", \"B\", \"C\", \"D\"]\n",
    "classes = [\"B\"]\n",
    "processes = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "targetIndex = -1\n",
    "csvDirPath = \"./csv_files/\"\n",
    "\n",
    "dfByDatumExcludeBTSP = returnDFSummarizedData(\n",
    "    benchmarkNames=benchmarkNamesExcludeBTSP, classes=classes, processes=processes, targetIndex=targetIndex, csvDirPath=csvDirPath)\n",
    "# dfByDatumExcludeBTSP\n",
    "\n",
    "dictForLatexTable = {}\n",
    "numOfData = 0\n",
    "for benchmarkName in benchmarkNamesExcludeBTSP:\n",
    "    dictForLatexTable[benchmarkName] = dfByDatumExcludeBTSP[dfByDatumExcludeBTSP[\"benchmarkName\"] == benchmarkName]\n",
    "    numOfData += len(\n",
    "        dfByDatumExcludeBTSP[dfByDatumExcludeBTSP[\"benchmarkName\"] == benchmarkName])\n",
    "\n",
    "numOfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "listForDF = []\n",
    "\n",
    "for benchmarkName in benchmarkNamesExcludeBTSP:\n",
    "    listForDF.append(returnSeriesOfDatumPerBenchmark(\n",
    "        inputDF=dictForLatexTable[benchmarkName]))\n",
    "DF = pd.DataFrame(listForDF)\n",
    "print(DF.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_returnSeriesOfDatumPerBenchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultIs = dictForLatexTable[\"is\"]\n",
    "# resultIs\n",
    "resultIsAtModelBranch = resultIs[resultIs[\"objectBestModelName\"]\n",
    "                                 == \"ModelBranch\"]\n",
    "datumX = resultIsAtModelBranch[\"usedDataX\"].tolist()\n",
    "datumY = resultIsAtModelBranch[\"usedDataY\"].tolist()\n",
    "\n",
    "datumX\n",
    "datumY\n",
    "\n",
    "# returnSeriesOfData(benchmarkName=\"is\", functionName=\"double_randlc(double_*_double_*)\", rawX=dataX, rawY=dataY, fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=-1, csvDirPath=\"./csv_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultIs = dictForLatexTable[\"ft\"]\n",
    "# resultIs\n",
    "resultIsAtModelBranch = resultIs[resultIs[\"objectBestModelName\"]\n",
    "                                 == \"ModelBranch\"]\n",
    "resultIsAtModelBranchOfNotLowMAPE = resultIsAtModelBranch[\n",
    "    resultIsAtModelBranch[\"MAPEOfBestModel\"] > 1]\n",
    "resultIsAtModelBranchOfNotLowMAPE\n",
    "datumX = resultIsAtModelBranchOfNotLowMAPE[\"usedDataX\"].tolist()\n",
    "datumY = resultIsAtModelBranchOfNotLowMAPE[\"usedDataY\"].tolist()\n",
    "\n",
    "datumX\n",
    "datumY\n",
    "\n",
    "for dataIndex in range(len(datumX)):\n",
    "    plt.figure()\n",
    "    plt.scatter(datumX[dataIndex], datumY[dataIndex])\n",
    "\n",
    "# returnSeriesOfData(benchmarkName=\"is\", functionName=\"double_randlc(double_*_double_*)\", rawX=dataX, rawY=dataY, fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=-1, csvDirPath=\"./csv_files\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 実験用に小規模なリスト\n",
    "benchmarkNames = [\"cg\"]\n",
    "classes = [\"B\"]\n",
    "processes = [1, 2, 4, 8, 16, 32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 生データの取得\n",
    "cgDF = returnCollectedExistingData(benchmarkNames=[\"cg\"], classes=[\"A\", \"B\", \"C\", \"D\"], processes=[\n",
    "                                   1, 2, 4, 8, 16, 32, 64, 128, 256], csvDirPath=\"./csv_files/\")\n",
    "cgDF\n",
    "# ベンチマーククラスがAの情報を取得\n",
    "cgDFfixedA = cgDF[cgDF[\"benchmarkClass\"] == \"A\"]\n",
    "cgDFfixedA\n",
    "# 関数名のリストを取得\n",
    "functionNames = sorted(list(set(cgDFfixedA[\"functionName\"])))\n",
    "print(functionNames)\n",
    "\n",
    "# 関数名を関数名のリストから抽出\n",
    "functionNameCG = cgDFfixedA[cgDFfixedA[\"functionName\"] == \"CG\"]\n",
    "functionNameCG\n",
    "\n",
    "# 説明変数と目的変数とをリスト化したものを抽出\n",
    "# プロセス数\n",
    "raw_x = functionNameCG['process'].tolist()\n",
    "# 関数コール回数\n",
    "raw_y = functionNameCG['functionCallNum'].tolist()\n",
    "\n",
    "print(f\"raw_x={raw_x}\")\n",
    "print(f\"raw_y={raw_y}\")\n",
    "\n",
    "bencmarkName = \"CG\"\n",
    "functionName = \"CG\"\n",
    "fixProcessOrClass = \"Class\"\n",
    "fixed = \"A\"\n",
    "targetProcess = 256\n",
    "targetBenchmarkClass = fixed\n",
    "targetFunctionCallNum = raw_y[-1]\n",
    "returnSeriesOfData(benchmarkName=\"benhmarkName\", functionName=\"functionName\", rawX=[1, 2, 3], rawY=[\n",
    "                   1, 2, 3], fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=-1, csvDirPath=\"./csv_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ノートブック中で変数のみを記述することでデータフレームをきれいに表示させる設定の有効化\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib/lib.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題サイズD, コア数256での関数コール回数を予測する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO：BT, SP以外のベンチマーク名を入れる\n",
    "benchmarkNames = ['cg', 'ep', 'ft', 'is', 'lu', 'mg']\n",
    "classes = [\"A\", \"B\", \"C\", \"D\"]\n",
    "processes = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "\n",
    "dictForSummarizedResult = {}\n",
    "columnName = [\"benchmarkName\", \"functionName\", \"score\", \"relativeErrorRate\"]\n",
    "dfForSummarizedResult = pd.DataFrame(columns=columnName)\n",
    "for benchmarkName in benchmarkNames:\n",
    "    # ベンチマークごとにscoreを保持するためのリスト\n",
    "    listForSummarizedResultPerBenchmarkName = []\n",
    "    # 学習用生データ\n",
    "    DF = returnCollectedExistingData(benchmarkNames=[\n",
    "                                     benchmarkName], classes=classes, processes=processes, csvDirPath=\"./csv_files/\")\n",
    "    # 重複のない関数名のリスト\n",
    "    functionNames = list(set(DF[\"functionName\"]))\n",
    "    usefulFunctionNames = []\n",
    "    # このループで関数ごとのデータが問題サイズパターン数xコア数パターン数 分だけ存在する関数名のリストを作成する\n",
    "    for functionName in functionNames:\n",
    "        # 関数ごとに生データを集計\n",
    "        dfPerFunction = DF[DF[\"functionName\"] == functionName]\n",
    "        if len(classes) * len(processes) == len(dfPerFunction):\n",
    "            usefulFunctionNames.append(functionName)\n",
    "    if len(usefulFunctionNames) == 0:\n",
    "        continue\n",
    "    # 関数ごとのデータを抽出\n",
    "    for functionName in usefulFunctionNames:\n",
    "        # 問題サイズを数値化したカラムを追加\n",
    "        listBenchmarkClass = DF[\"benchmarkClass\"].tolist()\n",
    "        DFWithNumInBenchmarkClass = DF.assign(\n",
    "            benchmarkClassInNum=convertBenchmarkClasses_problemSizeInNPB(listBenchmarkClass))\n",
    "        # 学習用データ\n",
    "        dfPerFunctionForTrain = DFWithNumInBenchmarkClass[(\n",
    "            DFWithNumInBenchmarkClass[\"functionName\"] == functionName)]\n",
    "        dfPerFunctionForTest = DFWithNumInBenchmarkClass[(DFWithNumInBenchmarkClass[\"functionName\"] == functionName) & (\n",
    "            DFWithNumInBenchmarkClass[\"benchmarkClass\"] == \"D\") & (DFWithNumInBenchmarkClass[\"process\"] == 256)]\n",
    "\n",
    "        # x:説明変数, t:目的変数\n",
    "        trainX = dfPerFunctionForTrain[[\"process\", \"benchmarkClassInNum\"]]\n",
    "        trainT = dfPerFunctionForTrain[[\"functionCallNum\"]]\n",
    "        testX = dfPerFunctionForTest[[\"process\", \"benchmarkClassInNum\"]]\n",
    "        testT = dfPerFunctionForTest[[\"functionCallNum\"]]\n",
    "        # 重回帰分析する\n",
    "        reg_model = LinearRegression()\n",
    "        reg_model.fit(trainX, trainT)\n",
    "        # 関数ごとの結果をベンチマークごとの結果に入れる\n",
    "        scorePerFunction = reg_model.score(trainX, trainT)\n",
    "        listForSummarizedResultPerBenchmarkName.append(scorePerFunction)\n",
    "        # 予測を実施して、相対誤差を算出\n",
    "        predictedTByTestX = reg_model.predict(testX)\n",
    "        predictedData = predictedTByTestX[0][0]\n",
    "        realData = testT[\"functionCallNum\"].tolist()[0]\n",
    "        relativeErrorPerFunction = abs(predictedData - realData)/realData * 100\n",
    "        ##\n",
    "        dfPerFunction = pd.DataFrame(index=columnName, data=[\n",
    "                                     benchmarkName, functionName, scorePerFunction, relativeErrorPerFunction]).T\n",
    "        dfForSummarizedResult = dfForSummarizedResult.append(dfPerFunction)\n",
    "\n",
    "# ( A ~ D ) * (1 ~ 256) のすべての条件を\n",
    "# 満たしていたら、リストに追加\n",
    "# 満たしていなければ、なにもしない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfForSummarizedResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF = dfForSummarizedResult\n",
    "\n",
    "\n",
    "benchmarkNamesInDF = list(set(dfForSummarizedResult[\"benchmarkName\"].tolist()))\n",
    "\n",
    "listForLatexTable = []\n",
    "for benchmarkName in benchmarkNamesInDF:\n",
    "    print(benchmarkName)\n",
    "    inputDFPerBenchmark = inputDF[inputDF[\"benchmarkName\"] == benchmarkName]\n",
    "    meanData = inputDFPerBenchmark.mean()\n",
    "    print(type(meanData))\n",
    "    meanData[\"benchmarkName\"] = f\"{benchmarkName.upper()}({len(inputDFPerBenchmark)})\"\n",
    "    listForLatexTable.append(meanData)\n",
    "DF = pd.DataFrame(listForLatexTable)\n",
    "\n",
    "DF = DF.sort_index(axis='columns')\n",
    "DF\n",
    "# relativeErrorの単位は[%]ではない。scoreの値はscore()で取得できたもの\n",
    "DF.columns = [\"ベンチマーク名(関数の個数)\", \"MAPE(予測対象関数コール回数に対する)\", \"決定係数\"]\n",
    "print(DF.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forInputDF = returnDFSummarizedData(\n",
    "    benchmarkNames=[\"cg\", \"ep\", \"ft\", \"is\", \"lu\", \"mg\"],\n",
    "    classes=[\"C\"],\n",
    "    processes=[2, 4, 8, 16, 32, 64, 128, 256],\n",
    "    targetIndex=-1,\n",
    "    csvDirPath=\"./csv_files/\",\n",
    ")\n",
    "\n",
    "benchmarkNames = list(set(forInputDF[\"benchmarkName\"].tolist()))\n",
    "columnsNames = [\"ベンチマーク名(関数の個数)\", \"MAPE(予測対象関数コール回数に対する)\"]\n",
    "listForRelativeErrorTable = []\n",
    "for benchmarkName in benchmarkNames:\n",
    "    forInputDFPerBenchmark = forInputDF[forInputDF[\"benchmarkName\"]\n",
    "                                        == benchmarkName]\n",
    "    column1 = f\"{benchmarkName.upper()}({len(forInputDFPerBenchmark)})\"\n",
    "    seriesOfMean = forInputDFPerBenchmark.mean()\n",
    "    seriesOfMeanRelativeErrorRate = seriesOfMean[\"RelativeErrorRate\"]\n",
    "    column2 = int(seriesOfMeanRelativeErrorRate * 100) / 100\n",
    "    listForRelativeErrorTable.append([{column1}, {column2}])\n",
    "print(pd.DataFrame(listForRelativeErrorTable,\n",
    "      columns=columnsNames).to_latex(index=False))\n",
    "\n",
    "# forInputDFPerBenchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(listForRelativeErrorTable, columns=columnsNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題サイズD, コア数256での関数コール回数を予測する(モデルの変更の実験)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib/lib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple regression analysis （重回帰分析）\n",
    "\n",
    "# class baseModelForMultipleRegression\n",
    "# 重回帰分析用のモデルの共通部分となるクラス\n",
    "# 引数名とその説明\n",
    "## inputDF：入力データの全てを保持したDF（説明変数・目的変数・ベンチマーク名・関数名を最低限保持している）\n",
    "## explanatoryVariableColumnNames：inputDFの列名の中で、説明変数として用いるカラム名のリスト\n",
    "## responseVariableColumnNames：inputDFの列名の中で、説明変数として用いるカラム名のリスト\n",
    "## conditionDictForTest：\"カラム名\":\"要素\"でテスト用データを指定する\n",
    "class ModelBaseForMultipleRegression:\n",
    "    \n",
    "    def __init__(self, inputDF, explanatoryVariableColumnNames, responseVariableColumnNames, conditionDictForTest={})\n",
    "        # 関数名が複数種類ある場合は警告\n",
    "        functionNames = inputDF[\"functionNames\"].tolist()\n",
    "        if(len(functionNames) > 1):\n",
    "            warn(\"関数が複数種類存在します\")\n",
    "        \n",
    "        # self.explanatoryVariableをセット\n",
    "        # self.responseVariableをセット\n",
    "        # len(conditionDictForTest) != 0 ならば\n",
    "        ## self.explanatoryVariableForTestをセット\n",
    "        ## self.responseVariableForTestをセット\n",
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
