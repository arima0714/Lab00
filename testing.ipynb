{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修正したモデルから卒論時に集計したデータを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 表\n",
    "\n",
    "| ベンチマーク名 | 平均誤差率(%) | コスト比(%) |\n",
    "|---------|----------|---------|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 表\n",
    "\n",
    "| ベンチマーク名 | 採用割合(最大MAPE(%), 最小MAPE(%)) |\n",
    "|---------|----------------------------|\n",
    "|         | モデル(1), モデル(2), ...        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 平均誤差率：大規模実行時の関数コール回数との比較\n",
    "* MAPE：トレーニングデータとの比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.xlabel(\"使用したプロファイル数\")\n",
    "plt.ylabel(\"平均誤差率(%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.get_option(\"display.max_columns\")\n",
    "# pd.get_option(\"display.max_rows\")\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "benchmark = \"cg\"\n",
    "fix = \"Class\"\n",
    "if benchmark == \"bt\" or benchmark == \"sp\":\n",
    "    processes = processes_onlyBTSP\n",
    "else:\n",
    "    processes = processes_excludeBTSP\n",
    "benchmarkClasses = [\"A\", \"B\", \"C\", \"D\"]\n",
    "targetNumOfProcess = 256\n",
    "fixedBenchmarkClass = \"B\"\n",
    "fixedProcess = 64\n",
    "\n",
    "# 引数の条件に合った生の実験データを取得する\n",
    "DF = returnRawDFperBenchmark(Benchmark=benchmark, fix=fix, benchmarkClass=benchmarkClasses,\n",
    "                             FixedProcess=fixedProcess, Processes=processes, FixedBenchmarkClass=fixedBenchmarkClass)\n",
    "# 取得した生の実験データから NaN が含まれる関数の実験データを削除\n",
    "noNaNDF = DF.dropna(how='any')\n",
    "# noNaNDF\n",
    "\n",
    "returnedCalculatedDF = return_calculatedDF(benchmark=benchmark, noNaNDF=noNaNDF,\n",
    "                                           targetNumOfProcess=targetNumOfProcess, targetProblemSize=fixedBenchmarkClass, fix=fix)\n",
    "# returnedCalculatedDF\n",
    "\n",
    "# numOfData列の要素一覧を作成し、ソートされたリストを、listOfNumDataに格納する\n",
    "listOfNumOfData = returnedCalculatedDF['numOfData'].tolist()\n",
    "listOfNumOfData = sorted(list(set(listOfNumOfData)))\n",
    "# listOfNumOfData\n",
    "\n",
    "\n",
    "# 使用したプロファイル数をキー・最適モデルでの相対誤差の平均をバリューとした辞書を作成する\n",
    "dictAverageRelativeErrorOfBestModel = {}\n",
    "x = []\n",
    "y = []\n",
    "for numOfData in listOfNumOfData:\n",
    "    # 使用したプロファイル数で抽出\n",
    "    extractedPerNumOfProfileDF = returnedCalculatedDF[returnedCalculatedDF['numOfData'] == numOfData]\n",
    "    meanDF = extractedPerNumOfProfileDF.mean()\n",
    "    data = meanDF.at['relativeErrorOfBestModel']\n",
    "    dictAverageRelativeErrorOfBestModel[numOfData] = data\n",
    "\n",
    "x = list(dictAverageRelativeErrorOfBestModel.keys())\n",
    "x\n",
    "y = [dictAverageRelativeErrorOfBestModel[key] for key in x]\n",
    "y\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, marker='o')\n",
    "plt.xlabel(\"使用したプロファイル数[％]\")\n",
    "plt.ylabel(\"平均絶対誤差率\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベンチマーク名・関数名・プロセス数・問題サイズを指定することで、その条件での関数コール回数を取得する関数\n",
    "\n",
    "def returnSpecificData(benchmarkName=\"cg\", functionName=\".TAU_application\", process=256, benchmarkClass=\"D\"):\n",
    "    targetRawDF = returnRawDF(Benchmark=benchmarkName, functionName=functionName, benchmarkClass=[\n",
    "                              benchmarkClass], FixedProcess=process, Processes=[process], FixedBenchmarkClass=benchmarkClass)\n",
    "    return targetRawDF.iat[0, 0]\n",
    "# returnSpecificData(benchmarkName=\"mg\", functionName=\"BUBBLE\", process=256, benchmarkClass=\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmarksからbt, spを除外する\n",
    "benchmarks = [benchmark for benchmark in benchmarks if benchmark !=\n",
    "              'bt' and benchmark != 'sp']\n",
    "# pandasのDFをprintした時の幅を広げる\n",
    "pd.set_option('display.width', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTmp = returnDictForPlotPerNumOfUsedData(Benchmark=benchmarks, fix=\"Class\", benchmarkClass=[\n",
    "    \"A\", \"B\", \"C\", \"D\"], FixedProcess=64, Processes=[1, 2, 4, 8, 16, 32, 64, 128, 256], FixedBenchmarkClass=\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.4g}'.format\n",
    "\n",
    "tmpDF = pd.DataFrame()\n",
    "for benchmark in benchmarks:\n",
    "    listToLearn = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "    listToPredict = [256]\n",
    "    benchmark_x = dictTmp[benchmark][\"x\"]\n",
    "    benchmark_y = dictTmp[benchmark][\"y\"]\n",
    "    index = benchmark_x.index(len(listToLearn))\n",
    "    MAPE = benchmark_y[index]\n",
    "    relativeCost = returnRelativeCost(benchmark=benchmark, variablesToLearn=listToLearn,\n",
    "                                      variablesToPredict=listToPredict, fixedClassOrProcess=\"Class\", fixed=\"C\")\n",
    "    dictRowData = {\"ベンチマーク名\": benchmark.upper(\n",
    "    ), \"平均絶対誤差率[％]\": MAPE, \"相対コスト[％]\": relativeCost}\n",
    "    iDF = pd.DataFrame.from_dict(dictRowData, orient='index').T\n",
    "    tmpDF = tmpDF.append(iDF)\n",
    "tmpDFMean = tmpDF.mean()\n",
    "type(tmpDFMean)\n",
    "print(tmpDF.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictTmp\n",
    "\n",
    "plt.figure(figsize=(5.72, 4), dpi=200)\n",
    "for benchmark in list(dictTmp.keys()):\n",
    "    x = dictTmp[benchmark][\"x\"]\n",
    "    y = dictTmp[benchmark][\"y\"]\n",
    "    plt.plot(x, y, marker='o', label=benchmark.upper())\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"使用したプロファイル数\")\n",
    "    plt.ylabel(\"平均絶対誤差率[％]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.72, 4), dpi=200)\n",
    "\n",
    "# Extra-PでfixProcessデータを入力して出力したモデルの図時\n",
    "plot_x = np.linspace(0.8, 256, 500)\n",
    "# -3590464.6990329633 + 3759195.349891038 * p^(1/4)\n",
    "plot_y = []\n",
    "for x in plot_x:\n",
    "    plot_y.append(2286768.3333333326 + 301997.61904761934 * math.log2(x)**(1))\n",
    "plt.plot(plot_x, plot_y, label=\"ExtraP\")\n",
    "\n",
    "x = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "y = [1984770.0, 2263540.0, 2821070.0, 3936140.0,\n",
    "     3936140.0, 3936140.0, 3936140.0, 3936140.0]\n",
    "x = np.array(x).reshape(-1, 1)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "plt.scatter(x, y, marker=\"o\", label=\"予測に用いた関数コール回数\")\n",
    "plot_x = np.array(plot_x).reshape(-1, 1)\n",
    "x_target = [256]\n",
    "y_target = [3936140]\n",
    "plt.scatter(x_target, y_target, marker=\"o\", label=\"予測したい関数コール回数の実測値\")\n",
    "\n",
    "benchmarkName = \"CG\"\n",
    "functionName = \"ICNVRT\"\n",
    "\n",
    "# 線形モデル\n",
    "# 対数モデル\n",
    "\n",
    "# 反比例モデル\n",
    "modelIpMk2 = ModelIp_mk2(train_x=x, train_y=y, target_x=x_target, target_y=y_target,\n",
    "                         benchmark_name=benchmarkName, function_name=functionName)\n",
    "modelIpMk2.calc_lr()\n",
    "plot_y_IpMk2 = modelIpMk2.predict(plot_x)\n",
    "plt.plot(plot_x, plot_y_IpMk2, label=\"反比例モデル\")\n",
    "# 線形飽和モデル\n",
    "modelBranchMk2 = ModelBranch_mk2(train_x=x, train_y=y, target_x=x_target,\n",
    "                                 target_y=y_target, benchmark_name=benchmarkName, function_name=functionName)\n",
    "modelBranchMk2.calc_lr()\n",
    "plot_y_BranchMk2 = modelBranchMk2.predict(plot_x)\n",
    "plt.plot(plot_x, plot_y_BranchMk2, label=\"線形飽和モデル\")\n",
    "# # 線形モデル\n",
    "# model_lin = ModelLin(x, y, \"CG\", \"ICNVRT\", test_ratio=0)\n",
    "# model_lin.calc_lr()\n",
    "# plot_y_lin = model_lin.predict(plot_x)\n",
    "# plt.plot(plot_x, plot_y_lin, label=\"線形モデル\")\n",
    "# # 対数モデル\n",
    "# model_log10 = ModelLog10(x, y, \"CG\", \"ICNVRT\", test_ratio=0)\n",
    "# model_log10.calc_lr()\n",
    "# plot_y_log10 = model_log10.predict(plot_x)\n",
    "# plt.plot(plot_x, plot_y_log10, label=\"対数モデル\")\n",
    "# # 反比例モデル\n",
    "# model_ip = ModelIP(x, y, \"CG\", \"ICNVRT\", test_ratio=0)\n",
    "# model_ip.calc_lr()\n",
    "# plot_y_ip = model_ip.predict(plot_x)\n",
    "# plt.plot(plot_x, plot_y_ip, label=\"反比例モデル\")\n",
    "# # 線形飽和モデル\n",
    "# model_branch = ModelBranch(x, y, \"CG\", \"ICNVRT\", test_ratio=0)\n",
    "# model_branch.calc_lr()\n",
    "# plot_y_branch = model_branch.predict(plot_x)\n",
    "# plt.plot(plot_x, plot_y_branch, label=\"線形飽和モデル\")\n",
    "# 凡例の表示\n",
    "plt.legend()\n",
    "# 軸ラベルの設定\n",
    "plt.ylabel(\"関数コール回数\")\n",
    "plt.xlabel(\"実行コア数\")\n",
    "\n",
    "plt.scatter(x, y, marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 実際にプロットする\n",
    "\n",
    "\n",
    "# print(f\"fix={fix}, benchmarkClasses={benchmarkClasses}, fixedProcess={fixedProcess}, Processes={processes}, FixedBenchmarkClass={fixedBenchmarkClass}\")\n",
    "# print(f\"targetNumOfProcess={targetNumOfProcess}, targetProblemSize={fixedBenchmarkClass}, fix={fix}\")\n",
    "\n",
    "# DF = returnRawDFperBenchmark(Benchmark=\"mg\", fix=\"Process\", benchmarkClass=[\"A\", \"B\", \"C\", \"D\"], Processes=[\n",
    "#                              1, 2, 4, 8, 16, 32, 64, 128, 256], FixedBenchmarkClass=\"B\", FixedProcess=64)\n",
    "# DF.dropna(how='any')\n",
    "# DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib/lib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmarkNamesExcludeBTSP = [\"cg\", \"ep\", \"ft\", \"is\", \"lu\", \"mg\"]\n",
    "# classes = [\"A\", \"B\", \"C\", \"D\"]\n",
    "classes = [\"B\"]\n",
    "processes = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "targetIndex = -1\n",
    "csvDirPath = \"./csv_files/\"\n",
    "\n",
    "dfByDatumExcludeBTSP = returnDFSummarizedData(\n",
    "    benchmarkNames=benchmarkNamesExcludeBTSP, classes=classes, processes=processes, targetIndex=targetIndex, csvDirPath=csvDirPath)\n",
    "# dfByDatumExcludeBTSP\n",
    "\n",
    "dictForLatexTable = {}\n",
    "numOfData = 0\n",
    "for benchmarkName in benchmarkNamesExcludeBTSP:\n",
    "    dictForLatexTable[benchmarkName] = dfByDatumExcludeBTSP[dfByDatumExcludeBTSP[\"benchmarkName\"] == benchmarkName]\n",
    "    numOfData += len(\n",
    "        dfByDatumExcludeBTSP[dfByDatumExcludeBTSP[\"benchmarkName\"] == benchmarkName])\n",
    "\n",
    "numOfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "listForDF = []\n",
    "\n",
    "for benchmarkName in benchmarkNamesExcludeBTSP:\n",
    "    listForDF.append(returnSeriesOfDatumPerBenchmark(\n",
    "        inputDF=dictForLatexTable[benchmarkName]))\n",
    "DF = pd.DataFrame(listForDF)\n",
    "print(DF.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_returnSeriesOfDatumPerBenchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultIs = dictForLatexTable[\"is\"]\n",
    "# resultIs\n",
    "resultIsAtModelBranch = resultIs[resultIs[\"objectBestModelName\"]\n",
    "                                 == \"ModelBranch\"]\n",
    "datumX = resultIsAtModelBranch[\"usedDataX\"].tolist()\n",
    "datumY = resultIsAtModelBranch[\"usedDataY\"].tolist()\n",
    "\n",
    "datumX\n",
    "datumY\n",
    "\n",
    "# returnSeriesOfData(benchmarkName=\"is\", functionName=\"double_randlc(double_*_double_*)\", rawX=dataX, rawY=dataY, fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=-1, csvDirPath=\"./csv_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultIs = dictForLatexTable[\"ft\"]\n",
    "# resultIs\n",
    "resultIsAtModelBranch = resultIs[resultIs[\"objectBestModelName\"]\n",
    "                                 == \"ModelBranch\"]\n",
    "resultIsAtModelBranchOfNotLowMAPE = resultIsAtModelBranch[\n",
    "    resultIsAtModelBranch[\"MAPEOfBestModel\"] > 1]\n",
    "resultIsAtModelBranchOfNotLowMAPE\n",
    "datumX = resultIsAtModelBranchOfNotLowMAPE[\"usedDataX\"].tolist()\n",
    "datumY = resultIsAtModelBranchOfNotLowMAPE[\"usedDataY\"].tolist()\n",
    "\n",
    "datumX\n",
    "datumY\n",
    "\n",
    "for dataIndex in range(len(datumX)):\n",
    "    plt.figure()\n",
    "    plt.scatter(datumX[dataIndex], datumY[dataIndex])\n",
    "\n",
    "# returnSeriesOfData(benchmarkName=\"is\", functionName=\"double_randlc(double_*_double_*)\", rawX=dataX, rawY=dataY, fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=-1, csvDirPath=\"./csv_files\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 実験用に小規模なリスト\n",
    "benchmarkNames = [\"cg\"]\n",
    "classes = [\"B\"]\n",
    "processes = [1, 2, 4, 8, 16, 32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 生データの取得\n",
    "cgDF = returnCollectedExistingData(benchmarkNames=[\"cg\"], classes=[\"A\", \"B\", \"C\", \"D\"], processes=[\n",
    "                                   1, 2, 4, 8, 16, 32, 64, 128, 256], csvDirPath=\"./csv_files/\")\n",
    "cgDF\n",
    "# ベンチマーククラスがAの情報を取得\n",
    "cgDFfixedA = cgDF[cgDF[\"benchmarkClass\"] == \"A\"]\n",
    "cgDFfixedA\n",
    "# 関数名のリストを取得\n",
    "functionNames = sorted(list(set(cgDFfixedA[\"functionName\"])))\n",
    "print(functionNames)\n",
    "\n",
    "# 関数名を関数名のリストから抽出\n",
    "functionNameCG = cgDFfixedA[cgDFfixedA[\"functionName\"] == \"CG\"]\n",
    "functionNameCG\n",
    "\n",
    "# 説明変数と目的変数とをリスト化したものを抽出\n",
    "# プロセス数\n",
    "raw_x = functionNameCG['process'].tolist()\n",
    "# 関数コール回数\n",
    "raw_y = functionNameCG['functionCallNum'].tolist()\n",
    "\n",
    "print(f\"raw_x={raw_x}\")\n",
    "print(f\"raw_y={raw_y}\")\n",
    "\n",
    "bencmarkName = \"CG\"\n",
    "functionName = \"CG\"\n",
    "fixProcessOrClass = \"Class\"\n",
    "fixed = \"A\"\n",
    "targetProcess = 256\n",
    "targetBenchmarkClass = fixed\n",
    "targetFunctionCallNum = raw_y[-1]\n",
    "returnSeriesOfData(benchmarkName=\"benhmarkName\", functionName=\"functionName\", rawX=[1, 2, 3], rawY=[\n",
    "                   1, 2, 3], fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=-1, csvDirPath=\"./csv_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ノートブック中で変数のみを記述することでデータフレームをきれいに表示させる設定の有効化\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib/lib.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題サイズD, コア数256での関数コール回数を予測する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO：BT, SP以外のベンチマーク名を入れる\n",
    "benchmarkNames = ['cg', 'ep', 'ft', 'is', 'lu', 'mg']\n",
    "classes = [\"A\", \"B\", \"C\", \"D\"]\n",
    "processes = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "\n",
    "dictForSummarizedResult = {}\n",
    "columnName = [\"benchmarkName\", \"functionName\", \"score\", \"relativeErrorRate\"]\n",
    "dfForSummarizedResult = pd.DataFrame(columns=columnName)\n",
    "for benchmarkName in benchmarkNames:\n",
    "    # ベンチマークごとにscoreを保持するためのリスト\n",
    "    listForSummarizedResultPerBenchmarkName = []\n",
    "    # 学習用生データ\n",
    "    DF = returnCollectedExistingData(benchmarkNames=[\n",
    "                                     benchmarkName], classes=classes, processes=processes, csvDirPath=\"./csv_files/\")\n",
    "    # 重複のない関数名のリスト\n",
    "    functionNames = list(set(DF[\"functionName\"]))\n",
    "    usefulFunctionNames = []\n",
    "    # このループで関数ごとのデータが問題サイズパターン数xコア数パターン数 分だけ存在する関数名のリストを作成する\n",
    "    for functionName in functionNames:\n",
    "        # 関数ごとに生データを集計\n",
    "        dfPerFunction = DF[DF[\"functionName\"] == functionName]\n",
    "        if len(classes) * len(processes) == len(dfPerFunction):\n",
    "            usefulFunctionNames.append(functionName)\n",
    "    if len(usefulFunctionNames) == 0:\n",
    "        continue\n",
    "    # 関数ごとのデータを抽出\n",
    "    for functionName in usefulFunctionNames:\n",
    "        # 問題サイズを数値化したカラムを追加\n",
    "        listBenchmarkClass = DF[\"benchmarkClass\"].tolist()\n",
    "        DFWithNumInBenchmarkClass = DF.assign(\n",
    "            benchmarkClassInNum=convertBenchmarkClasses_problemSizeInNPB(listBenchmarkClass))\n",
    "        # 学習用データ\n",
    "        dfPerFunctionForTrain = DFWithNumInBenchmarkClass[(\n",
    "            DFWithNumInBenchmarkClass[\"functionName\"] == functionName)]\n",
    "        dfPerFunctionForTest = DFWithNumInBenchmarkClass[(DFWithNumInBenchmarkClass[\"functionName\"] == functionName) & (\n",
    "            DFWithNumInBenchmarkClass[\"benchmarkClass\"] == \"D\") & (DFWithNumInBenchmarkClass[\"process\"] == 256)]\n",
    "\n",
    "        # x:説明変数, t:目的変数\n",
    "        trainX = dfPerFunctionForTrain[[\"process\", \"benchmarkClassInNum\"]]\n",
    "        trainT = dfPerFunctionForTrain[[\"functionCallNum\"]]\n",
    "        testX = dfPerFunctionForTest[[\"process\", \"benchmarkClassInNum\"]]\n",
    "        testT = dfPerFunctionForTest[[\"functionCallNum\"]]\n",
    "        # 重回帰分析する\n",
    "        reg_model = LinearRegression()\n",
    "        reg_model.fit(trainX, trainT)\n",
    "        # 関数ごとの結果をベンチマークごとの結果に入れる\n",
    "        scorePerFunction = reg_model.score(trainX, trainT)\n",
    "        listForSummarizedResultPerBenchmarkName.append(scorePerFunction)\n",
    "        # 予測を実施して、相対誤差を算出\n",
    "        predictedTByTestX = reg_model.predict(testX)\n",
    "        predictedData = predictedTByTestX[0][0]\n",
    "        realData = testT[\"functionCallNum\"].tolist()[0]\n",
    "        relativeErrorPerFunction = abs(predictedData - realData)/realData * 100\n",
    "        ##\n",
    "        dfPerFunction = pd.DataFrame(index=columnName, data=[\n",
    "                                     benchmarkName, functionName, scorePerFunction, relativeErrorPerFunction]).T\n",
    "        dfForSummarizedResult = dfForSummarizedResult.append(dfPerFunction)\n",
    "\n",
    "# ( A ~ D ) * (1 ~ 256) のすべての条件を\n",
    "# 満たしていたら、リストに追加\n",
    "# 満たしていなければ、なにもしない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfForSummarizedResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF = dfForSummarizedResult\n",
    "\n",
    "\n",
    "benchmarkNamesInDF = list(set(dfForSummarizedResult[\"benchmarkName\"].tolist()))\n",
    "\n",
    "listForLatexTable = []\n",
    "for benchmarkName in benchmarkNamesInDF:\n",
    "    print(benchmarkName)\n",
    "    inputDFPerBenchmark = inputDF[inputDF[\"benchmarkName\"] == benchmarkName]\n",
    "    meanData = inputDFPerBenchmark.mean()\n",
    "    print(type(meanData))\n",
    "    meanData[\"benchmarkName\"] = f\"{benchmarkName.upper()}({len(inputDFPerBenchmark)})\"\n",
    "    listForLatexTable.append(meanData)\n",
    "DF = pd.DataFrame(listForLatexTable)\n",
    "\n",
    "DF = DF.sort_index(axis='columns')\n",
    "DF\n",
    "# relativeErrorの単位は[%]ではない。scoreの値はscore()で取得できたもの\n",
    "DF.columns = [\"ベンチマーク名(関数の個数)\", \"MAPE(予測対象関数コール回数に対する)\", \"決定係数\"]\n",
    "print(DF.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forInputDF = returnDFSummarizedData(\n",
    "    benchmarkNames=[\"cg\", \"ep\", \"ft\", \"is\", \"lu\", \"mg\"],\n",
    "    classes=[\"C\"],\n",
    "    processes=[2, 4, 8, 16, 32, 64, 128, 256],\n",
    "    targetIndex=-1,\n",
    "    csvDirPath=\"./csv_files/\",\n",
    ")\n",
    "\n",
    "benchmarkNames = list(set(forInputDF[\"benchmarkName\"].tolist()))\n",
    "columnsNames = [\"ベンチマーク名(関数の個数)\", \"MAPE(予測対象関数コール回数に対する)\"]\n",
    "listForRelativeErrorTable = []\n",
    "for benchmarkName in benchmarkNames:\n",
    "    forInputDFPerBenchmark = forInputDF[forInputDF[\"benchmarkName\"]\n",
    "                                        == benchmarkName]\n",
    "    column1 = f\"{benchmarkName.upper()}({len(forInputDFPerBenchmark)})\"\n",
    "    seriesOfMean = forInputDFPerBenchmark.mean()\n",
    "    seriesOfMeanRelativeErrorRate = seriesOfMean[\"RelativeErrorRate\"]\n",
    "    column2 = int(seriesOfMeanRelativeErrorRate * 100) / 100\n",
    "    listForRelativeErrorTable.append([{column1}, {column2}])\n",
    "print(pd.DataFrame(listForRelativeErrorTable,\n",
    "      columns=columnsNames).to_latex(index=False))\n",
    "\n",
    "# forInputDFPerBenchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(listForRelativeErrorTable, columns=columnsNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib/lib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarkNames = ['cg', 'ep', 'ft', 'is', 'lu', 'mg']\n",
    "\n",
    "classes = [\"A\", \"B\", \"C\", \"D\"]\n",
    "processes = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "targetClass = classes[-1]\n",
    "targetProcess = processes[-1]\n",
    "\n",
    "# 学習用生データ\n",
    "DF = returnCollectedExistingData(benchmarkNames=benchmarkNames,\n",
    "                                 classes=classes, processes=processes, csvDirPath=\"./csv_files/\")\n",
    "DFByValidFunction = returnDFwithFunctionsExecUnderAllConditions(\n",
    "    inputDF=DF, classes=classes, processes=processes)\n",
    "# 問題サイズを数値化したカラムを追加\n",
    "listBenchmarkClass = DFByValidFunction[\"benchmarkClass\"].tolist()\n",
    "# 生データにカラムなどを加えた整形済みのDF\n",
    "shapedDF = DFByValidFunction.assign(\n",
    "    benchmarkClassInNum=convertBenchmarkClasses_problemSizeInNPB(listBenchmarkClass))\n",
    "\n",
    "# 説明変数のカラム名のリスト\n",
    "expVarColNames = [\"process\", \"benchmarkClassInNum\"]\n",
    "# 目的変数のカラム名のリスト\n",
    "resVarColNames = [\"functionCallNum\"]\n",
    "\n",
    "# データ内にあるベンチマーク名のリスト\n",
    "benchmarkNames = set(shapedDF[\"benchmarkName\"].tolist())\n",
    "\n",
    "# 集計前のデータを作成\n",
    "# DFで[functionName | benchmarkName | expVarDatumDict | resVarDatumDict | modelsName | dictAggregateResult]がカラム名\n",
    "\n",
    "dictToMakeSummary = {}\n",
    "for benchmarkName in benchmarkNames:\n",
    "    DFperBenchmark = shapedDF[shapedDF[\"benchmarkName\"] == benchmarkName]\n",
    "    # すべての条件で実行された関数名のリスト\n",
    "    validFunctionNames = list(\n",
    "        set(DFperBenchmark[\"functionName\"].tolist()))\n",
    "    listToMakeDF = []\n",
    "    print(f\"benchmakName={benchmarkName}, 関数の個数:{len(validFunctionNames)}\")\n",
    "    for validFunctionName in validFunctionNames:\n",
    "        # 3モデルを一気に作成するmodels()を利用\n",
    "        inputDFperFunction = DFperBenchmark[(DFperBenchmark[\"functionName\"] == validFunctionName) & (\n",
    "            DFperBenchmark[\"benchmarkName\"] == benchmarkName)].reset_index()\n",
    "        targetDFperFunction = inputDFperFunction[(inputDFperFunction[\"benchmarkClass\"] == targetClass) & (\n",
    "            inputDFperFunction[\"process\"] == targetProcess)]\n",
    "        # 説明変数のカラム名リストを作成\n",
    "        expVarColNames = [\"process\", \"benchmarkClassInNum\"]\n",
    "        # 目的変数のカラム名リストを作成\n",
    "        resVarColNames = [\"functionCallNum\"]\n",
    "        # モデルを一括で作成\n",
    "        if len(targetDFperFunction) == 0:\n",
    "            print(\n",
    "                f\"benchmarkName={benchmarkName}, functionName={validFunctionName}\")\n",
    "            continue\n",
    "        returnedDF = returnDFtoMakeSummary(inputDF=inputDFperFunction, benchmarkName=benchmarkName, validFunctionName=validFunctionName,\n",
    "                                           targetClass=targetClass, targetProcess=targetProcess, expVarColNames=expVarColNames, resVarColNames=resVarColNames)\n",
    "        listToMakeDF.append(returnedDF)\n",
    "    if len(listToMakeDF) == 0:\n",
    "        continue\n",
    "    inputDFtoMakeDFperBenchmark = pd.concat(\n",
    "        listToMakeDF).reset_index(drop=True)\n",
    "    returnedDict = convertDictToMakeSummary(\n",
    "        inputDF=inputDFtoMakeDFperBenchmark, modelAdoptionRate=True, averageRelativeError=True)\n",
    "    dictToMakeSummary[benchmarkName] = returnedDict\n",
    "# TODO:作成したDFを入力として集計関数を実行\n",
    "\n",
    "modelAdoptionRate = returnedDict[\"modelAdoptionRate\"]\n",
    "averageRelativeError = returnedDict[\"averageRelativeError\"]\n",
    "returnedDict\n",
    "\n",
    "modelAdoptionRate\n",
    "\n",
    "averageRelativeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnBenchmarkName = []\n",
    "# 採用割合\n",
    "columnAdoptionRateLog = []\n",
    "columnAdoptionRateIp = []\n",
    "columnAdoptionRateLin = []\n",
    "# 平均相対誤差率\n",
    "columnAverageRelativeError = []\n",
    "\n",
    "for benchmarkName in dictToMakeSummary.keys():\n",
    "    # 関数の個数\n",
    "    numOfFunctions = 0\n",
    "\n",
    "    # 採用割合\n",
    "    modelAdoptionRate = dictToMakeSummary[benchmarkName][\"modelAdoptionRate\"]\n",
    "    modelNames = list(modelAdoptionRate.keys())\n",
    "    for modelName in modelNames:\n",
    "        #         print(modelName)\n",
    "        numOfFunctions += modelAdoptionRate[modelName][\"count\"]\n",
    "    dictToMakeSummary[benchmarkName][\"関数の個数\"] = numOfFunctions\n",
    "\n",
    "    # 採用割合を算出するモデルが３つであることを仮定している\n",
    "    # modelLog\n",
    "    adoptionRateLog = int(\n",
    "        modelAdoptionRate[\"modelLog\"][\"count\"]/numOfFunctions * 100)\n",
    "    if modelAdoptionRate[\"modelLog\"][\"count\"] == 0:\n",
    "        logMinMAPE = \"-\"\n",
    "        logMaxMAPE = \"-\"\n",
    "    else:\n",
    "        logMinMAPE = int(float(modelAdoptionRate[\"modelLog\"][\"min\"])*10)/10\n",
    "        logMaxMAPE = int(float(modelAdoptionRate[\"modelLog\"][\"max\"])*10)/10\n",
    "    # modelIp\n",
    "    adoptionRateIp = int(\n",
    "        modelAdoptionRate[\"modelIp\"][\"count\"]/numOfFunctions * 100)\n",
    "    if modelAdoptionRate[\"modelIp\"][\"count\"] == 0:\n",
    "        ipMinMAPE = \"-\"\n",
    "        ipMaxMAPE = \"-\"\n",
    "    else:\n",
    "        ipMinMAPE = int(float(modelAdoptionRate[\"modelIp\"][\"min\"])*10)/10\n",
    "        ipMaxMAPE = int(float(modelAdoptionRate[\"modelIp\"][\"max\"])*10)/10\n",
    "    # modelLin\n",
    "    adoptionRateLin = 100 - adoptionRateIp - adoptionRateLog\n",
    "    if modelAdoptionRate[\"modelLin\"][\"count\"] == 0:\n",
    "        linMinMAPE = \"-\"\n",
    "        linMaxMAPE = \"-\"\n",
    "    else:\n",
    "        linMinMAPE = int(float(modelAdoptionRate[\"modelLin\"][\"min\"])*10)/10\n",
    "        linMaxMAPE = int(float(modelAdoptionRate[\"modelLin\"][\"max\"])*10)/10\n",
    "\n",
    "    # Latex化するためにカラムとして入れる\n",
    "    columnBenchmarkName.append(f\"{benchmarkName.upper()}({numOfFunctions})\")\n",
    "    columnAdoptionRateLog.append(\n",
    "        f\"{adoptionRateLog}({logMinMAPE},{logMaxMAPE})\")\n",
    "    columnAdoptionRateIp.append(f\"{adoptionRateIp}({ipMinMAPE},{ipMaxMAPE})\")\n",
    "    columnAdoptionRateLin.append(\n",
    "        f\"{adoptionRateLin}({linMinMAPE},{linMaxMAPE})\")\n",
    "\n",
    "    # 相対誤差率\n",
    "    averageRelativeError = dictToMakeSummary[benchmarkName][\"averageRelativeError\"]\n",
    "    columnAverageRelativeError.append(int(averageRelativeError*100)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictToMakeSummary\n",
    "\n",
    "columnBenchmarkName\n",
    "\n",
    "columnAdoptionRateLog\n",
    "\n",
    "columnAdoptionRateIp\n",
    "\n",
    "columnAdoptionRateLin\n",
    "\n",
    "columnAverageRelativeError\n",
    "\n",
    "# 採用割合\n",
    "採用割合 = pd.DataFrame({\"ベンチマーク名\": columnBenchmarkName,\n",
    "                    \"反比例モデル\": columnAdoptionRateIp, \"対数モデル\": columnAdoptionRateLog, \"線形モデル\": columnAdoptionRateLin})\n",
    "# 相対誤差率\n",
    "相対誤差率 = pd.DataFrame({\"ベンチマーク名\": columnBenchmarkName,\n",
    "                     \"相対誤差率[%]\": columnAverageRelativeError})\n",
    "\n",
    "print(採用割合.to_latex(index=False))\n",
    "\n",
    "print(相対誤差率.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib/lib.ipynb\n",
    "\n",
    "class ModelBranchForMultipleRegression(ModelBaseForMultipleRegression):\n",
    "    # 線形モデル（重回帰分析）\n",
    "\n",
    "    def transformDataForModel(self, inputDF):\n",
    "        # inputDFで与えられたデータをモデルに適した形に変形する\n",
    "        return(inputDF)\n",
    "\n",
    "    def setUpDataBeforeCalcLr(self):\n",
    "        # 説明変数・目的変数を変換する関数\n",
    "        # モデル構築用データ\n",
    "        self.dataXForPredict = self.transformDataForModel(\n",
    "            self.rawExplanaoryVariable)\n",
    "        self.dataTForPredict = self.transformDataForModel(\n",
    "            self.rawResponseVariable)\n",
    "        # テスト用データ\n",
    "        self.dataXForTest = self.transformDataForModel(\n",
    "            self.rawExplanaoryVariableForTest)\n",
    "        self.dataTForTest = self.transformDataForModel(\n",
    "            self.rawResponseVariableForTest)\n",
    "\n",
    "    def calcLr(self):\n",
    "        # 実際にモデルを構築する\n",
    "        self.lr = LinearRegression()\n",
    "        self.lr.fit(self.dataXForPredict, self.dataTForPredict)\n",
    "\n",
    "    def predict(self, inputDF):\n",
    "        # inputDFのデータから構築されたモデルを使って予測を行う\n",
    "\n",
    "        # inputDFから説明変数データのみを取得\n",
    "        inputDFOnlyExplanatoryVariableColumn = inputDF[self.explanatoryVariableColumnNames]\n",
    "        # 予測を実行\n",
    "        result = self.lr.predict(inputDFOnlyExplanatoryVariableColumn)\n",
    "\n",
    "        return(result)\n",
    "\n",
    "\n",
    "def test_ModelBranchForMultipleRegression():\n",
    "    # 単なる線形モデル\n",
    "    # 説明変数\n",
    "    plotX = np.linspace(0, 20, 10)\n",
    "    plotY = np.linspace(20, 40, 10)\n",
    "    plotZ = np.linspace(40, 60, 10)\n",
    "    # 目的変数\n",
    "    plotT = plotX + 2 * plotY + 3 * plotZ + 4\n",
    "\n",
    "    # DFを作成する\n",
    "    # カラム名のリスト\n",
    "    columnNames = [\"plotX\", \"plotY\", \"plotZ\", \"plotT\"]\n",
    "    datumForDF = [plotX, plotY, plotZ, plotT]\n",
    "    inputDFForTest = pd.DataFrame(index=columnNames, data=datumForDF).T\n",
    "    inputDFForTest[\"functionName\"] = \"functionName\"\n",
    "\n",
    "    # 目的変数・説明変数のカラム名のリスト\n",
    "    # 目的変数のカラム名のリスト\n",
    "    columnNamesForExp = columnNames[:-1]\n",
    "    # 説明変数のカラム名のリスト\n",
    "    columnNamesForRes = columnNames[-1:]\n",
    "\n",
    "    # 予測をする\n",
    "    # モデルオブジェクトの作成\n",
    "    objectModel = ModelBranchForMultipleRegression(inputDF=inputDFForTest, explanatoryVariableColumnNames=columnNamesForExp,\n",
    "                                                   responseVariableColumnNames=columnNamesForRes, conditionDictForTest={})\n",
    "    # モデルの生成の準備\n",
    "    objectModel.setUpDataBeforeCalcLr()\n",
    "    # モデルの生成\n",
    "    objectModel.calcLr()\n",
    "    # モデルによる予測\n",
    "    # 入力データDFを作成\n",
    "    inputDFForPredict = pd.DataFrame(inputDFForTest.tail(1))\n",
    "    predictedNum = objectModel.predict(inputDFForPredict)\n",
    "\n",
    "    # 相対誤差率でテスト対象のデータが想定通りに動作しているかを判断する\n",
    "    # 相対誤差率を計算するために実データを取得する\n",
    "    realNum = plotT[-1]\n",
    "    relativeErrorRate = returnRelativeErrorRate(\n",
    "        realNum=realNum, predictedNum=predictedNum)\n",
    "\n",
    "    assert relativeErrorRate < 1\n",
    "\n",
    "    # 線形飽和モデル\n",
    "    branchIndex = 5\n",
    "    # 説明変数\n",
    "    branchX = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    branchY = [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "    branchZ = [21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
    "    # 目的変数\n",
    "    branchT_X = returnListForBranchModel(\n",
    "        inputList=branchX, branchIndex=branchIndex, a=1, b=2)\n",
    "    branchT_Y = returnListForBranchModel(\n",
    "        inputList=branchY, branchIndex=branchIndex, a=3, b=4)\n",
    "    branchT_Z = returnListForBranchModel(\n",
    "        inputList=branchZ, branchIndex=branchIndex, a=5, b=6)\n",
    "    branchT = []\n",
    "    for numX, numY, numZ in zip(branchT_X, branchT_Y, branchT_Z):\n",
    "        branchT.append(numX+numY+numZ)\n",
    "    # DFを作成する\n",
    "    # カラム名のリスト\n",
    "    inputDFForTest = pd.DataFrame(\n",
    "        {\"branchX\": branchX, \"branchY\": branchY, \"branchZ\": branchZ, \"branchT\": branchT})\n",
    "    # 目的変数のカラム名のリスト\n",
    "    expVarName = [\"branchX\", \"branchY\", \"branchZ\"]\n",
    "    # 説明変数のカラム名のリスト\n",
    "    resVarName = [\"branchT\"]\n",
    "    # 関数名\n",
    "    inputDFForTest[\"functionName\"] = \"functionName\"\n",
    "    # 予測のためのモデルオブジェクトの作成\n",
    "    objectModel = ModelBranchForMultipleRegression(\n",
    "        inputDF=inputDFForTest, explanatoryVariableColumnNames=expVarName, responseVariableColumnNames=resVarName, conditionDictForTest={})\n",
    "    # モデルの生成の準備\n",
    "    objectModel.setUpDataBeforeCalcLr()\n",
    "    objectModel.calcLr()\n",
    "    # モデルによる予測\n",
    "    inputDFForPredict = pd.DataFrame(inputDFForTest.tail(1))\n",
    "    predictedNum = objectModel.predict(inputDFForPredict)\n",
    "    # 相対誤差率でテスト対象のデータに焚いてモデルが想定通りに動作しているかを判断する\n",
    "    realNum = branchT[-1]\n",
    "    relativeErrorRate = returnRelativeErrorRate(\n",
    "        realNum=realNum, predictedNum=predictedNum)\n",
    "    print(f\"relatieErrorRate={relativeErrorRate}\")\n",
    "    assert relativeErrorRate < 1\n",
    "\n",
    "\n",
    "test_ModelBranchForMultipleRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
