{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修正したモデルから卒論時に集計したデータを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 表\n",
    "\n",
    "| ベンチマーク名 | 平均誤差率(%) | コスト比(%) |\n",
    "|---------|----------|---------|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 表\n",
    "\n",
    "| ベンチマーク名 | 採用割合(最大MAPE(%), 最小MAPE(%)) |\n",
    "|---------|----------------------------|\n",
    "|         | モデル(1), モデル(2), ...        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 平均誤差率：大規模実行時の関数コール回数との比較\n",
    "* MAPE：トレーニングデータとの比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.xlabel(\"使用したプロファイル数\")\n",
    "plt.ylabel(\"平均誤差率(%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.get_option(\"display.max_columns\")\n",
    "# pd.get_option(\"display.max_rows\")\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "benchmark = \"cg\"\n",
    "fix = \"Class\"\n",
    "if benchmark == \"bt\" or benchmark == \"sp\":\n",
    "    processes = processes_onlyBTSP\n",
    "else:\n",
    "    processes = processes_excludeBTSP\n",
    "benchmarkClasses = [\"A\", \"B\", \"C\", \"D\"]\n",
    "targetNumOfProcess = 256\n",
    "fixedBenchmarkClass = \"B\"\n",
    "fixedProcess = 64\n",
    "\n",
    "# 引数の条件に合った生の実験データを取得する\n",
    "DF = returnRawDFperBenchmark(Benchmark=benchmark, fix=fix, benchmarkClass=benchmarkClasses,\n",
    "                             FixedProcess=fixedProcess, Processes=processes, FixedBenchmarkClass=fixedBenchmarkClass)\n",
    "# 取得した生の実験データから NaN が含まれる関数の実験データを削除\n",
    "noNaNDF = DF.dropna(how='any')\n",
    "# noNaNDF\n",
    "\n",
    "returnedCalculatedDF = return_calculatedDF(benchmark=benchmark, noNaNDF=noNaNDF,\n",
    "                                           targetNumOfProcess=targetNumOfProcess, targetProblemSize=fixedBenchmarkClass, fix=fix)\n",
    "# returnedCalculatedDF\n",
    "\n",
    "# numOfData列の要素一覧を作成し、ソートされたリストを、listOfNumDataに格納する\n",
    "listOfNumOfData = returnedCalculatedDF['numOfData'].tolist()\n",
    "listOfNumOfData = sorted(list(set(listOfNumOfData)))\n",
    "# listOfNumOfData\n",
    "\n",
    "\n",
    "# 使用したプロファイル数をキー・最適モデルでの相対誤差の平均をバリューとした辞書を作成する\n",
    "dictAverageRelativeErrorOfBestModel = {}\n",
    "x = []\n",
    "y = []\n",
    "for numOfData in listOfNumOfData:\n",
    "    # 使用したプロファイル数で抽出\n",
    "    extractedPerNumOfProfileDF = returnedCalculatedDF[returnedCalculatedDF['numOfData'] == numOfData]\n",
    "    meanDF = extractedPerNumOfProfileDF.mean()\n",
    "    data = meanDF.at['relativeErrorOfBestModel']\n",
    "    dictAverageRelativeErrorOfBestModel[numOfData] = data\n",
    "\n",
    "x = list(dictAverageRelativeErrorOfBestModel.keys())\n",
    "x\n",
    "y = [dictAverageRelativeErrorOfBestModel[key] for key in x]\n",
    "y\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, marker='o')\n",
    "plt.xlabel(\"使用したプロファイル数[％]\")\n",
    "plt.ylabel(\"平均絶対誤差率\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベンチマーク名・関数名・プロセス数・問題サイズを指定することで、その条件での関数コール回数を取得する関数\n",
    "\n",
    "def returnSpecificData(benchmarkName=\"cg\", functionName=\".TAU_application\", process=256, benchmarkClass=\"D\"):\n",
    "    targetRawDF = returnRawDF(Benchmark=benchmarkName, functionName=functionName, benchmarkClass=[\n",
    "                              benchmarkClass], FixedProcess=process, Processes=[process], FixedBenchmarkClass=benchmarkClass)\n",
    "    return targetRawDF.iat[0, 0]\n",
    "# returnSpecificData(benchmarkName=\"mg\", functionName=\"BUBBLE\", process=256, benchmarkClass=\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmarksからbt, spを除外する\n",
    "benchmarks = [benchmark for benchmark in benchmarks if benchmark !=\n",
    "              'bt' and benchmark != 'sp']\n",
    "# pandasのDFをprintした時の幅を広げる\n",
    "pd.set_option('display.width', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTmp = returnDictForPlotPerNumOfUsedData(Benchmark=benchmarks, fix=\"Class\", benchmarkClass=[\n",
    "    \"A\", \"B\", \"C\", \"D\"], FixedProcess=64, Processes=[1, 2, 4, 8, 16, 32, 64, 128, 256], FixedBenchmarkClass=\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.4g}'.format\n",
    "\n",
    "tmpDF = pd.DataFrame()\n",
    "for benchmark in benchmarks:\n",
    "    listToLearn = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "    listToPredict = [256]\n",
    "    benchmark_x = dictTmp[benchmark][\"x\"]\n",
    "    benchmark_y = dictTmp[benchmark][\"y\"]\n",
    "    index = benchmark_x.index(len(listToLearn))\n",
    "    MAPE = benchmark_y[index]\n",
    "    relativeCost = returnRelativeCost(benchmark=benchmark, variablesToLearn=listToLearn,\n",
    "                                      variablesToPredict=listToPredict, fixedClassOrProcess=\"Class\", fixed=\"C\")\n",
    "    dictRowData = {\"ベンチマーク名\": benchmark.upper(\n",
    "    ), \"平均絶対誤差率[％]\": MAPE, \"相対コスト[％]\": relativeCost}\n",
    "    iDF = pd.DataFrame.from_dict(dictRowData, orient='index').T\n",
    "    tmpDF = tmpDF.append(iDF)\n",
    "tmpDFMean = tmpDF.mean()\n",
    "type(tmpDFMean)\n",
    "print(tmpDF.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictTmp\n",
    "\n",
    "plt.figure(figsize=(5.72, 4), dpi=200)\n",
    "for benchmark in list(dictTmp.keys()):\n",
    "    x = dictTmp[benchmark][\"x\"]\n",
    "    y = dictTmp[benchmark][\"y\"]\n",
    "    plt.plot(x, y, marker='o', label=benchmark.upper())\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"使用したプロファイル数\")\n",
    "    plt.ylabel(\"平均絶対誤差率[％]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.72, 4), dpi=200)\n",
    "\n",
    "# Extra-PでfixProcessデータを入力して出力したモデルの図時\n",
    "plot_x = np.linspace(0.8, 256, 500)\n",
    "# -3590464.6990329633 + 3759195.349891038 * p^(1/4)\n",
    "plot_y = []\n",
    "for x in plot_x:\n",
    "    plot_y.append(2286768.3333333326 + 301997.61904761934 * math.log2(x)**(1))\n",
    "plt.plot(plot_x, plot_y, label=\"ExtraP\")\n",
    "\n",
    "x = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "y = [1984770.0, 2263540.0, 2821070.0, 3936140.0,\n",
    "     3936140.0, 3936140.0, 3936140.0, 3936140.0]\n",
    "x = np.array(x).reshape(-1, 1)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "plt.scatter(x, y, marker=\"o\", label=\"予測に用いた関数コール回数\")\n",
    "plot_x = np.array(plot_x).reshape(-1, 1)\n",
    "x_target = [256]\n",
    "y_target = [3936140]\n",
    "plt.scatter(x_target, y_target, marker=\"o\", label=\"予測したい関数コール回数の実測値\")\n",
    "\n",
    "benchmarkName = \"CG\"\n",
    "functionName = \"ICNVRT\"\n",
    "\n",
    "# 線形モデル\n",
    "# 対数モデル\n",
    "\n",
    "# 反比例モデル\n",
    "modelIpMk2 = ModelIp_mk2(train_x=x, train_y=y, target_x=x_target, target_y=y_target,\n",
    "                         benchmark_name=benchmarkName, function_name=functionName)\n",
    "modelIpMk2.calc_lr()\n",
    "plot_y_IpMk2 = modelIpMk2.predict(plot_x)\n",
    "plt.plot(plot_x, plot_y_IpMk2, label=\"反比例モデル\")\n",
    "# 線形飽和モデル\n",
    "modelBranchMk2 = ModelBranch_mk2(train_x=x, train_y=y, target_x=x_target,\n",
    "                                 target_y=y_target, benchmark_name=benchmarkName, function_name=functionName)\n",
    "modelBranchMk2.calc_lr()\n",
    "plot_y_BranchMk2 = modelBranchMk2.predict(plot_x)\n",
    "plt.plot(plot_x, plot_y_BranchMk2, label=\"線形飽和モデル\")\n",
    "# # 線形モデル\n",
    "# model_lin = ModelLin(x, y, \"CG\", \"ICNVRT\", test_ratio=0)\n",
    "# model_lin.calc_lr()\n",
    "# plot_y_lin = model_lin.predict(plot_x)\n",
    "# plt.plot(plot_x, plot_y_lin, label=\"線形モデル\")\n",
    "# # 対数モデル\n",
    "# model_log10 = ModelLog10(x, y, \"CG\", \"ICNVRT\", test_ratio=0)\n",
    "# model_log10.calc_lr()\n",
    "# plot_y_log10 = model_log10.predict(plot_x)\n",
    "# plt.plot(plot_x, plot_y_log10, label=\"対数モデル\")\n",
    "# # 反比例モデル\n",
    "# model_ip = ModelIP(x, y, \"CG\", \"ICNVRT\", test_ratio=0)\n",
    "# model_ip.calc_lr()\n",
    "# plot_y_ip = model_ip.predict(plot_x)\n",
    "# plt.plot(plot_x, plot_y_ip, label=\"反比例モデル\")\n",
    "# # 線形飽和モデル\n",
    "# model_branch = ModelBranch(x, y, \"CG\", \"ICNVRT\", test_ratio=0)\n",
    "# model_branch.calc_lr()\n",
    "# plot_y_branch = model_branch.predict(plot_x)\n",
    "# plt.plot(plot_x, plot_y_branch, label=\"線形飽和モデル\")\n",
    "# 凡例の表示\n",
    "plt.legend()\n",
    "# 軸ラベルの設定\n",
    "plt.ylabel(\"関数コール回数\")\n",
    "plt.xlabel(\"実行コア数\")\n",
    "\n",
    "plt.scatter(x, y, marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 実際にプロットする\n",
    "\n",
    "\n",
    "# print(f\"fix={fix}, benchmarkClasses={benchmarkClasses}, fixedProcess={fixedProcess}, Processes={processes}, FixedBenchmarkClass={fixedBenchmarkClass}\")\n",
    "# print(f\"targetNumOfProcess={targetNumOfProcess}, targetProblemSize={fixedBenchmarkClass}, fix={fix}\")\n",
    "\n",
    "# DF = returnRawDFperBenchmark(Benchmark=\"mg\", fix=\"Process\", benchmarkClass=[\"A\", \"B\", \"C\", \"D\"], Processes=[\n",
    "#                              1, 2, 4, 8, 16, 32, 64, 128, 256], FixedBenchmarkClass=\"B\", FixedProcess=64)\n",
    "# DF.dropna(how='any')\n",
    "# DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ノートブック中で変数のみを記述することでデータフレームをきれいに表示させる設定の有効化\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb形式のライブラリのインポート\n",
    "%run ./lib/lib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarkNamesExcludeBTSP = [\"cg\", \"ep\", \"ft\", \"is\", \"lu\", \"mg\"]\n",
    "# classes = [\"A\", \"B\", \"C\", \"D\"]\n",
    "classes = [\"B\"]\n",
    "processes = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "targetIndex = -1\n",
    "csvDirPath = \"./csv_files/\"\n",
    "\n",
    "dfByDatumExcludeBTSP = returnDFSummarizedData(\n",
    "    benchmarkNames=benchmarkNamesExcludeBTSP, classes=classes, processes=processes, targetIndex=targetIndex, csvDirPath=csvDirPath)\n",
    "# dfByDatumExcludeBTSP\n",
    "\n",
    "dictForLatexTable = {}\n",
    "numOfData = 0\n",
    "for benchmarkName in benchmarkNamesExcludeBTSP:\n",
    "    dictForLatexTable[benchmarkName] = dfByDatumExcludeBTSP[dfByDatumExcludeBTSP[\"benchmarkName\"] == benchmarkName]\n",
    "    numOfData += len(\n",
    "        dfByDatumExcludeBTSP[dfByDatumExcludeBTSP[\"benchmarkName\"] == benchmarkName])\n",
    "\n",
    "numOfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "benchmarkName &      ModelIp &      ModelLog & ModelBranch &     ModelLin \\\\\n",
      "\\midrule\n",
      "           CG &         0(-) & 13(23.0,23.0) & 18(0.0,0.0) &  69(0.0,0.0) \\\\\n",
      "           EP &         0(-) &          0(-) &        0(-) & 100(0.0,0.0) \\\\\n",
      "           FT &         0(-) &          0(-) & 26(0.0,0.0) & 74(0.0,84.1) \\\\\n",
      "           IS &         0(-) & 14(11.5,11.5) &        0(-) & 86(0.0,84.4) \\\\\n",
      "           LU & 23(0.0,28.1) &          0(-) &        0(-) &  77(0.0,0.0) \\\\\n",
      "           MG &         0(-) &    4(0.5,0.5) &        0(-) &  96(0.0,3.2) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 入力：returnSeriesOfDataを結合したDF（含むベンチマークの種類は1つ）\n",
    "# 出力：各モデルの採用割合が入ったSeries\n",
    "def returnSeriesOfDatumPerBenchmark(inputDF):\n",
    "    # 全データが単一のベンチマークによるものかを確認し、そうでなければ警告を出力する\n",
    "    listOfBenchmarkNameInInputDF = inputDF[\"benchmarkName\"].tolist()\n",
    "    noDuplicateBenchmarkName = list(set(listOfBenchmarkNameInInputDF))\n",
    "    if (len(noDuplicateBenchmarkName) != 1):\n",
    "        warnings.warn(\"入力DFには複数のベンチマークの結果が含まれています\")\n",
    "    benchmarkName = noDuplicateBenchmarkName[0]\n",
    "    numOfInputDF = len(inputDF)\n",
    "    modelNames = [\"ModelIp\", \"ModelLog\", \"ModelBranch\", \"ModelLin\"]\n",
    "    contentList = [benchmarkName.upper()]\n",
    "    summarizedRateExcludeModelLin = 0\n",
    "    for modelName in modelNames:\n",
    "        dfOfModel = inputDF[inputDF[\"objectBestModelName\"] == modelName]\n",
    "        numOfModel = len(dfOfModel)\n",
    "        rateOfModel = int(numOfModel/numOfInputDF * 100)\n",
    "\n",
    "        try:\n",
    "            maxInDfOfModel = int(dfOfModel[\"MAPEOfBestModel\"].max()*10)/10\n",
    "        except:\n",
    "            maxInDfOfModel = \"-\"\n",
    "\n",
    "        try:\n",
    "            minInDfOfModel = int(dfOfModel[\"MAPEOfBestModel\"].min()*10)/10\n",
    "        except:\n",
    "            minInDfOfModel = \"-\"\n",
    "\n",
    "        if modelName != \"ModelLin\":\n",
    "            summarizedRateExcludeModelLin += rateOfModel\n",
    "        elif modelName == \"ModelLin\":\n",
    "            rateOfModel = 100 - summarizedRateExcludeModelLin\n",
    "\n",
    "        instanceDatumAboutRateOfModel = DatumAboutRateOfModel(\n",
    "            modelName=modelName, rateOfModel=rateOfModel, minMAPE=minInDfOfModel, maxMAPE=maxInDfOfModel)\n",
    "        contentList.append(instanceDatumAboutRateOfModel.returnFormattedStr())\n",
    "    columnList = [\"benchmarkName\"] + modelNames\n",
    "    returnSeries = pd.Series(data=contentList, index=columnList)\n",
    "    return(returnSeries)\n",
    "\n",
    "\n",
    "class DatumAboutRateOfModel:\n",
    "    def __init__(self, modelName, rateOfModel, minMAPE, maxMAPE):\n",
    "        # モデル名\n",
    "        self.modelName = modelName\n",
    "        # モデルの被採用率\n",
    "        self.rateOfModel = rateOfModel\n",
    "        # モデルの最小MAPE・最大MAPE\n",
    "        self.minMAPE = minMAPE\n",
    "        self.maxMAPE = maxMAPE\n",
    "\n",
    "    def returnFormattedStr(self):\n",
    "        if (self.maxMAPE == \"-\" or self.minMAPE == \"-\"):\n",
    "            strMinMax = \"-\"\n",
    "        else:\n",
    "            strMinMax = (f\"{self.minMAPE},{self.maxMAPE}\")\n",
    "        returnStr = f\"{self.rateOfModel}({strMinMax})\"\n",
    "        return(returnStr)\n",
    "\n",
    "\n",
    "listForDF = []\n",
    "\n",
    "for benchmarkName in benchmarkNamesExcludeBTSP:\n",
    "    listForDF.append(returnSeriesOfDatumPerBenchmark(\n",
    "        inputDF=dictForLatexTable[benchmarkName]))\n",
    "DF = pd.DataFrame(listForDF)\n",
    "print(DF.to_latex(index=False))\n",
    "\n",
    "\n",
    "@pytest.fixture()\n",
    "def test_generateCSVFilesForReturnSeriesOfDatumPerBenchmark():\n",
    "    benchmarkName = \"test\"\n",
    "    functionNames = [\"modelBranch\", \"modelIp\", \"modelLin\", \"modelLog\"]\n",
    "    fixed=\"B\"\n",
    "    targetProcess=\"256\"\n",
    "    filePath = \"/tmp/pprof_testD256.csv\"\n",
    "    functionName = \"testFunctionName\"\n",
    "    with open(filePath, 'w') as f:\n",
    "        f.write(\"Name,#Call\\n\")\n",
    "        # 本来は各モデルごとに最適な関数コール回数とするべきだが、できないので-1を返すようにした\n",
    "        f.write(f\"{functionName},-1\\n\")\n",
    "        \n",
    "        \n",
    "def test_returnSeriesOfDatumPerBenchmark():\n",
    "    # テストについて\n",
    "    pass\n",
    "    # 各モデルがそれぞれカウントされている\n",
    "    # 線形飽和モデル\n",
    "    plotXForBranch = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "    plotYForBranch = [5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 23, 23, 23, 23]\n",
    "    seriesBranch = returnSeriesOfData(benchmarkName=\"test\", functionName=\"modelBranch\", rawX=plotXForBranch, rawY=plotYForBranch, fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=plotYForBranch[-1], csvDirPath=\"./csv_files\")\n",
    "    csvDirPath = \"../csv_files\"\n",
    "    # 反比例モデル・線形モデル・対数モデルで共通の説明変数\n",
    "    plotX = np.linspace(0.5, 256, 500)\n",
    "    # 3モデルで共通な説明変数が256のときのインデックス値\n",
    "    indexAt256Core = -1\n",
    "    # 反比例モデル\n",
    "    plotYForIp = 2/plotX + 3\n",
    "    seriesIp = returnSeriesOfData(benchmarkName=\"test\", functionName=\"modelIp\", rawX=plotX, rawY=plotYForIp, fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=plotYForIp[-1], csvDirPath=csvDirPath)\n",
    "    # 線形モデル\n",
    "    plotYForLin = 2 * plotX + 3\n",
    "    seriesLin = returnSeriesOfData(benchmarkName=\"test\", functionName=\"modelLin\", rawX=plotX, rawY=plotYForLin, fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=plotYForLin[-1], csvDirPath=csvDirPath)\n",
    "    # 対数モデル\\\n",
    "    plotYForLog = 2 * np.log10(plotX) + 3\n",
    "    seriesLog = returnSeriesOfData(benchmarkName=\"test\", functionName=\"modelLog\", rawX=plotX, rawY=plotYForLog, fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=plotYForLog[-1], csvDirPath=csvDirPath)\n",
    "    # 4つのモデルが最適となるDFをテストデータとするのでそれぞれ25%であることを確認\n",
    "    # 入力データ数と各モデルのカウント値の最大値が同じ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_returnSeriesOfDatumPerBenchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultIs = dictForLatexTable[\"is\"]\n",
    "# resultIs\n",
    "resultIsAtModelBranch = resultIs[resultIs[\"objectBestModelName\"]\n",
    "                                 == \"ModelBranch\"]\n",
    "datumX = resultIsAtModelBranch[\"usedDataX\"].tolist()\n",
    "datumY = resultIsAtModelBranch[\"usedDataY\"].tolist()\n",
    "\n",
    "datumX\n",
    "datumY\n",
    "\n",
    "# returnSeriesOfData(benchmarkName=\"is\", functionName=\"double_randlc(double_*_double_*)\", rawX=dataX, rawY=dataY, fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=-1, csvDirPath=\"./csv_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultIs = dictForLatexTable[\"ft\"]\n",
    "# resultIs\n",
    "resultIsAtModelBranch = resultIs[resultIs[\"objectBestModelName\"]\n",
    "                                 == \"ModelBranch\"]\n",
    "resultIsAtModelBranchOfNotLowMAPE = resultIsAtModelBranch[\n",
    "    resultIsAtModelBranch[\"MAPEOfBestModel\"] > 1]\n",
    "resultIsAtModelBranchOfNotLowMAPE\n",
    "datumX = resultIsAtModelBranchOfNotLowMAPE[\"usedDataX\"].tolist()\n",
    "datumY = resultIsAtModelBranchOfNotLowMAPE[\"usedDataY\"].tolist()\n",
    "\n",
    "datumX\n",
    "datumY\n",
    "\n",
    "for dataIndex in range(len(datumX)):\n",
    "    plt.figure()\n",
    "    plt.scatter(datumX[dataIndex], datumY[dataIndex])\n",
    "\n",
    "# returnSeriesOfData(benchmarkName=\"is\", functionName=\"double_randlc(double_*_double_*)\", rawX=dataX, rawY=dataY, fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=-1, csvDirPath=\"./csv_files\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 実験用に小規模なリスト\n",
    "benchmarkNames = [\"cg\"]\n",
    "classes = [\"B\"]\n",
    "processes = [1, 2, 4, 8, 16, 32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 生データの取得\n",
    "cgDF = returnCollectedExistingData(benchmarkNames=[\"cg\"], classes=[\"A\", \"B\", \"C\", \"D\"], processes=[\n",
    "                                   1, 2, 4, 8, 16, 32, 64, 128, 256], csvDirPath=\"./csv_files/\")\n",
    "cgDF\n",
    "# ベンチマーククラスがAの情報を取得\n",
    "cgDFfixedA = cgDF[cgDF[\"benchmarkClass\"] == \"A\"]\n",
    "cgDFfixedA\n",
    "# 関数名のリストを取得\n",
    "functionNames = sorted(list(set(cgDFfixedA[\"functionName\"])))\n",
    "print(functionNames)\n",
    "\n",
    "# 関数名を関数名のリストから抽出\n",
    "functionNameCG = cgDFfixedA[cgDFfixedA[\"functionName\"] == \"CG\"]\n",
    "functionNameCG\n",
    "\n",
    "# 説明変数と目的変数とをリスト化したものを抽出\n",
    "# プロセス数\n",
    "raw_x = functionNameCG['process'].tolist()\n",
    "# 関数コール回数\n",
    "raw_y = functionNameCG['functionCallNum'].tolist()\n",
    "\n",
    "print(f\"raw_x={raw_x}\")\n",
    "print(f\"raw_y={raw_y}\")\n",
    "\n",
    "bencmarkName = \"CG\"\n",
    "functionName = \"CG\"\n",
    "fixProcessOrClass = \"Class\"\n",
    "fixed = \"A\"\n",
    "targetProcess = 256\n",
    "targetBenchmarkClass = fixed\n",
    "targetFunctionCallNum = raw_y[-1]\n",
    "returnSeriesOfData(benchmarkName=\"benhmarkName\", functionName=\"functionName\", rawX=[1, 2, 3], rawY=[\n",
    "                   1, 2, 3], fixProcessOrClass=\"Class\", fixed=\"B\", targetProcess=256, targetBenchmarkClass=\"B\", targetFunctionCallNum=-1, csvDirPath=\"./csv_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
